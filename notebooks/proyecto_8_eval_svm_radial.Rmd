---
title: "Prediccion de Tipo de Transporte - Proyecto de Transporte"
output: html_notebook
---

### General: Objetivos del Proyecto y Definici贸n de Variables

El objetivo principal de este proyecto es desarrollar un modelo basado en **M谩quinas de Vectores de Soporte (SVM)** para predecir el **modo de transporte** utilizado por un individuo en funci贸n de los datos recopilados por sensores de dispositivos m贸viles. Se busca analizar c贸mo las diferentes se帽ales captadas por el aceler贸metro, gir贸scopo, bar贸metro, GPS y magnet贸metro pueden ser utilizadas para inferir con precisi贸n el medio de transporte en uso.

Para lograr esto, se cuenta con un conjunto de datos que incluye:

1.  **Registro Temporal**

    -   Cada observaci贸n est谩 asociada a un instante de tiempo espec铆fico.

2.  **Datos de Movimiento y Orientaci贸n**

    -   **Aceler贸metro**: Componentes X, Y, Z del vector aceleraci贸n.

    -   **Gir贸scopo**: Velocidad angular en los ejes X, Y, Z y su derivada.

    -   **Matriz de Rotaci贸n y Cuaterniones**: Representan la orientaci贸n tridimensional del dispositivo.

3.  **Datos de Ubicaci贸n y Contexto**

    -   **GPS**: Coordenadas de latitud y longitud, velocidad, altitud y rumbo.

    -   **Presi贸n Atmosf茅rica**: Valores obtenidos del bar贸metro, junto con la altitud relativa.

    -   **Campo Magn茅tico Terrestre**: Medici贸n en los ejes X, Y, Z.

4.  **Variables Categ贸ricas**

    -   **Modo de Transporte**: La categor铆a que se busca predecir (caminar, bicicleta, autom贸vil, etc.).

    -   **Nivel de Confianza**: Un indicador de la precisi贸n estimada para la clasificaci贸n del transporte en los datos originales.

### Objetivo Notebook:

# **1. Carga de librer铆as**

```{r}
# Lista de paquetes necesarios
necessary_packages <- c("dplyr", "caret", "e1071", "robustbase", "ggplot2", "data.table", "pROC","doParallel")

# Instalar paquetes que no est谩n instalados
new_packages <- necessary_packages[!(necessary_packages %in% installed.packages()[, "Package"])]
if (length(new_packages) > 0) {
  install.packages(new_packages)
}

# Cargar todos los paquetes
lapply(necessary_packages, library, character.only = TRUE)
```

```{r}
# Cargar las librer铆as necesarias
library(caret)      # Para divisi贸n estratificada y evaluaci贸n de modelos
library(scales)     # Para Min-Max Scaling
library(e1071)      # Para entrenar SVM
library(randomForest)  # Para obtener la importancia de las variables
library(dplyr)      # Para manipulaci贸n de datos
# Cargar la librer铆a
library(visdat)
# Cargar la librer铆a
library(tidyr)
# Cargar el paquete 'car'
library(car)
library(ggplot2)
library(stringr) #Cambiar variables
library(DMwR)  # Para SMOTE

```

# 2. Cargar el dataset

```{r}
# Ruta del archivo CSV (modificar seg煤n tu sistema)
ruta_dataset <- "C:/Users/Lenovo/Documents/IT Academy/Datos proyecto 8/proyect8/data_vars_eliminadas.csv"
data <- read.csv(ruta_dataset)


data <- read.csv(ruta_dataset)

# Resumen del dataset
cat("### Informaci贸n General del Dataset")
dim(data) # Dimensiones del dataset
str(data) # Estructura del dataset

```

```{r}
summary(data) # Resumen estad铆stico b谩sico
```

## 2.1 Selecci贸n de las Variables de acuerdo a RF, VIF y Anova

```{r}
# Seleccionar solo las variables relevantes
data_filtrado <- data %>%
  select(accelX.g., accelZ.g., accelY.g., # Aceleraci贸n
         Roll.rads., Pitch.rads., gyroX.rad.s.,  # Giroscopios
         RelativeAltitude.meters., herzios,  # Contexto ambiental
         m33,  # Componente de Movimiento
         ActivityType)  # Variable objetivo

# Guardar el dataset actualizado
write.csv(data_filtrado, "dataset_filtrado.csv", row.names = FALSE)

# Mostrar primeras filas del dataset filtrado
head(data_filtrado)
```

```{r}
str ( data_filtrado)
```

```{r}
library(dplyr)

# Verificar que el dataset existe
if (exists("data")) {
  # Filtrar las variables num茅ricas y eliminar la variable dependiente (ActivityType)
  num_data_filtered <- data_filtrado %>%
    select(where(is.numeric)) %>%
    mutate(dummy_target = runif(nrow(.), 0, 1)) # Crear una variable dummy temporal

  # Validar si hay suficientes variables para calcular el modelo
  if (ncol(num_data_filtered) > 1) {
    # Crear un modelo de regresi贸n con las variables predictoras
    vif_model <- lm(dummy_target ~ ., data = num_data_filtered)
    
    # Calcular los valores de VIF
    vif_values <- vif(vif_model)
    
    # Imprimir los valores de VIF
    print("### Factores de Inflaci贸n de Varianza (VIF)")
    print(vif_values)
    
    # Identificar variables con alta colinealidad (VIF > 10 como umbral com煤n)
    high_vif <- vif_values[vif_values > 10]
    if (length(high_vif) > 0) {
      cat("\nVariables con alta colinealidad (VIF > 10):\n")
      print(high_vif)
    } else {
      cat("\nNo se encontraron variables con alta colinealidad (VIF <= 10).\n")
    }
  } else {
    cat("No hay suficientes variables num茅ricas para calcular el VIF.\n")
  }
} else {
  cat("El dataset 'data' no existe en el entorno.\n")
}
```

# 3. Implementar `class.weights` para ajustar el desbalance de clases.

```{r}
# Convertir la variable objetivo a factor (si no lo est谩)
data_filtrado$ActivityType <- as.factor(data_filtrado$ActivityType)

# 1 Convertir Herzios a num茅rico
data_filtrado <- data_filtrado %>%
  mutate(herzios = as.numeric(herzios))

# Verificar que Herzios ahora es num茅rico
str(data_filtrado$herzios)
summary(data_filtrado$herzios)
```

```{r}
# Identificar solo las columnas num茅ricas (excluyendo `ActivityType`)
num_cols <- sapply(data_filtrado, is.numeric)

# Aplicar Min-Max Scaling SOLO a las columnas num茅ricas
preproc <- preProcess(data_filtrado[, num_cols], method = c("range"))
data_scaled <- predict(preproc, data_filtrado[, num_cols])

# Volver a agregar la variable objetivo `ActivityType`
data_scaled$ActivityType <- data_filtrado$ActivityType

# Verificar la estructura del dataset escalado
str(data_scaled)
summary(data_scaled)
```

```{r}
# Verificar si hay NA despu茅s del escalado
print(" 驴Hay valores NA despu茅s del escalado?")
print(any(is.na(data_scaled)))  # Debe ser FALSE

# Verificar si las variables est谩n en el rango correcto [0,1]
summary(data_scaled)
```

```{r}

# 1锔 Calcular pesos inversamente proporcionales al tama帽o de cada clase
class_counts <- table(data_scaled$ActivityType)
class_weights <- 1 / class_counts

# 2锔 Normalizar dividiendo por el m谩ximo peso
class_weights <- class_weights / max(class_weights)

# 3锔 Asignar nombres a los pesos
names(class_weights) <- names(class_counts)

# Ver los pesos normalizados
print(class_weights)

```

```{r}
print(class_weights)
```

```{r}
set.seed(123)
trainIndex <- createDataPartition(data_scaled$ActivityType, p = 0.8, list = FALSE)
train_data <- data_scaled[trainIndex, ]
test_data <- data_scaled[-trainIndex, ]
```

```{r}
print(colnames(train_data))
print(colnames(test_data))

```

```{r}
print(table(train_data$ActivityType))
print(table(test_data$ActivityType))

```

# 4. Entrenar Modelo Kermel Radial:

## 4.1 SVM con Kernel: Radial y pesos inversamente proporcionales al tama帽o de cada clase.

```{r}
# Entrenar SVM con Kernel Radial y Pesos Ajustados
svm_model <- svm(ActivityType ~ ., data = train_data, kernel = "radial", 
                 cost = 1, gamma = 0.01, class.weights = class_weights)

# Hacer predicciones en el conjunto de prueba
pred <- predict(svm_model, test_data)
```

```{r}
# Hacer predicciones con el modelo corregido
pred_adjusted <- predict(svm_model, test_data)

# Evaluar el modelo con bias ajustado
conf_matrix_adjusted <- confusionMatrix(pred_adjusted, test_data$ActivityType)
print(conf_matrix_adjusted)
```

```{r}
library(FactoMineR)
library(factoextra)
library(ggplot2)

# Aplicar PCA para reducir la dimensionalidad
pca_model <- PCA(data_scaled[, -ncol(data_scaled)], graph = FALSE)

# Extraer los dos primeros componentes principales
pca_data <- as.data.frame(pca_model$ind$coord)
pca_data$ActivityType <- data_scaled$ActivityType

# Graficar las clases en el espacio PCA
ggplot(pca_data, aes(x = Dim.1, y = Dim.2, color = ActivityType)) +
  geom_point(alpha = 0.7) +
  labs(title = "Separaci贸n de Clases con PCA",
       x = "PC1",
       y = "PC2") +
  theme_minimal()

```

Se puede notar una buena separaci贸n en algunas clases (`Andando`, `Coche_urbano`, `Bicicleta`), lo cual indica que hay informaci贸n relevante en las variables seleccionadas. Sin embargo, hay solapamiento entre algunas clases, como Autob煤s, Coche_autopista y Avion lo que podr铆a generar errores de clasificaci贸n. `Avi贸n` parece estar m谩s disperso, lo que sugiere que podr铆a beneficiarse de pesos m谩s fuertes o de un modelo m谩s flexible.

## 4.2 SVM con Kernel: Radial y pesos manual.

```{r}
# Aplciar nuevos pesos
class_weights_pesado <- c("Andando" = 5, "Autobus" = 3, "Avion" = 10, 
                   "Bicleta" = 4, "Coche_autopista" = 6, "Coche_urbano" = 2)

# Normalizaci贸n para que la suma de los pesos sea 1
class_weights_pesadp <- class_weights_pesado / sum(class_weights_pesado)

print(class_weights_pesado)  # Revisar los nuevos pesos normalizados

```

```{r}
svm_model <- svm(ActivityType ~ ., data = train_data, kernel = "radial", 
                 cost = 0.1, gamma = 0.001, class.weights = class_weights_pesado)

```

```{r}
pred <- predict(svm_model, test_data)

# Matriz de confusi贸n
conf_matrix <- confusionMatrix(pred, test_data$ActivityType)
print(conf_matrix)

```

### 4.3 Busqueda del mejor modelo

Dado que el modelo a煤n no proporciona valores 贸ptimos en las m茅tricas de clasificaci贸n, se proceder谩 a realizar una b煤squeda m谩s exhaustiva de hiperpar谩metros. Se explorar谩n diferentes valores de **C (cost)** y **gamma**, utilizando el **kernel radial** para mejorar la capacidad del modelo de capturar relaciones no lineales en los datos.

Esta optimizaci贸n se realizar谩 mediante **Validaci贸n Cruzada (CV = 10)** para obtener estimaciones m谩s robustas del desempe帽o del modelo y evitar sobreajuste.

```{r}
library(caret)
library(e1071)
library(doParallel)  # Para paralelizaci贸n

# 1  Configurar los n煤cleos para paralelizaci贸n
num_cores <- detectCores() - 2  # Dejar 2 n煤cleos libres para evitar bloqueos
cl <- makeCluster(num_cores)  # Crear cl煤ster
registerDoParallel(cl)  # Activar paralelizaci贸n

# 2锔 Definir la malla de hiperpar谩metros correctamente
tune_grid <- expand.grid(
  sigma = c(0.0001, 0.001, 0.01, 0.1, 1),  # Cambiar 'gamma' por 'sigma'
  C = c(0.01, 0.1, 1, 10)
)


# 3  Configurar validaci贸n cruzada con paralelizaci贸n
train_control <- trainControl(method = "cv", number = 10, allowParallel = TRUE)

# 4 Entrenar el modelo SVM con Grid Search paralelizado
svm_tune <- train(ActivityType ~ ., data = train_data, 
                   method = "svmRadial",
                   trControl = train_control,
                   tuneGrid = tune_grid,
                   class.weights = class_weights_pesado)

# 5 Apagar el cl煤ster despu茅s del entrenamiento
stopCluster(cl)
registerDoSEQ()  # Volver al modo secuencial normal

```

```{r}

# 6 Imprimir los mejores hiperpar谩metros
print(svm_tune$bestTune)

# 7 Visualizar resultados de Grid Search
plot(svm_tune)

```

```{r}
# Extraer los mejores hiperpar谩metros encontrados en Grid Search
best_C <- svm_tune$bestTune$C
best_gamma <- svm_tune$bestTune$sigma

# Entrenar el modelo final con los mejores hiperpar谩metros
svm_final <- svm(ActivityType ~ ., data = train_data, kernel = "radial",
                 cost = best_C, gamma = best_gamma, class.weights = class_weights_pesado)

# Hacer predicciones en el conjunto de prueba
pred_final <- predict(svm_final, test_data)
```

```{r}
# Evaluar modelo con Matriz de Confusi贸n
conf_matrix <- confusionMatrix(pred, test_data$ActivityType)

# Mostrar matriz de confusi贸n
print(conf_matrix)

# Extraer m茅tricas espec铆ficas
precision <- conf_matrix$byClass[, "Pos Pred Value"]  # Precisi贸n por clase
recall <- conf_matrix$byClass[, "Sensitivity"]        # Recall por clase
f1_score <- 2 * (precision * recall) / (precision + recall)  # F1-score

# Mostrar resultados
print(data.frame(Class = levels(test_data$ActivityType),
                 Precision = precision,
                 Recall = recall,
                 F1_Score = f1_score))
```

El modelo SVM con kernel radial ha sido optimizado utilizando validaci贸n cruzada (CV) con valores de 5 y 10 particiones, obteniendo resultados muy similares en t茅rminos de precisi贸n, recall y F1-score. La precisi贸n global es alta (\~97.9%), pero se observa que algunas clases presentan un desbalance en la sensibilidad y especificidad. En particular, la clase *Autob煤s* muestra una sensibilidad de 100%, pero una precisi贸n m谩s baja (84.5%), lo que sugiere que hay un n煤mero significativo de falsos positivos.

El tuning de hiperpar谩metros con grid search ha permitido encontrar valores 贸ptimos de *C* y *gamma*, pero la mejora sigue siendo marginal. Esto sugiere que la estructura del modelo SVM, incluso con el ajuste de pesos de clase, no est谩 abordando completamente el problema de desbalance en la clasificaci贸n.

```{r}
best_C <- svm_tune$bestTune$C
best_gamma <- svm_tune$bestTune$sigma

#  Obtener las frecuencias de clases en el conjunto de entrenamiento
class_counts <- table(train_data$ActivityType)
class_weights <- 1 / class_counts  # Pesos inversamente proporcionales
names(class_weights) <- names(class_counts)

#  Normalizar los pesos (opcional)
class_weights <- class_weights / sum(class_weights)

#  Entrenar SVM con los mejores hiperpar谩metros y los pesos ajustados
svm_final <- svm(ActivityType ~ ., data = train_data, 
                 kernel = "radial", 
                 cost = best_C, 
                 gamma = best_gamma, 
                 class.weights = class_weights)

#  Hacer predicciones en el conjunto de prueba
predictions <- predict(svm_final, test_data)

#  Evaluar el modelo con la Matriz de Confusi贸n
conf_matrix <- confusionMatrix(predictions, test_data$ActivityType)
print(conf_matrix)

#  Extraer m茅tricas de rendimiento
precision <- conf_matrix$byClass[, "Pos Pred Value"]
recall <- conf_matrix$byClass[, "Sensitivity"]
f1_score <- 2 * (precision * recall) / (precision + recall)

#  Mostrar resultados de precisi贸n, recall y F1-score
metrics_results <- data.frame(Class = levels(test_data$ActivityType),
                              Precision = precision,
                              Recall = recall,
                              F1_Score = f1_score)

print(metrics_results)
```

### ** An谩lisis de Resultados**

**Por completar**

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)

#  Contar la frecuencia de clases reales y predichas por separado
df_actual <- test_data %>%
  count(ActivityType) %>%
  mutate(Type = "Real")

df_predicted <- data.frame(Predicted = predict(svm_final, test_data)) %>%
  count(Predicted) %>%
  rename(ActivityType = Predicted) %>%
  mutate(Type = "Predicho")

#  Unir ambos datasets
df_comparison <- bind_rows(df_actual, df_predicted)

#  Graficar comparaci贸n entre clases reales y predichas
ggplot(df_comparison, aes(x = ActivityType, y = n, fill = Type)) +
  geom_bar(stat = "identity", position = "dodge") +  # Barras lado a lado
  scale_fill_manual(values = c("Real" = "blue", "Predicho" = "red")) +
  labs(title = "Comparaci贸n de Clases Reales vs. Predichas",
       x = "Clase",
       y = "Frecuencia",
       fill = "Tipo") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotar etiquetas para mejor lectura

```

**Las clases mayoritarias est谩n bien representadas.**\
锔 **Las clases minoritarias como "Bicicleta", "Avi贸n" y "Coche Autopista" est谩n siendo subestimadas.**\
锔 **El modelo podr铆a estar sesgado hacia clases m谩s comunes.**

MEJORAR COMENTARIOS

# 5. Entrenar Modelo Kermel Simoid:

Dado que los resultados con el kernel radial han mostrado un buen rendimiento general, pero a煤n presentan ciertos desaf铆os con el desbalanceo de clases, se considera probar el **kernel sigmoide**. Este kernel puede ser 煤til en problemas donde los datos no sean perfectamente separables mediante una frontera estricta, ya que introduce una transformaci贸n m谩s flexible similar a las redes neuronales.

Sin embargo, es importante se帽alar que el principal factor que afecta la clasificaci贸n sigue siendo el **desbalanceo de clases**, lo que podr铆a generar sesgo en el modelo sin importar el kernel utilizado. Por ello, adem谩s de probar el kernel sigmoide, es recomendable continuar ajustando los pesos de clase.

```{r}
library(e1071)
library(caret)
library(doParallel)

# Configurar paralelizaci贸n
num_cores <- detectCores() - 2  
cl <- makeCluster(num_cores)  
registerDoParallel(cl)  

# Definir los valores de hiperpar谩metros a explorar
tune_grid_sigmoid <- expand.grid(
  C = c(0.01, 0.1, 1, 10),  # Valores de regularizaci贸n
  gamma = c(0.0001, 0.001, 0.01, 0.1, 1),  # Par谩metro gamma
  coef0 = c(0, 0.5, 1, 2, 3)  # Par谩metro coef0 para el kernel sigmoide
)

# Configurar validaci贸n cruzada manualmente
train_control <- trainControl(method = "cv", number = 5, allowParallel = TRUE)

# Entrenar el modelo SVM con Kernel Sigmoide
svm_results <- expand.grid(C = tune_grid_sigmoid$C, 
                           gamma = tune_grid_sigmoid$gamma, 
                           coef0 = tune_grid_sigmoid$coef0)

svm_results$Accuracy <- NA

for (i in 1:nrow(svm_results)) {
  set.seed(123)  # Reproducibilidad
  
  model <- svm(ActivityType ~ ., 
               data = train_data, 
               kernel = "sigmoid",
               cost = svm_results$C[i],
               gamma = svm_results$gamma[i],
               coef0 = svm_results$coef0[i],
               class.weights = class_weights_pesado,
               cross = 5)  # 5-fold cross-validation

  # Guardar la precisi贸n promedio
  svm_results$Accuracy[i] <- mean(model$tot.accuracy)
}

# Apagar paralelizaci贸n
stopCluster(cl)
registerDoSEQ()
```

```{r}
# Mostrar los mejores hiperpar谩metros encontrados
best_params <- svm_results[which.max(svm_results$Accuracy), ]
print(best_params)

```

```{r}
# Entrenar el modelo final con los mejores par谩metros encontrados
final_model <- svm(ActivityType ~ ., 
                   data = train_data, 
                   kernel = "sigmoid", 
                   cost = best_params$C,
                   gamma = best_params$gamma,
                   coef0 = best_params$coef0,
                   class.weights = class_weights_pesado)

# Realizar predicciones en el conjunto de prueba
predictions <- predict(final_model, test_data)

# Evaluar el modelo con la matriz de confusi贸n
conf_matrix <- confusionMatrix(predictions, test_data$ActivityType)

# Imprimir la matriz de confusi贸n
print(conf_matrix)


#  Mostrar resultados de precisi贸n, recall y F1-score
metrics_results_sigmoid <- data.frame(Class = levels(test_data$ActivityType),
                                      Precision = precision_sigmoid,
                                      Recall = recall_sigmoid,
                                      F1_Score = f1_score_sigmoid)

print(metrics_results_sigmoid)

```
