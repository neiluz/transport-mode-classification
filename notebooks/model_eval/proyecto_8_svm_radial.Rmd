---
title: "Prediccion de Tipo de Transporte - Proyecto de Transporte"
output: html_notebook
---

### General: Objetivos del Proyecto y Definici贸n de Variables

El objetivo principal de este proyecto es desarrollar un modelo basado en **M谩quinas de Vectores de Soporte (SVM)** para predecir el **modo de transporte** utilizado por un individuo en funci贸n de los datos recopilados por sensores de dispositivos m贸viles. Se busca analizar c贸mo las diferentes se帽ales captadas por el aceler贸metro, gir贸scopo, bar贸metro, GPS y magnet贸metro pueden ser utilizadas para inferir con precisi贸n el medio de transporte en uso.

Para lograr esto, se cuenta con un conjunto de datos que incluye:

1.  **Registro Temporal**

    -   Cada observaci贸n est谩 asociada a un instante de tiempo espec铆fico.

2.  **Datos de Movimiento y Orientaci贸n**

    -   **Aceler贸metro**: Componentes X, Y, Z del vector aceleraci贸n.

    -   **Gir贸scopo**: Velocidad angular en los ejes X, Y, Z y su derivada.

    -   **Matriz de Rotaci贸n y Cuaterniones**: Representan la orientaci贸n tridimensional del dispositivo.

3.  **Datos de Ubicaci贸n y Contexto**

    -   **GPS**: Coordenadas de latitud y longitud, velocidad, altitud y rumbo.

    -   **Presi贸n Atmosf茅rica**: Valores obtenidos del bar贸metro, junto con la altitud relativa.

    -   **Campo Magn茅tico Terrestre**: Medici贸n en los ejes X, Y, Z.

4.  **Variables Categ贸ricas**

    -   **Modo de Transporte**: La categor铆a que se busca predecir (caminar, bicicleta, autom贸vil, etc.).

    -   **Nivel de Confianza**: Un indicador de la precisi贸n estimada para la clasificaci贸n del transporte en los datos originales.

### Objetivo Notebook:

-   Evaluar el rendimiento del modelo Support Vector Machine (SVM) con diferentes configuraciones del kernel radial.

-   Optimizar el modelo SVM mediante la b煤squeda de hiperpar谩metros.

-   Generar predicciones utilizando el conjunto de test 1.

-   Evaluar el modelo en el conjunto de test 2.

# **1. Carga de librer铆as**

```{r}
# Lista de paquetes necesarios
necessary_packages <- c("dplyr", "caret", "e1071", "robustbase", "ggplot2", "data.table", "pROC","doParallel")

# Instalar paquetes que no est谩n instalados
new_packages <- necessary_packages[!(necessary_packages %in% installed.packages()[, "Package"])]
if (length(new_packages) > 0) {
  install.packages(new_packages)
}

# Cargar todos los paquetes
lapply(necessary_packages, library, character.only = TRUE)
```

```{r}
# Cargar las librer铆as necesarias
library(caret)      # Para divisi贸n estratificada y evaluaci贸n de modelos
library(scales)     # Para Min-Max Scaling
library(e1071)      # Para entrenar SVM
library(randomForest)  # Para obtener la importancia de las variables
library(dplyr)      # Para manipulaci贸n de datos
# Cargar la librer铆a
library(visdat)
# Cargar la librer铆a
library(tidyr)
# Cargar el paquete 'car'
library(car)
library(ggplot2)
library(stringr) #Cambiar variables
library(DMwR)  # Para SMOTE

```

# 2. Cargar el dataset

```{r}
# Ruta del archivo CSV (modificar seg煤n tu sistema)
ruta_dataset <- "C:/Users/Lenovo/Documents/IT Academy/Datos proyecto 8/proyect8/data_vars_imputadas.csv"
data <- read.csv(ruta_dataset)


data <- read.csv(ruta_dataset)

# Resumen del dataset
cat("### Informaci贸n General del Dataset")
dim(data) # Dimensiones del dataset
str(data) # Estructura del dataset

```

```{r}
summary(data) # Resumen estad铆stico b谩sico
```

## 2.1 Selecci贸n de las Variables de acuerdo a RF, VIF y Anova

```{r}
# Seleccionar solo las variables relevantes
data_filtrado <- data %>%
  select(accelX.g., accelZ.g., accelY.g.,  # Aceleraci贸n
         Roll.rads., Pitch.rads., Yaw.rads., gyroY.rad.s.,  # Giroscopios
         Pressure.kilopascals., herzios,  # Contexto ambiental
         m33,  # Componentes de Movimiento
         ActivityType)  # Variable objetivo

# Guardar el dataset actualizado
write.csv(data_filtrado, "dataset_filtrado.csv", row.names = FALSE)

# Mostrar primeras filas del dataset filtrado
head(data_filtrado)
```

```{r}
str( data_filtrado)
```

```{r}
# Variables num茅ricas en el dataset
numeric_vars <- names(data_filtrado)[sapply(data_filtrado, is.numeric)]

# Graficar histogramas para cada variable num茅rica
par(mfrow = c(3, 3))  # Organizar en una matriz de 3x3
for (var in numeric_vars) {
  hist(data_filtrado[[var]], main = paste("Histograma de", var), col = "skyblue", border = "white")
}

```

# 3. Implementar `class.weights` para ajustar el desbalance de clases.

```{r}
# Convertir la variable objetivo a factor (si no lo est谩)
data_filtrado$ActivityType <- as.factor(data_filtrado$ActivityType)

# 1 Convertir Herzios a num茅rico
data_filtrado <- data_filtrado %>%
  mutate(herzios = as.numeric(herzios))

# Verificar que Herzios ahora es num茅rico
str(data_filtrado$herzios)
summary(data_filtrado$herzios)
```

```{r}
# Identificar solo las columnas num茅ricas (excluyendo `ActivityType`)
num_cols <- sapply(data_filtrado, is.numeric)

# Aplicar Min-Max Scaling SOLO a las columnas num茅ricas
preproc <- preProcess(data_filtrado[, num_cols], method = c("range"))
data_scaled <- predict(preproc, data_filtrado[, num_cols])

# Volver a agregar la variable objetivo `ActivityType`
data_scaled$ActivityType <- data_filtrado$ActivityType

# Verificar la estructura del dataset escalado
str(data_scaled)
summary(data_scaled)
```

```{r}
# Verificar si hay NA despu茅s del escalado
print(" 驴Hay valores NA despu茅s del escalado?")
print(any(is.na(data_scaled)))  # Debe ser FALSE

# Verificar si las variables est谩n en el rango correcto [0,1]
summary(data_scaled)
```

```{r}

# 1 Calcular pesos inversamente proporcionales al tama帽o de cada clase
class_counts <- table(data_scaled$ActivityType)
class_weights <- 1 / class_counts

# 2 Normalizar dividiendo por el m谩ximo peso
class_weights <- class_weights / max(class_weights)

# 3 Asignar nombres a los pesos
names(class_weights) <- names(class_counts)

# Ver los pesos normalizados
print(class_weights)

```

```{r}
print(class_weights)
```

```{r}
set.seed(123)
trainIndex <- createDataPartition(data_scaled$ActivityType, p = 0.8, list = FALSE)
train_data <- data_scaled[trainIndex, ]
test_data <- data_scaled[-trainIndex, ]
```

```{r}
print(colnames(train_data))
print(colnames(test_data))

```

```{r}
print(table(train_data$ActivityType))
print(table(test_data$ActivityType))

```

# 4. Entrenar Modelo Kermel Radial:

## 4.1 SVM con Kernel: Radial y pesos inversamente proporcionales al tama帽o de cada clase.

```{r}
# Registrar el tiempo de inicio para el entrenamiento
start_time <- Sys.time()

# Entrenar el modelo SVM con kernel radial y pesos ajustados
svm_model <- svm(ActivityType ~ ., data = train_data, kernel = "radial", 
                 cost = 1, gamma = 0.01, class.weights = class_weights)

# Registrar el tiempo de finalizaci贸n del entrenamiento
end_time <- Sys.time()

# Calcular el tiempo de entrenamiento
training_time <- end_time - start_time
cat("Tiempo de entrenamiento SVM:", training_time, "\n")

```

```{r}
# Registrar el tiempo de inicio para las predicciones
start_time_pred <- Sys.time()

# Hacer predicciones con el modelo corregido
pred_adjusted <- predict(svm_model, test_data)

# Registrar el tiempo de finalizaci贸n de las predicciones
end_time_pred <- Sys.time()

# Calcular el tiempo de las predicciones
prediction_time <- end_time_pred - start_time_pred
cat("Tiempo para hacer las predicciones:", prediction_time, "\n")
```

```{r}
# Evaluar el modelo con bias ajustado
conf_matrix_adjusted <- confusionMatrix(pred_adjusted, test_data$ActivityType)
print(conf_matrix_adjusted)

# Extraer m茅tricas espec铆ficas
precision <- conf_matrix$byClass[, "Pos Pred Value"]  # Precisi贸n por clase
recall <- conf_matrix$byClass[, "Sensitivity"]        # Recall por clase
f1_score <- 2 * (precision * recall) / (precision + recall)  # F1-score

#  Mostrar resultados de precisi贸n, recall y F1-score
metrics_results <- data.frame(Class = levels(test_data$ActivityType),
                              Precision = precision,
                              Recall = recall,
                              F1_Score = f1_score)

print(metrics_results)

```

```{r}
library(FactoMineR)
library(factoextra)
library(ggplot2)

# Aplicar PCA para reducir la dimensionalidad (sin incluir la columna ActivityType)
pca_model <- PCA(data_scaled %>% select(-ActivityType), graph = FALSE)

# Extraer los dos primeros componentes principales
pca_data <- as.data.frame(pca_model$ind$coord[, 1:2])  # Solo PC1 y PC2
colnames(pca_data) <- c("PC1", "PC2")

# Agregar las clases reales y predichas
pca_data$Clase_Real <- data_scaled$ActivityType  # Clases reales
pca_data$Predicci贸n <- predict(svm_model_combined, data_scaled)  # Predicciones del modelo

# Graficar PCA con predicciones
ggplot(pca_data, aes(x = PC1, y = PC2, color = Predicci贸n, shape = Clase_Real)) +
  geom_point(alpha = 0.7, size = 2) +
  labs(title = "Separaci贸n de Clases con PCA en SVM - Peso Inverso",
       x = "PC1",
       y = "PC2") +
  theme_minimal()

```

Se puede notar una buena separaci贸n en algunas clases (`Andando`, `Coche_urbano`, `Bicicleta`), lo cual indica que hay informaci贸n relevante en las variables seleccionadas. Sin embargo, hay solapamiento entre algunas clases, como Autob煤s, Coche_autopista y Bicicleta, lo que podr铆a generar errores de clasificaci贸n. `Avi贸n` parece estar m谩s disperso, lo que sugiere que podr铆a beneficiarse de pesos m谩s fuertes o de un modelo m谩s flexible.

## 4.2 SVM con Kernel: Radial y pesos manual.

En vista de los resultados, se realizar谩 una prueba manual de los pesos.

```{r}
# Aplciar nuevos pesos
class_weights_pesado <- c("Andando" = 10, "Autobus" = 15, "Avion" = 60, 
                   "Bicicleta" = 5, "Coche_autopista" = 10, "Coche_urbano" = 1)

# Normalizaci贸n para que la suma de los pesos sea 1
class_weights_pesadp <- class_weights_pesado / sum(class_weights_pesado)

print(class_weights_pesado)  # Revisar los nuevos pesos normalizados

```

```{r}
# Registrar el tiempo de inicio para el entrenamiento
start_time <- Sys.time()
svm_model <- svm(ActivityType ~ ., data = train_data, kernel = "radial", 
                 cost = 0.1, gamma = 0.001, class.weights = class_weights_pesado)
# Registrar el tiempo de finalizaci贸n del entrenamiento
end_time <- Sys.time()

# Calcular el tiempo de entrenamiento
training_time <- end_time - start_time
cat("Tiempo de entrenamiento SVM:", training_time, "\n")

```

```{r}
pred <- predict(svm_model, test_data)

# Matriz de confusi贸n
conf_matrix <- confusionMatrix(pred, test_data$ActivityType)
print(conf_matrix)

# Extraer m茅tricas espec铆ficas
precision <- conf_matrix$byClass[, "Pos Pred Value"]  # Precisi贸n por clase
recall <- conf_matrix$byClass[, "Sensitivity"]        # Recall por clase
f1_score <- 2 * (precision * recall) / (precision + recall)  # F1-score

#  Mostrar resultados de precisi贸n, recall y F1-score
metrics_results <- data.frame(Class = levels(test_data$ActivityType),
                              Precision = precision,
                              Recall = recall,
                              F1_Score = f1_score)

print(metrics_results)

```

```{r}
library(ggplot2)

# Generar predicciones en los datos de prueba
pred <- predict(svm_model_combined, test_data)

# Asegurar que test_data solo tiene variables num茅ricas antes de PCA
test_data_numeric <- test_data %>%
  select(-ActivityType) %>%
  mutate_if(is.character, as.numeric)  # Convertir caracteres a num茅ricos si hay errores

# Aplicar PCA a los datos de prueba
pca_result <- prcomp(scale(test_data_numeric))

# Crear un dataframe con los resultados del PCA y las predicciones del modelo
pca_data <- data.frame(
  PC1 = pca_result$x[, 1], 
  PC2 = pca_result$x[, 2], 
  Predicci贸n = pred,  # Agregamos la predicci贸n del modelo
  Clase_Real = test_data$ActivityType  # Agregamos la clase real
)

# Graficar la separaci贸n de clases usando PCA (seg煤n la predicci贸n del modelo)
ggplot(pca_data, aes(x = PC1, y = PC2, color = Predicci贸n, shape = Clase_Real)) +
  geom_point(alpha = 0.6, size = 2) +  
  labs(title = "Separaci贸n de Clases con PCA en SVM - Peso Manual",
       x = "PC1",
       y = "PC2") +
  theme_minimal()

```

Se compararon dos estrategias de ajuste de pesos en un modelo SVM para la clasificaci贸n de tipos de transporte: pesos inversos, ajustados seg煤n la frecuencia de las clases, y pesos manuales, definidos por criterio experto. Ambos enfoques lograron una alta precisi贸n global **(98.51% para pesos inversos y 98.33% para pesos manuales),** con un rendimiento 贸ptimo en las clases mayoritarias como Andando, Bicicleta, Coche Autopista y Coche Urbano. Sin embargo, los pesos inversos mostraron una ligera mejora en la clasificaci贸n de las clases minoritarias, reduciendo la confusi贸n entre Autob煤s y Avi贸n. **En particular, con pesos inversos, solo 15 instancias de Autob煤s fueron clasificadas err贸neamente como Avi贸n, mientras que con pesos manuales esta confusi贸n aument贸 a 24 instancias.**

El an谩lisis de PCA tambi茅n revel贸 que los pesos inversos permitieron una mejor agrupaci贸n de clases con menor solapamiento en comparaci贸n con los pesos manuales. Aunque ambos m茅todos ofrecen un desempe帽o s贸lido, los pesos inversos optimizan la diferenciaci贸n de clases menos representadas, mientras que los pesos manuales pueden ser m谩s adecuados cuando se busca un ajuste basado en conocimiento experto. Para mejorar la clasificaci贸n, se recomienda realizar una nueva optimizaci贸n de hiperpar谩metros y ajustar los pesos de Autob煤s y Avi贸n, con el fin de reducir a煤n m谩s los errores en estas clases.

## 4.3 SVM con Kernel: Radial y pesos combinados

En lugar de elegir solo una estrategia, podemos:

1.  **Promediar** los pesos manuales y los pesos inversos (`class.weights`).

2.  **Ajustar los pesos manuales multiplic谩ndolos por un factor basado en la frecuencia inversa de cada clase**.

3.  **Escalar los pesos inversos para evitar valores extremos y combinarlos con los manuales**.

```{r}
# Normalizaci贸n para que la suma de los pesos sea 1
class_weights_pesado <- class_weights_pesado / sum(class_weights_pesado)

print(class_weights_pesado)  # Revisar los nuevos pesos no
```

```{r}
#Promediamos los pesos calculados autom谩ticamente y los manuales:
class_weights_combined <- (class_weights + class_weights_pesado) / 2

```

```{r}
#M茅todo de Ajuste por Factor Escalado
scaling_factor <- 0.5 + (class_weights - min(class_weights)) / (max(class_weights) - min(class_weights))
class_weights_combined <- class_weights_pesado * scaling_factor

class_weights_combined <- class_weights_pesado * 0.75 + class_weights * 0.25

```

```{r}
# Registrar el tiempo de inicio para el entrenamiento
start_time <- Sys.time()
svm_model_combined <- svm(ActivityType ~ ., data = train_data, 
                          kernel = "radial", cost = 1, gamma = 0.01, 
                          class.weights = class_weights_combined)

# Registrar el tiempo de finalizaci贸n del entrenamiento
end_time <- Sys.time()

# Calcular el tiempo de entrenamiento
training_time <- end_time - start_time
cat("Tiempo de entrenamiento SVM:", training_time, "\n")

```

```{r}
pred_2 <- predict(svm_model_combined, test_data)

# Matriz de confusi贸n
conf_matrix_2 <- confusionMatrix(pred_2, test_data$ActivityType)
print(conf_matrix_2)

# Extraer m茅tricas espec铆ficas
precision <- conf_matrix_2$byClass[, "Pos Pred Value"]  # Precisi贸n por clase
recall <- conf_matrix_2$byClass[, "Sensitivity"]        # Recall por clase
f1_score <- 2 * (precision * recall) / (precision + recall)  # F1-score

#  Mostrar resultados de precisi贸n, recall y F1-score
metrics_results_2 <- data.frame(Class = levels(test_data$ActivityType),
                              Precision = precision,
                              Recall = recall,
                              F1_Score = f1_score)

print(metrics_results_2)
```

```{r}
# Generar predicciones en los datos de prueba
predictions <- predict(svm_model_combined, test_data)

```

```{r}
library(ggplot2)
library(ggfortify)

# Generar predicciones en los datos de prueba
pred <- predict(svm_model_combined, test_data)

# Asegurar que test_data solo tiene variables num茅ricas antes de PCA
test_data_numeric <- test_data %>%
  select(-ActivityType) %>%
  mutate_if(is.character, as.numeric)  # Convertir caracteres a num茅ricos si es necesario

# Aplicar PCA a los datos de prueba
pca_result <- prcomp(test_data_numeric, scale. = TRUE)

# Crear un dataframe con los resultados del PCA y las predicciones del modelo
pca_data <- data.frame(
  PC1 = pca_result$x[, 1], 
  PC2 = pca_result$x[, 2], 
  Predicci贸n = pred,  # Agregamos la predicci贸n del modelo
  Clase_Real = test_data$ActivityType  # Agregamos la clase real
)

# Graficar PCA con predicciones del modelo combinado
ggplot(pca_data, aes(x = PC1, y = PC2, color = Predicci贸n, shape = Clase_Real)) +
  geom_point(alpha = 0.6, size = 2) +
  labs(title = "Separaci贸n de Clases con PCA en SVM - Peso Combinado",
       x = "PC1",
       y = "PC2") +
  theme_minimal()

```

Se evaluaron tres estrategias de ajuste de pesos en el modelo SVM para la clasificaci贸n de tipos de transporte: pesos manuales, pesos inversos y una combinaci贸n de ambos. Los resultados muestran que todos los enfoques lograron una alta precisi贸n global (por encima del 98%), pero con diferencias clave en la capacidad de clasificaci贸n de clases minoritarias como Autob煤s y Avi贸n.

El m茅todo de **pesos manuales** permiti贸 un mejor control de la clasificaci贸n global, con una precisi贸n del 98.33%. Sin embargo, present贸 mayor confusi贸n en la diferenciaci贸n entre Autob煤s y Avi贸n, con 24 instancias de Autob煤s clasificadas incorrectamente como Avi贸n y un Recall de 0.8527 para Avi贸n.

El **m茅todo de pesos inversos** mejor贸 la detecci贸n de clases menos representadas, aumentando el Recall de Avi贸n a 0.8466, pero con una leve p茅rdida de precisi贸n en Autob煤s (0.8615). Aunque ayud贸 a equilibrar el impacto de clases minoritarias, el riesgo de falsos positivos en otras clases aument贸 ligeramente.

La **estrategia combinada** logr贸 la mejor precisi贸n global (98.37%) y un balance entre estabilidad y diferenciaci贸n de clases minoritarias. Aunque persisti贸 cierta confusi贸n entre Autob煤s y Avi贸n (22 instancias de Autob煤s clasificadas como Avi贸n), el Recall de Avi贸n mejor贸 a 0.8650 sin afectar significativamente las clases mayoritarias. Adem谩s, el an谩lisis de PCA mostr贸 una mejor separaci贸n de las clases en comparaci贸n con los otros enfoques.

### **Conclusi贸n**

El enfoque de pesos combinados es el m谩s equilibrado, ya que logra una alta precisi贸n global y mejora la identificaci贸n de clases menos representadas sin sacrificar la estabilidad en la clasificaci贸n general. Sin embargo, a煤n existen oportunidades de mejora, particularmente en la separaci贸n entre Autob煤s y Avi贸n. Para optimizar a煤n m谩s el modelo, se recomienda ajustar los pesos espec铆ficos de estas clases y realizar una nueva b煤squeda de hiperpar谩metros en SVM.

Para mejorar esta clasificaci贸n, se recomienda **ajustar nuevamente los pesos manuales**, aumentando la penalizaci贸n por errores en `Autob煤s` y `Avi贸n`, y realizar **una nueva b煤squeda de hiperpar谩metros (`cost`, `gamma`)** en el modelo SVM para optimizar su capacidad de separaci贸n

### 4.3 Busqueda del mejor modelo

La **b煤squeda de hiperpar谩metros** es un proceso esencial en el desarrollo de modelos de Machine Learning, cuyo objetivo es encontrar la combinaci贸n m谩s adecuada de par谩metros que maximice el rendimiento del modelo. En el caso de un **Support Vector Machine (SVM)** con kernel radial, los par谩metros m谩s relevantes son:

-   **`C`**: Es el par谩metro de penalizaci贸n que controla la compensaci贸n entre margen y los errores de clasificaci贸n. Un valor bajo permite m谩s errores en la clasificaci贸n, mientras que un valor alto obliga al modelo a ajustarse m谩s estrictamente a los datos, lo que puede resultar en sobreajuste.

-   **`sigma` (conocido como `gamma`)**: Este par谩metro regula la forma del kernel radial, afectando c贸mo se miden las distancias entre las muestras. Un valor peque帽o de `sigma` hace que el modelo sea m谩s suave y generalice mejor, mientras que un valor grande puede resultar en un modelo que se ajusta demasiado a los datos de entrenamiento, reduciendo su capacidad de generalizaci贸n.

### **Pasos para la B煤squeda de Hiperpar谩metros:**

1.  **Definici贸n de la Malla de Hiperpar谩metros:** El primer paso en la b煤squeda de los mejores par谩metros es definir una **malla de hiperpar谩metros**. Esta malla consiste en un conjunto de valores posibles para `C` y `sigma` que el modelo probar谩 durante el proceso de entrenamiento. La malla se elige en funci贸n de los valores que se consideran m谩s relevantes o que se sabe que pueden ofrecer buenos resultados seg煤n el tipo de problema y los datos.

2.  **Estrategia de Validaci贸n Cruzada:** Para evaluar la eficacia de cada combinaci贸n de hiperpar谩metros, se utiliza **validaci贸n cruzada**. Este m茅todo divide el conjunto de datos en varios subconjuntos o "pliegues". El modelo se entrena en algunos de estos subconjuntos y se eval煤a en los otros. Esto se repite varias veces para asegurar que el modelo se eval煤e de manera robusta y no se sobreajuste a un 煤nico conjunto de datos. La validaci贸n cruzada ayuda a obtener una estimaci贸n m谩s confiable del rendimiento del modelo.

    En este caso, se utiliz贸 una **validaci贸n cruzada de 10 pliegues**, lo que significa que el conjunto de datos se divide en 10 partes, y el modelo se entrena y eval煤a 10 veces, asegurando que todas las muestras se utilicen tanto para entrenar como para evaluar el modelo.

3.  **Entrenamiento con B煤squeda de Hiperpar谩metros:** Durante el proceso de entrenamiento, el modelo se ajusta repetidamente utilizando cada combinaci贸n de valores de `C` y `sigma` definida en la malla de hiperpar谩metros. Cada combinaci贸n se eval煤a a trav茅s de la validaci贸n cruzada, y el rendimiento del modelo se calcula para determinar cu谩l de las combinaciones proporciona el mejor resultado en t茅rminos de precisi贸n, recall, o cualquier otra m茅trica relevante.

4.  **Paralelizaci贸n del Proceso:** Dado que el proceso de b煤squeda de hiperpar谩metros puede ser computacionalmente costoso, especialmente cuando se utiliza validaci贸n cruzada con m煤ltiples combinaciones de par谩metros, **paralelizaci贸n** es una t茅cnica clave para acelerar el proceso. Mediante la paralelizaci贸n, se distribuyen las cargas de trabajo entre m煤ltiples n煤cleos del procesador, lo que permite que las pruebas de diferentes combinaciones de hiperpar谩metros se realicen simult谩neamente, reduciendo significativamente el tiempo total de ejecuci贸n.

5.  **Selecci贸n de la Mejor Combinaci贸n de Hiperpar谩metros:** Una vez que se completa la b煤squeda, se selecciona el conjunto de hiperpar谩metros que ha mostrado el mejor rendimiento en t茅rminos de la m茅trica de evaluaci贸n. El modelo final es entrenado utilizando esta combinaci贸n 贸ptima de par谩metros y se utiliza para hacer predicciones sobre nuevos datos.

6.  **Liberaci贸n de Recursos del Sistema:** Despu茅s de completar el proceso de entrenamiento y selecci贸n del modelo, es importante liberar los recursos del sistema que se utilizaron para la paralelizaci贸n. Esto implica cerrar el cl煤ster de n煤cleos y volver al modo secuencial para evitar sobrecargar el sistema.

```{r}
library(caret)
library(e1071)
library(doParallel)  # Para paralelizaci贸n

# 1  Configurar los n煤cleos para paralelizaci贸n
num_cores <- detectCores() - 2  # Dejar 2 n煤cleos libres para evitar bloqueos
cl <- makeCluster(num_cores)  # Crear cl煤ster
registerDoParallel(cl)  # Activar paralelizaci贸n

# 1 Definir la malla de hiperpar谩metros correctamente
tune_grid <- expand.grid(
  sigma = c(0.0001, 0.001, 0.01, 0.1, 1),  # Cambiar 'gamma' por 'sigma'
  C = c(0.01, 0.1, 1, 10)
)

# 2  Configurar validaci贸n cruzada con paralelizaci贸n
train_control <- trainControl(method = "cv", number = 10, allowParallel = TRUE)

# 3 Registrar el tiempo de inicio
start_time <- Sys.time()

# 4 Entrenar el modelo SVM con Grid Search paralelizado
svm_tune <- train(ActivityType ~ ., data = train_data, 
                   method = "svmRadial",
                   trControl = train_control,
                   tuneGrid = tune_grid,
                   class.weights = class_weights_combined)

# 5 Registrar el tiempo de fin
end_time <- Sys.time()

# Calcular el tiempo total de entrenamiento
training_time <- end_time - start_time
cat("Tiempo total de entrenamiento SVM con Grid Search:", training_time, "\n")

# 6 Apagar el cl煤ster despu茅s del entrenamiento
stopCluster(cl)
registerDoSEQ()  # Volver al modo secuencial normal
```

```{r}
# 6 Imprimir los mejores hiperpar谩metros
print(svm_tune$bestTune)

# 7 Visualizar resultados de Grid Search
plot(svm_tune)

```

```{r}
library(viridis)

# 9 **Heatmap de Accuracy en funci贸n de C y Sigma para SVM Radial**
# Ordenar resultados por accuracy
tune_results_radial <- svm_tune$results %>% 
  select(C, sigma, Accuracy) %>% 
  arrange(desc(Accuracy))

# Crear Heatmap con colores equilibrados y etiquetas adaptadas al fondo
ggplot(tune_results_radial, aes(x = factor(sigma), y = factor(C), fill = Accuracy)) +
  geom_tile() +
  scale_fill_viridis_c(option = "cividis", direction = -1, name = "Accuracy") +  
  geom_text(aes(label = round(Accuracy, 4), 
                color = ifelse(Accuracy > 0.7, "black", "white")), 
            size = 5, fontface = "bold") +  # Tama帽o m谩s grande para mayor visibilidad
  scale_color_manual(values = c("white", "black"), guide = "none") +  
  labs(title = "Accuracy en funci贸n de C y Sigma (SVM Radial)",
       x = "Sigma",
       y = "C") +
  theme_minimal(base_size = 14) +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# Capturar el tiempo de inicio del entrenamiento
start_train_time <- Sys.time()

# Extraer los mejores hiperpar谩metros encontrados en Grid Search
best_C <- svm_tune$bestTune$C
best_gamma <- svm_tune$bestTune$sigma

# Entrenar el modelo final con los mejores hiperpar谩metros
svm_final <- svm(ActivityType ~ ., data = train_data, kernel = "radial",
                 cost = 1, gamma = 0.1, class.weights = class_weights_combined)

# Capturar el tiempo de finalizaci贸n del entrenamiento
end_train_time <- Sys.time()
train_duration <- end_train_time - start_train_time

# Capturar el tiempo de inicio de la predicci贸n
start_pred_time <- Sys.time()

# Hacer predicciones en el conjunto de prueba 
pred_final <- predict(svm_final, test_data)

# Capturar el tiempo de finalizaci贸n de la predicci贸n
end_pred_time <- Sys.time()
pred_duration <- end_pred_time - start_pred_time

# Imprimir los tiempos de ejecuci贸n
print(paste("Tiempo de entrenamiento:", train_duration))
print(paste("Tiempo de predicci贸n:", pred_duration))

```

```{r}
# Evaluar modelo con Matriz de Confusi贸n
conf_matrix <- confusionMatrix(pred_final, test_data$ActivityType)

# Mostrar matriz de confusi贸n
print(conf_matrix)

# Extraer m茅tricas espec铆ficas
precision <- conf_matrix$byClass[, "Pos Pred Value"]  # Precisi贸n por clase
recall <- conf_matrix$byClass[, "Sensitivity"]        # Recall por clase
f1_score <- 2 * (precision * recall) / (precision + recall)  # F1-score

# Mostrar resultados
print(data.frame(Class = levels(test_data$ActivityType),
                 Precision = precision,
                 Recall = recall,
                 F1_Score = f1_score))
```

```{r}
library(ggplot2)
library(ggfortify)

# Generar predicciones en los datos de prueba
pred <- predict(svm_model_combined, test_data)

# Asegurar que test_data solo tiene variables num茅ricas antes de PCA
test_data_numeric <- test_data %>%
  select(-ActivityType) %>%
  mutate_if(is.character, as.numeric)  # Convertir caracteres a num茅ricos si es necesario

# Aplicar PCA a los datos de prueba
pca_result <- prcomp(test_data_numeric, scale. = TRUE)

# Crear un dataframe con los resultados del PCA y las predicciones del modelo
pca_data <- data.frame(
  PC1 = pca_result$x[, 1], 
  PC2 = pca_result$x[, 2], 
  Predicci贸n = pred_final,  # Agregamos la predicci贸n del modelo
  Clase_Real = test_data$ActivityType  # Agregamos la clase real
)

# Graficar PCA con clases reales
autoplot(pca_result, data = test_data, colour = "ActivityType") +
  labs(title = "Separaci贸n de Clases con PCA en SVM - Clases Reales")

# Graficar PCA con predicciones del modelo combinado
ggplot(pca_data, aes(x = PC1, y = PC2, color = Predicci贸n, shape = Clase_Real)) +
  geom_point(alpha = 0.6, size = 2) +
  labs(title = "Separaci贸n de Clases con PCA en SVM - Peso Combinado - Mejor Parametro",
       x = "PC1",
       y = "PC2") +
  theme_minimal()

```

# 5. Resultados:

Tras la optimizaci贸n de hiperpar谩metros utilizando validaci贸n cruzada, se identific贸 que el mejor modelo seg煤n Grid Search suger铆a **C=10** y **gamma=0.1**. Sin embargo, al analizar la curva de validaci贸n cruzada y los resultados en el conjunto de prueba, se observ贸 que estos valores generaban un desempe帽o **casi perfecto** en todas las m茅tricas de evaluaci贸n. Aunque esto puede parecer ideal, es una clara se帽al de **sobreajuste (overfitting)**, donde el modelo memoriza patrones espec铆ficos de los datos de entrenamiento en lugar de aprender reglas generalizables. Un modelo sobreajustado tiende a perder precisi贸n cuando se enfrenta a nuevos datos, lo que podr铆a comprometer su efectividad en aplicaciones reales.

Por esta raz贸n, se opt贸 por **ajustar manualmente los hiperpar谩metros**, seleccionando **C=1** y **gamma=0.1**, lo que permiti贸 mantener un alto rendimiento sin comprometer la capacidad de generalizaci贸n. La elecci贸n de un valor m谩s bajo de C evita que el modelo se vuelva demasiado r铆gido, permiti茅ndole manejar mejor la variabilidad en los datos. Este ajuste manual se aline贸 con la curva de validaci贸n cruzada, que mostr贸 que incrementar **C** m谩s all谩 de **1** no proporcionaba beneficios significativos. En conclusi贸n, la selecci贸n final de **C=1, gamma=0.1** equilibra precisi贸n y capacidad de generalizaci贸n, asegurando un modelo robusto y menos propenso al sobreajuste.

El desempe帽o del modelo alcanz贸 una **precisi贸n global del 99.8%**, con un **Kappa de 0.9972**, indicando una excelente concordancia entre predicciones y valores reales. En t茅rminos de sensibilidad y especificidad, la mayor铆a de las clases obtuvieron valores cercanos a 1.0, asegurando una correcta clasificaci贸n de los datos. No obstante, se observ贸 un leve error en la clase "Coche urbano", con una sensibilidad de **0.9959**, indicando que algunas muestras fueron clasificadas incorrectamente.

Los valores de **Precision, Recall y F1-Score** reflejan el alto rendimiento del modelo. Por ejemplo, "Andando", "Bicicleta" y "Coche autopista" alcanzaron un **F1-Score de 1.0**, evidenciando una clasificaci贸n perfecta. En contraste, "Autob煤s" mostr贸 un ligero descenso en precisi贸n (**0.9816**), aunque su Recall fue **1.0**, lo que indica que todas las instancias reales de esta clase fueron correctamente detectadas. Este desempe帽o sugiere que el modelo optimizado logra una separaci贸n efectiva entre las clases, con un margen m铆nimo de error. Sin embargo, considerando que los resultados son casi perfectos, podr铆a existir **riesgo de sobreajuste (overfitting)**, por lo que se recomienda validar el modelo en un conjunto de datos externo para garantizar su generalizaci贸n.

## Tabla Resumen de SVM - Kernel Radial:

![](images/comparacion_modelos_svm_actualizada.png){width="688"}
