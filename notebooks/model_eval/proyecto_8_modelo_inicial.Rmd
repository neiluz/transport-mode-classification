---
title: "Prediccion de Tipo de Transporte - Proyecto de Transporte"
output: html_notebook
---

### General: Objetivos del Proyecto y Definici√≥n de Variables

El objetivo principal de este proyecto es desarrollar un modelo basado en **M√°quinas de Vectores de Soporte (SVM)** para predecir el **modo de transporte** utilizado por un individuo en funci√≥n de los datos recopilados por sensores de dispositivos m√≥viles. Se busca analizar c√≥mo las diferentes se√±ales captadas por el aceler√≥metro, gir√≥scopo, bar√≥metro, GPS y magnet√≥metro pueden ser utilizadas para inferir con precisi√≥n el medio de transporte en uso.

Para lograr esto, se cuenta con un conjunto de datos que incluye:

1.  **Registro Temporal**

    -   Cada observaci√≥n est√° asociada a un instante de tiempo espec√≠fico.

2.  **Datos de Movimiento y Orientaci√≥n**

    -   **Aceler√≥metro**: Componentes X, Y, Z del vector aceleraci√≥n.

    -   **Gir√≥scopo**: Velocidad angular en los ejes X, Y, Z y su derivada.

    -   **Matriz de Rotaci√≥n y Cuaterniones**: Representan la orientaci√≥n tridimensional del dispositivo.

3.  **Datos de Ubicaci√≥n y Contexto**

    -   **GPS**: Coordenadas de latitud y longitud, velocidad, altitud y rumbo.

    -   **Presi√≥n Atmosf√©rica**: Valores obtenidos del bar√≥metro, junto con la altitud relativa.

    -   **Campo Magn√©tico Terrestre**: Medici√≥n en los ejes X, Y, Z.

4.  **Variables Categ√≥ricas**

    -   **Modo de Transporte**: La categor√≠a que se busca predecir (caminar, bicicleta, autom√≥vil, etc.).

    -   **Nivel de Confianza**: Un indicador de la precisi√≥n estimada para la clasificaci√≥n del transporte en los datos originales.

### Objetivo Notebook:

El objetivo de este notebook es realizar una preselecci√≥n de variables clave para la construcci√≥n de un modelo basado en M√°quinas de Vectores de Soporte (SVM) que permita predecir el modo de transporte a partir de datos de sensores de dispositivos m√≥viles.

# **1. Carga de librer√≠as**

```{r}
# Lista de paquetes necesarios
necessary_packages <- c("dplyr", "caret", "e1071", "robustbase", "ggplot2", "data.table", "pROC","doParallel" )

# Instalar paquetes que no est√°n instalados
new_packages <- necessary_packages[!(necessary_packages %in% installed.packages()[, "Package"])]
if (length(new_packages) > 0) {
  install.packages(new_packages)
}

# Cargar todos los paquetes
lapply(necessary_packages, library, character.only = TRUE)
```

```{r}
# Cargar las librer√≠as necesarias
library(caret)      # Para divisi√≥n estratificada y evaluaci√≥n de modelos
library(scales)     # Para Min-Max Scaling
library(e1071)      # Para entrenar SVM
library(randomForest)  # Para obtener la importancia de las variables
library(dplyr)      # Para manipulaci√≥n de datos
# Cargar la librer√≠a
library(visdat)
# Cargar la librer√≠a
library(tidyr)
# Cargar el paquete 'car'
library(car)
library(ggplot2)
library(stringr) #Cambiar variables
```

# 2. Cargar el dataset

```{r}
# Ruta del archivo CSV (modificar seg√∫n tu sistema)
ruta_dataset <- "C:/Users/Lenovo/Documents/IT Academy/Datos proyecto 8/proyect8/input_data/dataframes_modificado.csv"
data <- read.csv(ruta_dataset)


data <- read.csv(ruta_dataset)

# Resumen del dataset
cat("### Informaci√≥n General del Dataset")
dim(data) # Dimensiones del dataset
str(data) # Estructura del dataset

```

```{r}
summary(data) # Resumen estad√≠stico b√°sico
```

## 2.1 Adecuaci√≥n del dataset

```{r}
# Usando la funci√≥n table()
actividad_count <- table(data$ActivityType)
print(actividad_count)

```

```{r}
# Eliminar la columna "ActivityConfidence"
data <- data[, !names(data) %in% "ActivityConfidence"]

# Crear la nueva columna "herzios" basada en "ActivityType"
data$herzios <- ifelse(data$ActivityType == "Avion", 10,
                    ifelse(data$ActivityType == "Coche autopista", 2,
                    ifelse(data$ActivityType == "Autobus", 50,
                    ifelse(data$ActivityType == "Bicleta", 50,
                    ifelse(data$ActivityType == "Andando", 100,
                    ifelse(data$ActivityType == "Coche Urbano 100", 100,
                    ifelse(data$ActivityType == "Coche Urbano 250", 250,
                    ifelse(data$ActivityType == "Coche carretera", 100, 0))))))))
```

```{r}
data %>%
  count(ActivityType, sort = TRUE)

# Reemplazar las categor√≠as 'Coche autopista' y 'Coche carretera' por 'Coche'
data <- data %>%
  mutate(ActivityType = str_replace(ActivityType, "Coche autopista|Coche carretera", "Coche_autopista"))

data <- data %>%
  mutate(ActivityType = str_replace(ActivityType, "Coche Urbano 250|Coche Urbano 100", "Coche_urbano"))

data <- data %>%
  mutate(ActivityType = str_replace(ActivityType, "Bicleta", "Bicicleta"))

# Verificar los primeros valores de ActivityType despu√©s del reemplazo
head(data$ActivityType)
```

```{r}
str(data)
```

# 3. An√°lisis de Datos

## 3.1 Detecci√≥n de Valores faltantes

Identificar valores faltantes es crucial porque pueden afectar el rendimiento del modelo predictivo. Este paso ayuda a decidir estrategias para imputar o manejar estos valores.

```{r}
cat("### An√°lisis de Valores Faltantes\n")
# Resumen de valores faltantes por columna
print(sapply(data, function(x) sum(is.na(x))))

# Visualizaci√≥n de valores faltantes mejorada
vis_miss(data) +
  ggtitle("Mapa de Valores Faltantes") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, size = 8), # Ajuste de las etiquetas del eje X
    axis.text.y = element_text(size = 10),                       # Ajuste de las etiquetas del eje Y
    plot.title = element_text(hjust = 0.5, size = 14)            # Centrar y ajustar tama√±o del t√≠tulo
  )

```

El an√°lisis muestra que no hay valores nulos en el dataset. Esto significa que todas las variables contienen informaci√≥n completa para las 816 observaciones registradas. Este resultado asegura que no ser√° necesario realizar t√©cnicas de imputaci√≥n de datos.

## 3.2 Detecci√≥n de Outliers Univariantes

Usaremos el rango intercuart√≠lico (IQR) para identificar outliers y calcular el porcentaje de valores extremos en cada variable num√©rica.

```{r}
# Extraer solo las columnas num√©ricas
num_data <- data %>% select(where(is.numeric))

if (ncol(num_data) > 0) {
  cat("### An√°lisis de Outliers\n")
  
  # C√°lculo de outliers por IQR
  outlier_detection <- num_data %>%
    summarise(across(everything(), ~ {
      q1 <- quantile(.x, 0.25, na.rm = TRUE)
      q3 <- quantile(.x, 0.75, na.rm = TRUE)
      iqr <- q3 - q1
      sum(.x < (q1 - 1.5 * iqr) | .x > (q3 + 1.5 * iqr), na.rm = TRUE) / length(.x) * 100
    }))
  
  # Transponer la tabla
  outlier_detection <- as.data.frame(t(outlier_detection))
  outlier_detection$Variable <- rownames(outlier_detection)
  rownames(outlier_detection) <- NULL
  
  # Reordenar las columnas
  outlier_detection <- outlier_detection %>%
    select(Variable, `V1`) %>%  # Mantiene "V1" como nombre original
    arrange(desc(`V1`))  # Ordenar de mayor a menor

  # Mostrar la tabla
  print(outlier_detection)

} else {
  cat("No hay columnas num√©ricas en el dataset.\n")
}

```

**Visualizaci√≥n de Outliers**

Utilizaremos boxplots para visualizar los outliers en cada variable num√©rica.

```{r}
if (ncol(num_data) > 0) {
  # Transformar datos a formato largo
  num_data_long <- num_data %>%
    pivot_longer(cols = everything(), names_to = "Variable", values_to = "Valor")
  
  # Dividir las variables en grupos de 6
  variable_groups <- split(unique(num_data_long$Variable), ceiling(seq_along(unique(num_data_long$Variable)) / 6))

  for (group in variable_groups) {
    # Filtrar las variables del grupo actual
    group_data_long <- num_data_long %>% filter(Variable %in% group)
    
    # Crear los boxplots
    print(
      ggplot(group_data_long, aes(x = Variable, y = Valor)) +
        geom_boxplot(outlier.colour = "red", outlier.size = 1.5, fill = "lightblue") +
        theme_minimal() +
        labs(
          title = "Visualizaci√≥n de Outliers",
          x = "Variable",
          y = "Valores"
        ) +
        theme(
          plot.title = element_text(size = 8, hjust = 0.5),
          axis.text.x = element_text(angle = 0, hjust = 1)
        ) +
        facet_wrap(~ Variable, scales = "free", ncol = 3)  # Cambia "ncol" a 2 o 3 seg√∫n el dise√±o que prefieras
    )
  }
} else {
  cat("No hay variables num√©ricas en el dataset.\n")
}
```

## **3.3** Analisisis de Influencias

## 3.3.1. **Correlacion en el conjunto de datos**

```{r}
library(knitr)      # Para formatear tablas
library(kableExtra) # Para mejorar la presentaci√≥n


# Calcular la matriz de correlaci√≥n
cor_matrix <- cor(num_data, use = "complete.obs")

# Redondear para mejor visualizaci√≥n
cor_matrix_rounded <- round(cor_matrix, 2)

# Imprimir la matriz de correlaci√≥n en la consola
print(cor_matrix_rounded)

# Alternativamente, generar una tabla con kable si prefieres una salida m√°s ordenada

kable(cor_matrix_rounded, caption = "Tabla de Correlaciones (Excluyendo Variables No Relevantes)")
```

```{r}
library(ggplot2)
library(reshape2)

# Convertir la matriz en formato largo
corr_melted <- melt(cor_matrix)

# Crear el heatmap
ggplot(corr_melted, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "steelblue", high = "darkred", mid = "white", midpoint = 0, name = "Correlaci√≥n") +
  theme_minimal(base_size = 6) +  # Aumentar el tama√±o del texto
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, size = 10),
    axis.text.y = element_text(size = 10),
    plot.title = element_text(hjust = 0.5, size = 14),
    legend.text = element_text(size = 10),
    legend.title = element_text(size = 12)
  ) +
  labs(
    title = "Mapa de Calor de Correlaciones",
    x = "Variables",
    y = "Variables"
  ) +
  coord_fixed()
```

## **3.3.2 Colinealidad**

```{r}
library(dplyr)

# Verificar que el dataset existe
if (exists("data")) {
  # Filtrar las variables num√©ricas y eliminar la variable dependiente (ActivityType)
  num_data_filtered <- data %>%
    select(where(is.numeric)) %>%
    mutate(dummy_target = runif(nrow(.), 0, 1)) # Crear una variable dummy temporal

  # Validar si hay suficientes variables para calcular el modelo
  if (ncol(num_data_filtered) > 1) {
    # Crear un modelo de regresi√≥n con las variables predictoras
    vif_model <- lm(dummy_target ~ ., data = num_data_filtered)
    
    # Calcular los valores de VIF
    vif_values <- vif(vif_model)
    
    # Imprimir los valores de VIF
    print("### Factores de Inflaci√≥n de Varianza (VIF)")
    print(vif_values)
    
    # Identificar variables con alta colinealidad (VIF > 10 como umbral com√∫n)
    high_vif <- vif_values[vif_values > 10]
    if (length(high_vif) > 0) {
      cat("\nVariables con alta colinealidad (VIF > 10):\n")
      print(high_vif)
    } else {
      cat("\nNo se encontraron variables con alta colinealidad (VIF <= 10).\n")
    }
  } else {
    cat("No hay suficientes variables num√©ricas para calcular el VIF.\n")
  }
} else {
  cat("El dataset 'data' no existe en el entorno.\n")
}
```

> En el an√°lisis de los datos, hemos observado que algunas variables, como `qX`, `qY` y `gyroX.rad.s.`, est√°n fuertemente correlacionadas entre s√≠ y tambi√©n con otras variables clave del modelo, como las mediciones magn√©ticas (`magX.¬µT.`, `magY.¬µT.`). Esta alta colinealidad genera un aumento en los **Factores de Inflaci√≥n de Varianza (VIF)**, con varios valores superiores a 10. Esto indica que algunas de estas variables est√°n aportando la misma informaci√≥n, lo que provoca redundancia en el modelo.
>
> La presencia de estas variables altamente correlacionadas puede afectar la estabilidad y precisi√≥n de las predicciones. En particular, las variables relacionadas con las matrices de rotaci√≥n y el campo magn√©tico tienden a influir de manera similar, lo que dificulta que el modelo identifique correctamente las variables m√°s importantes.
>
> Para mejorar la precisi√≥n y estabilidad del modelo, ser√≠a recomendable eliminar estas variables colineales, como `qX`, `qY` y `gyroX.rad.s.`, as√≠ como las variables magn√©ticas. De esta forma, reducimos la redundancia, lo que permitir√° que el modelo funcione de manera m√°s eficiente y que los resultados sean m√°s f√°ciles de interpretar.

### 3.3.3. ANOVA

l an√°lisis de **Factor de Inflaci√≥n de Varianza (VIF)** revel√≥ la presencia de **alta colinealidad** entre varias variables, lo que indica redundancia y posible inestabilidad en el modelo. Para abordar esto, se aplica **ANOVA** con el fin de:

‚úÖ **Seleccionar solo las variables con diferencias significativas entre las clases de `ActivityType`**\
‚úÖ **Eliminar variables con VIF alto que no aporten informaci√≥n relevante**\
‚úÖ **Reducir la redundancia y mejorar la capacidad de generalizaci√≥n del modelo**

Se consideran significativas las variables con **p \< 0.05**, asegurando que solo aquellas que realmente influyen en la clasificaci√≥n sean retenidas. Esto optimiza el modelo, evitando sobreajuste y mejorando la interpretaci√≥n de los resultados.

```{r}
library(dplyr)
library(purrr)

num_vars <- names(data)[sapply(data, is.numeric)]
num_vars <- setdiff(num_vars, "ActivityType")


# Calcular ANOVA para todas las variables num√©ricas
anova_results <- map_dbl(num_vars, ~anova(lm(data[[.x]] ~ data$ActivityType))$`Pr(>F)`[1])

# Crear un dataframe con los resultados
anova_df <- data.frame(Variable = num_vars, P_Value = anova_results)

# Filtrar variables con p < 0.05 (significativas)
variables_significativas <- anova_df %>% filter(P_Value < 0.05) %>% arrange(P_Value)

# Mostrar las variables significativas
print(variables_significativas)

```

```{r}
library(ggplot2)

# Crear una nueva columna indicando si la variable es significativa
anova_df <- anova_df %>%
  mutate(Significativa = ifelse(P_Value < 0.05, "Significativa (p < 0.05)", "No significativa (p >= 0.05)"))

# Crear gr√°fico de barras
ggplot(anova_df, aes(x = reorder(Variable, -P_Value), y = -log10(P_Value), fill = Significativa)) +
  geom_bar(stat = "identity", position = "identity") +
  scale_fill_manual(values = c("Significativa (p < 0.05)" = "steelblue", "No significativa (p >= 0.05)" = "red")) +
  labs(title = "Resultados de ANOVA - Variables Significativas vs No Significativas",
       x = "Variables", y = "-log10(p-value)",
       fill = "Significancia") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  geom_hline(yintercept = -log10(0.05), linetype = "dashed", color = "gray")  # L√≠nea de referencia en p = 0.05

```

Para definir las variables m√°s relevantes en la predicci√≥n del tipo de transporte, se han utilizado los siguientes enfoques:

‚úÖ **1. ANOVA (An√°lisis de Varianza):** Se identificaron las variables con **p-valores menores a 0.05**, lo que indica que presentan diferencias significativas entre las clases de `ActivityType`.\
‚úÖ **2. VIF (Factor de Inflaci√≥n de la Varianza):** Se analizaron las variables con **VIF \> 10** para identificar posibles redundancias.\
‚úÖ **3. Validaci√≥n con Importancia en Random Forest (RF):** Se propone validar las variables seleccionadas a trav√©s del criterio `MeanDecreaseGini`, que permite medir la contribuci√≥n real de cada variable en la clasificaci√≥n.

## **3.4** Distribuci√≥n de las Clases en `ActivityType`

```{r}
# Crear un gr√°fico de barras para la variable 'target_variable' con un solo color
ggplot(data, aes(x = ActivityType)) + 
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Distribuci√≥n de las Clases en la Variable `ActivityType`", 
       x = "Clases", y = "Frecuencia") +
  theme_minimal()

```

> El gr√°fico muestra la distribuci√≥n de las clases en la variable objetivo `ActivityType`. Es evidente que existe un desbalance significativo en los datos, donde la clase `Coche_urbano` domina ampliamente con la mayor cantidad de observaciones, seguida por `Andando` y `Bicicleta`. En contraste, las clases `Avi√≥n` y `Coche_autopista` tienen una representaci√≥n mucho menor, lo que podr√≠a generar desaf√≠os para el modelo al clasificar estas clases minoritarias.
>
> ### **Implicaciones del Desbalance**
>
> 1.  **Riesgo de Sesgo hacia la Clase Mayoritaria:**\
>     El modelo puede sesgarse hacia la clase mayoritaria (`Coche_urbano`) durante el entrenamiento, ya que la mayor√≠a de los ejemplos pertenecen a esta clase. Esto podr√≠a conducir a una alta precisi√≥n global aparente, pero con un rendimiento deficiente en las clases minoritarias (`Avi√≥n`, `Coche_autopista`).
>
> 2.  **Impacto en M√©tricas como Sensibilidad y F1-score:**\
>     El desbalance puede afectar negativamente m√©tricas como la sensibilidad y el F1-score para las clases menos representadas, lo que es cr√≠tico en aplicaciones donde la detecci√≥n precisa de estas clases es importante.

# 4. Imputacion de Variables

## 4.1 Eliminacion de Variables

Las variables `qX`, `qY` y `qZ` ser√°n eliminadas debido a su alta correlaci√≥n con las **matrices de rotaci√≥n**. Estas variables aportan informaci√≥n redundante al modelo y, para evitar problemas de multicolinealidad, se ha decidido priorizar las **matrices de rotaci√≥n**, que ya encapsulan la informaci√≥n necesaria para describir la orientaci√≥n del objeto en movimiento.

Por otro lado, las variables asociadas al **campo magn√©tico** (`magX.¬µT.`, `magY.¬µT.`, `magZ.¬µT.`, `calMagX.¬µT.`, `calMagY.¬µT.`, `calMagZ.¬µT.`) tambi√©n ser√°n eliminadas, pero por un motivo distinto. Aunque estas variables no est√°n directamente relacionadas con las matrices de rotaci√≥n, el campo magn√©tico tiene un **impacto significativo en la clasificaci√≥n de los tipos de transporte**. Las se√±ales magn√©ticas pueden ser similares entre distintos medios de transporte, como coches, trenes o aviones, lo que puede generar confusi√≥n en el modelo. Al eliminar estas variables, se evita que el modelo dependa de estas se√±ales que pueden no ser determinantes para la tarea de clasificaci√≥n.

```{r}
# Eliminar las columnas especificadas del dataset
columns_to_remove <- c("qX", "qY", "qZ", "qW", "magX.¬µT.", "magY.¬µT.", "magZ.¬µT.", 
                       "calMagX.¬µT.", "calMagY.¬µT.", "calMagZ.¬µT.")

# Eliminar las columnas del dataset
data <- data[, !(colnames(data) %in% columns_to_remove)]

# Verificar las primeras filas despu√©s de eliminar las columnas
head(data)
```

## 4.2 Imputacion de Outliers

La imputaci√≥n mediante **winsorizaci√≥n** es un enfoque √∫til para tratar los outliers extremos en los datos. En este caso, se ha aplicado winsorizaci√≥n a las variables con m√°s del 10% de outliers, como `gyroZ.rad.s.`, `Roll.rads.`, `gyroX.rad.s.`, entre otras. Este proceso consiste en limitar los valores de las variables fuera de un rango espec√≠fico, utilizando los percentiles 1 y 99. De esta manera, los valores extremos son reemplazados por los valores m√°s cercanos en esos percentiles, lo que reduce el impacto de los outliers sin eliminar completamente los datos.

```{r}
# Funci√≥n para calcular outliers por IQR por cada grupo de ActivityType
calculate_outliers_by_activity <- function(df, group_col = "ActivityType") {
  df %>%
    group_by(!!sym(group_col)) %>%
    summarise(across(where(is.numeric), ~ {
      q1 <- quantile(.x, 0.25, na.rm = TRUE)
      q3 <- quantile(.x, 0.75, na.rm = TRUE)
      iqr <- q3 - q1
      outliers <- sum(.x < (q1 - 1.5 * iqr) | .x > (q3 + 1.5 * iqr), na.rm = TRUE)
      return(outliers / length(.x) * 100)  # Retornar el porcentaje de outliers
    })) %>%
    pivot_longer(cols = where(is.numeric),
                 names_to = "Variable", values_to = "Outliers (%)") %>%
    pivot_wider(names_from = ActivityType, values_from = `Outliers (%)`) %>%
    arrange(Variable)  # Reordenar por las variables
}

# Calcular outliers por cada tipo de actividad
outliers_by_activity <- calculate_outliers_by_activity(data)

# Mostrar los resultados
print(outliers_by_activity)

```

```{r}
# Variables y actividades que tienen m√°s del 10% de outliers
columns_to_impute <- c("gyroX.rad.s.", "gyroZ.rad.s.", "accelX.g.", "accelUserX.g.", "m21")
activities_to_impute <- c("Coche Urbano 100", "Coche autopista", "Avion", "Bicicleta")

# Funci√≥n para imputar outliers usando la mediana dentro de cada actividad
replace_outliers_by_activity_specific <- function(df, group_col = "ActivityType", outlier_threshold = 10) {
  df_no_outliers <- df
  df_no_outliers <- df_no_outliers %>%
    group_by(!!sym(group_col)) %>%
    mutate(across(all_of(columns_to_impute), ~ {
      Q1 <- quantile(.x, 0.25, na.rm = TRUE)
      Q3 <- quantile(.x, 0.75, na.rm = TRUE)
      IQR <- Q3 - Q1
      lower_limit <- Q1 - 1.5 * IQR
      upper_limit <- Q3 + 1.5 * IQR
      outlier_pct <- sum(.x < lower_limit | .x > upper_limit, na.rm = TRUE) / length(.x) * 100
      
      # Solo reemplazar los outliers si superan el umbral (10%)
      if (outlier_pct > outlier_threshold) {
        .[. < lower_limit | . > upper_limit] <- median(.x, na.rm = TRUE)
      }
      return(.)
    })) %>%
    ungroup()
  
  return(df_no_outliers)
}

# Filtrar solo las actividades con outliers altos
data_filtered <- data %>%
  filter(ActivityType %in% activities_to_impute)

# Aplicar imputaci√≥n de outliers en las actividades seleccionadas
data_no_outliers_activity_replaced_specific <- replace_outliers_by_activity_specific(data_filtered)

# Verificar los cambios despu√©s de reemplazar outliers
summary(data_no_outliers_activity_replaced_specific)
head(data_no_outliers_activity_replaced_specific)

```

```{r}
# 2. Asegurar que los datos originales y modificados se combinen correctamente sin duplicar
data_combined <- data %>%
  left_join(data_no_outliers_activity_replaced_specific %>%
              select(ActivityType, all_of(columns_to_impute)) %>%
              rename_with(~paste0(., "_imputed"), all_of(columns_to_impute)), 
            by = "ActivityType") %>%
  # Mantener las columnas originales si no fueron modificadas
  mutate(across(all_of(columns_to_impute), 
                ~ ifelse(is.na(get(paste0(cur_column(), "_imputed"))), .x, get(paste0(cur_column(), "_imputed"))), 
                .names = "{col}")) %>%
  # Eliminar las columnas imputadas que no necesitamos
  select(-ends_with("_imputed"))

# Verificar los cambios
summary(data_combined)
head(data_combined)
```

```{r}
# Verificar las columnas disponibles en el dataframe
str(data)

```

```{r}
# Guardar el dataset modificado en el directorio de trabajo actual
write.csv(data, "data_vars_imputadas.csv", row.names = FALSE)

# Mostrar el directorio de trabajo actual
cat("El dataset ha sido guardado en el directorio de trabajo actual:", getwd())

```

# 5. Escalado de Datos

Utilizamos **Min-Max Scaling, porque trabaja mejor con SVM**

```{r}
# Convertir las variables categ√≥ricas a factor
data$ActivityType <- factor(data$ActivityType)
```

```{r}
# Lista de columnas num√©ricas
num_columns <- sapply(data, is.numeric)

# Aplicar Min-Max Scaling a todas las columnas num√©ricas
data[num_columns] <- lapply(data[num_columns], function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
})

# Verificar el rango despu√©s del escalado
summary(data[num_columns])

```

```{r}
summary(data)
```

# 6. Dividir los datos en entrenamiento y test

```{r}
set.seed(123)

# Crear la partici√≥n (estratificaci√≥n)
split <- createDataPartition(data$ActivityType, p = 0.80, list = FALSE)  # 80% entrenamiento, 20% test
train_set <- data[split, ]
test_set <- data[-split, ]
```

# 7. Modelo SVM

## 7.1 entrenar el modelo

```{r}
# Medir el tiempo de entrenamiento con probabilidad habilitada
train_time <- system.time({
  svm_model <- svm(ActivityType ~ ., data = train_set, probability = TRUE)  # Activar probabilidades
})

# Medir el tiempo de predicci√≥n
predict_time <- system.time({
  predictions <- predict(svm_model, test_set, probability = TRUE)  # Obtener predicciones con probabilidades
})

# Imprimir los tiempos
print(train_time)
print(predict_time)
```

## 7.2 Evaluar el rendimiento del modelo

```{r}
# Evaluar el rendimiento del modelo
confusionMatrix(predictions, test_set$ActivityType)

```

El an√°lisis de la matriz de confusi√≥n muestra que el modelo alcanz√≥ una precisi√≥n perfecta (Accuracy = 1) con valores de sensibilidad y especificidad de 1.0000 para todas las clases. Sin embargo, la prevalencia de las clases indica un **desbalance significativo** en los datos. Por ejemplo, la clase mayoritaria (`Coche_urbano`) representa el 48.23% de las instancias, mientras que las clases minoritarias, como `Avi√≥n` (3.19%) y `Bicicleta` (11.72%), tienen una representaci√≥n considerablemente menor. Este desbalance puede no afectar el rendimiento actual debido a la alta diferenciaci√≥n en las caracter√≠sticas, pero podr√≠a impactar la **generalizaci√≥n del modelo** en datos no vistos o en escenarios con distribuciones de clases m√°s equilibradas.

Para abordar este problema y garantizar la robustez del modelo, se propone la implementaci√≥n de dos estrategias:

1.  **SMOTE (Synthetic Minority Oversampling Technique):**\
    Esta t√©cnica permite aumentar la representaci√≥n de las clases minoritarias mediante la generaci√≥n de ejemplos sint√©ticos que interpolan instancias existentes de estas clases. Esto mejora la sensibilidad y el rendimiento en la clasificaci√≥n de las clases menos representadas, evitando los problemas de sobreajuste asociados con el oversampling tradicional.

2.  **Ajuste de Pesos en SVM:**\
    Ajustar los pesos de penalizaci√≥n en la SVM permite compensar el desbalance asignando un mayor peso a las clases minoritarias. De esta forma, los errores en estas clases son m√°s penalizados durante el entrenamiento, equilibrando el impacto de la clase mayoritaria en el modelo.

Los resultados actuales muestran que el modelo puede clasificar perfectamente todas las clases bajo las condiciones de este dataset, pero la prevalencia desigual sugiere la necesidad de incorporar estas estrategias para garantizar una mayor robustez en escenarios m√°s variados. Estudios previos han demostrado que la combinaci√≥n de **SMOTE + Ajuste de Pesos** mejora significativamente m√©tricas clave como precisi√≥n balanceada, sensibilidad y F1-score, asegurando un mejor rendimiento en la clasificaci√≥n de medios de transporte con clases minoritarias relevantes.

```{r}
# Crear una malla de puntos en el espacio 2D
x_min <- min(train_set$accelX.g.)
x_max <- max(train_set$accelX.g.)
y_min <- min(train_set$accelY.g.)
y_max <- max(train_set$accelY.g.)

grid <- expand.grid(
  accelX.g. = seq(x_min, x_max, length.out = 100),
  accelY.g. = seq(y_min, y_max, length.out = 100)
)

# Obtener las variables predictoras usadas en el modelo (excluyendo ActivityType)
predictors <- setdiff(names(train_set), "ActivityType")

# Identificar variables num√©ricas y categ√≥ricas
num_vars <- names(train_set)[sapply(train_set, is.numeric)]
cat_vars <- setdiff(predictors, num_vars)

# Crear un dataframe con todas las columnas necesarias
grid_full <- as.data.frame(matrix(ncol = length(predictors), nrow = nrow(grid)))
names(grid_full) <- predictors

# Asignar valores de accelX.g. y accelY.g. desde la malla de puntos
grid_full$accelX.g. <- grid$accelX.g.
grid_full$accelY.g. <- grid$accelY.g.

# Para las variables num√©ricas, asignar el promedio de train_set
for (col in num_vars) {
  if (!(col %in% c("accelX.g.", "accelY.g."))) {
    grid_full[[col]] <- mean(train_set[[col]], na.rm = TRUE)
  }
}

# Para las variables categ√≥ricas, asignar la categor√≠a m√°s frecuente de train_set
for (col in cat_vars) {
  most_frequent <- names(which.max(table(train_set[[col]])))  # Obtener la categor√≠a m√°s frecuente
  grid_full[[col]] <- factor(rep(most_frequent, nrow(grid_full)), levels = levels(train_set[[col]]))
}

# Asegurar que las columnas de grid_full coincidan con las de train_set (menos ActivityType)
grid_full <- grid_full[, names(train_set)[names(train_set) != "ActivityType"]]

# Predecir con el modelo entrenado
grid_full$ActivityType <- predict(svm_model, newdata = grid_full)

# Graficar los datos de entrenamiento y la frontera de decisi√≥n
ggplot(train_set, aes(x = accelX.g., y = accelY.g., color = ActivityType)) +
  geom_point(alpha = 0.6) +
  geom_contour(data = grid_full, aes(z = as.numeric(ActivityType)), bins = 1) +
  labs(title = "SVM: Hiperplanos de Decisi√≥n en 2D (Solo Train)", x = "accelX.g.", y = "accelY.g.") +
  theme_minimal()



```

```{r}
# Aseg√∫rate de que tu modelo est√© entrenado con solo dos variables para graficarlo
# Por ejemplo, seleccionemos dos variables espec√≠ficas para entrenamiento
train_set_2d <- train_set[, c("accelX.g.", "accelY.g.", "ActivityType")]

# Volver a entrenar el modelo usando solo las dos variables seleccionadas
svm_model_2d <- svm(ActivityType ~ accelX.g. + accelY.g., data = train_set_2d, kernel = "linear")

# Graficar el modelo y los datos
plot(svm_model_2d, train_set_2d, main = "SVM classification plot")

# Agregar una leyenda manualmente
legend("bottom", legend = levels(train_set_2d$ActivityType),
       col = 1:length(levels(train_set_2d$ActivityType)), pch = 1)

```

**Observaciones de los graficos:**

-   El modelo ha logrado identificar regiones claras para la mayor√≠a de las clases (`Andando`, `Coche_urbano`, `Avi√≥n`). Esto sugiere que las caracter√≠sticas seleccionadas (`accelX.g.` y `accelY.g.`) son informativas para la clasificaci√≥n.

-   Hay √°reas donde las clases, como `Autob√∫s` y `Bicicleta`, tienen una ligera superposici√≥n en el espacio, lo que podr√≠a dificultar la clasificaci√≥n precisa. Esto podr√≠a deberse a la similitud en las caracter√≠sticas din√°micas de estas actividades.

-   Dado que algunas clases tienen una representaci√≥n mucho menor en los datos, como `Avi√≥n` y `Coche_autopista`, es posible que el modelo sea m√°s sensible a errores en estas clases, especialmente en regiones donde las fronteras son menos claras.

-   Este an√°lisis conecta directamente con los resultados de la matriz de confusi√≥n y la distribuci√≥n de clases, destacando la importancia de las caracter√≠sticas seleccionadas y la necesidad de estrategias adicionales para optimizar el modelo.\
    \

```{r}
# Instalar pROC si no lo tienes
library(pROC)

```

```{r}
# Obtener probabilidades predichas
predicted_probabilities <- attr(predictions, "probabilities")

# Inicializar gr√°fico vac√≠o
plot(1, type = "n", xlim = c(0, 1), ylim = c(0, 1),
     xlab = "Tasa de Falsos Positivos (1 - Especificidad)",
     ylab = "Tasa de Verdaderos Positivos (Sensibilidad)",
     main = "Curvas ROC por Clase")
abline(a = 0, b = 1, col = "red", lty = 2)  # L√≠nea de referencia

# Iterar sobre las clases
classes <- colnames(predicted_probabilities)
for (class in classes) {
  # Crear etiquetas binarias para la clase actual
  binary_labels <- ifelse(test_set$ActivityType == class, 1, 0)
  
  # Calcular la curva ROC para esta clase
  roc_curve <- roc(binary_labels, predicted_probabilities[, class])
  
  # Agregar la curva al gr√°fico
  plot(roc_curve, col = sample(colors(), 1), add = TRUE)
  
  # Mostrar el AUC en consola
  auc_value <- auc(roc_curve)
  cat("AUC para la clase", class, ":", auc_value, "\n")
}

# Agregar leyenda al gr√°fico
legend("bottomright", legend = classes, col = 1:length(classes), lty = 1)
```

-   **Correcto t√©cnicamente:** El gr√°fico muestra curvas ROC perfectamente ajustadas con valores de sensibilidad y especificidad ideales para todas las clases, lo que concuerda con las m√©tricas calculadas.

-   **Irrealista en la pr√°ctica:** La situaci√≥n en la que todas las clases tienen una separaci√≥n perfecta es extremadamente rara en problemas reales. Este comportamiento puede deberse a:

    -   **Sobreajuste:** El modelo est√° demasiado ajustado al dataset.

    -   **Datos ideales o sin ruido:** Si los datos tienen caracter√≠sticas muy bien separadas o hay poca variabilidad, el modelo puede mostrar este comportamiento.

    -   **Filtros en los datos:** Si hay una filtraci√≥n de datos entre el conjunto de entrenamiento y test (por ejemplo, datos duplicados), esto puede dar resultados enga√±osamente perfectos.

    ### **Pasos a Seguir**

    1.  **Verificar Overfitting:**

        -   Aplicar validaci√≥n cruzada para evaluar el rendimiento del modelo en diferentes subconjuntos de datos.

        -   Inspeccionar las m√©tricas en entrenamiento y prueba para verificar si hay una discrepancia significativa.

    2.  **Balancear las Clases:**

        -   Implementar t√©cnicas como **SMOTE** y/o ajustar los pesos de las clases en el modelo para abordar el desbalance.

    3.  **Revisar el Dataset:**

        -   Revisar la calidad, correlaci{ones con la variable target y escalado de las variables.

        -   Evaluar el uso de transformaciones adicionales o reducci√≥n de dimensionalidad (e.g., PCA).

    4.  **Validaci√≥n Adicional:**

        -   Auste del par√°metro `C` en SVM.

        -   Evaluar las m√©tricas como el **F1-Score** y precisi√≥n balanceada para todas las clases.

        -   Inspeccionar errores de clasificaci√≥n en clases minoritarias.

# 8. Evaluaci√≥n de la importancia de las variables utilizando RF

```{r}
# Entrenar el modelo Random Forest para obtener la importancia de las variables
rf_model <- randomForest(ActivityType ~ ., data = train_set)

# Ver la importancia de las variables
imp <- importance(rf_model)

# Ver las primeras filas de la importancia
imp
```

```{r}
str(imp)
```

```{r}
# Convertir el vector de importancias en un data frame
imp_df <- data.frame(Variable = rownames(imp), MeanDecreaseGini = imp[, 1])

# Ordenar el data frame por la importancia de mayor a menor
imp_sorted <- imp_df[order(imp_df$MeanDecreaseGini, decreasing = TRUE), ]

# Graficar la importancia de las variables
barplot(imp_sorted$MeanDecreaseGini, 
        main = "Importancia de las Variables", 
        las = 2,                       # Rotar nombres de las variables
        col = "skyblue",               # Color de las barras
        names.arg = imp_sorted$Variable,  # Nombres de las variables
        cex.names = 0.7,               # Ajustar tama√±o de los nombres
        horiz = TRUE,                  # Barra horizontal
        cex.axis = 0.7,                # Ajustar tama√±o de los n√∫meros del eje
        xlab = "Importancia",          # T√≠tulo para el eje X
        ylab = "Variables")            # T√≠tulo para el eje Y


```

## **üìä Variables Seleccionadas**

Para desarrollar un sistema de clasificaci√≥n del tipo de transporte, es crucial seleccionar las variables m√°s relevantes y evitar redundancias. En este an√°lisis, utilizamos tres enfoques principales:

-   **Mapa de calor de correlaciones** para identificar relaciones fuertes entre variables.

-   **Factores de Inflaci√≥n de Varianza (VIF)** para detectar multicolinealidad.

-   **Importancia de las variables (MeanDecreaseGini)** para evaluar su relevancia en la clasificaci√≥n.

Se identific√≥ **alta correlaci√≥n** entre las variables de aceleraci√≥n (`accelX.g`, `accelY.g`, `accelZ.g`), giroscopio (`gyroX.rad.s`, `gyroY.rad.s`, `gyroZ.rad.s`) y variables del grupo `m__` (`m11` a `m33`). Las variables de orientaci√≥n (`Yaw.rads.`, `Pitch.rads.`, `Roll.rads.`) mostraron correlaciones moderadas con aceleraciones y giroscopios. Variables como `Pressure.kilopascals`, `RelativeAltitude.meters` y `herzios` mostraron **baja correlaci√≥n con el resto**, indicando que aportan informaci√≥n √∫nica.

Con base en el an√°lisis, se seleccionaron las siguientes variables para el modelo:

### **‚úÖ Variables de contexto (presi√≥n y altitud)**

-   `Pressure.kilopascals` ‚Üí Informaci√≥n sobre presi√≥n atmosf√©rica, √∫til para diferenciar transportes en diferentes altitudes (ej. avi√≥n vs. coche).

### **‚úÖ Variable de frecuencia de muestreo**

-   `herzios` ‚Üí Puede indicar la tasa de muestreo del dispositivo, √∫til en la segmentaci√≥n de datos.

### **‚úÖ Variables de aceleraci√≥n (movimiento en los ejes X, Y, Z)**

-   `accelX.g`

-   `accelY.g`

-   `accelZ.g`\
    Estas variables permiten identificar patrones de movimiento y diferencias en los tipos de transporte basadas en fuerzas de aceleraci√≥n.

### **‚úÖ Variables de giroscopio y orientaci√≥n**

-   `gyroZ.rad.s` ‚Üí Se seleccion√≥ este eje como el m√°s representativo del giroscopio.

-   `Pitch.rads.` ‚Üí Inclinaci√≥n hacia adelante o atr√°s, utili para transporte a√©ros.

-   `Roll.rads.` ‚Üí Inclinaci√≥n lateral, para identificar cambios de pendientes.

-   Yaw.rads. ‚Üí Rotaci√≥n en el eje Z, clave para identificar cambios de direcci√≥n.

### **‚úÖ Variable representativa del grupo `m`**

-   `m33` ‚Üí Seleccionada como la m√°s relevante seg√∫n la importancia de variables (MeanDecreaseGini).

## üìå **Variables Excluidas**

Se decidi√≥ excluir variables con baja relevancia relativa o redundancia:

‚ùå **Variables del grupo `m`**: `m31`, `m21`, `m12`, `m11`, `m22`, `m32, m13, m23` (alta correlaci√≥n entre s√≠, se mantiene solo `m33` por su mayor importancia).

‚ùå **Giroscopios con menor relevancia**: `gyroY.rad.s.`, `gyroZ.rad.s.` (se selecciona solo `gyroZ.rad.s.` por su mayor impacto en MeanDecreaseGini).

‚ùå **Aceleraciones redundantes**: `accelUserX.g`, `accelUserY.g`, `accelUserZ.g` (altamente correlacionadas con `accelX.g`, `accelY.g` y `accelZ.g`).

### **üìä Variables Seleccionadas y Justificaci√≥n**

Las siguientes variables han sido retenidas porque:\
‚úî **Tienen alta importancia en Random Forest (`MeanDecreaseGini`).**\
‚úî **Son significativas en ANOVA (p \< 0.05).**\
‚úî **No presentan colinealidad extrema seg√∫n VIF.**

![](images/clipboard-3932775431.png)

# 9. Pasos a seguir:

1.  **Eliminaci√≥n de Variables no Relevantes:**\
    Basado en **ANOVA, VIF y `MeanDecreaseGini` en RF**. Se mantienen solo variables clave en **movimiento, aceleraci√≥n y contexto ambiental**.

2.  **Aplicaci√≥n de T√©cnicas para Abordar el Desbalance de Clases:**\
    Implementar t√©cnicas como **SMOTE (Synthetic Minority Oversampling Technique)** para aumentar la representaci√≥n de las clases minoritarias y **Ajuste de pesos (`class.weights`)** en SVM para penalizar errores en clases menos representadas.

3.  **Entrenamiento del Modelo y Evaluaci√≥n de Resultados:**\
    Entrenar nuevamente el modelo con las variables seleccionadas y las t√©cnicas de balanceo aplicadas. Evaluar su desempe√±o utilizando m√©tricas como sensibilidad, precisi√≥n balanceada y F1-score para asegurar mejoras en la clasificaci√≥n de las clases minoritarias.

4.  **Exploraci√≥n de Nuevos M√©todos de Entrenamiento:**\
    Probar configuraciones avanzadas, incluyendo:

    -   **Funciones Radiales Gamma:** Para capturar patrones no lineales en los datos.

    -   **Funciones Sigmoidales:** √ötiles para manejar relaciones complejas entre caracter√≠sticas.

5.  **Evaluaci√≥n de curvas ROC, matriz de confusi√≥n y F1-score para medir mejoras.**\
    Analizar las curvas ROC para cada clase y revisar posibles indicadores de overfitting, especialmente dado el desempe√±o aparentemente perfecto en los resultados actuales. Esto ayudar√° a identificar si el modelo est√° generalizando correctamente.

6.  **Aplicaci√≥n de Validaci√≥n Cruzada:**\
    Implementar t√©cnicas de validaci√≥n cruzada para evaluar la estabilidad del modelo en diferentes subconjuntos de datos. Esto permitir√° verificar la capacidad del modelo para generalizar y evitar problemas de sobreajuste.

# 
