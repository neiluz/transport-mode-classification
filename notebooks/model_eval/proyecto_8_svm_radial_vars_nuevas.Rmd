---
title: "Prediccion de Tipo de Transporte - Proyecto de Transporte"
output: html_notebook
---

### General: Objetivos del Proyecto y Definici√≥n de Variables

El objetivo principal de este proyecto es desarrollar un modelo basado en **M√°quinas de Vectores de Soporte (SVM)** para predecir el **modo de transporte** utilizado por un individuo en funci√≥n de los datos recopilados por sensores de dispositivos m√≥viles. Se busca analizar c√≥mo las diferentes se√±ales captadas por el aceler√≥metro, gir√≥scopo, bar√≥metro, GPS y magnet√≥metro pueden ser utilizadas para inferir con precisi√≥n el medio de transporte en uso.

Para lograr esto, se cuenta con un conjunto de datos que incluye:

1.  **Registro Temporal**

    -   Cada observaci√≥n est√° asociada a un instante de tiempo espec√≠fico.

2.  **Datos de Movimiento y Orientaci√≥n**

    -   **Aceler√≥metro**: Componentes X, Y, Z del vector aceleraci√≥n.

    -   **Gir√≥scopo**: Velocidad angular en los ejes X, Y, Z y su derivada.

    -   **Matriz de Rotaci√≥n y Cuaterniones**: Representan la orientaci√≥n tridimensional del dispositivo.

3.  **Datos de Ubicaci√≥n y Contexto**

    -   **GPS**: Coordenadas de latitud y longitud, velocidad, altitud y rumbo.

    -   **Presi√≥n Atmosf√©rica**: Valores obtenidos del bar√≥metro, junto con la altitud relativa.

    -   **Campo Magn√©tico Terrestre**: Medici√≥n en los ejes X, Y, Z.

4.  **Variables Categ√≥ricas**

    -   **Modo de Transporte**: La categor√≠a que se busca predecir (caminar, bicicleta, autom√≥vil, etc.).

    -   **Nivel de Confianza**: Un indicador de la precisi√≥n estimada para la clasificaci√≥n del transporte en los datos originales.

### Objetivo Notebook:

-   Evaluar el rendimiento del modelo Support Vector Machine (SVM) con diferentes configuraciones del kernel radial.

-   Optimizar el modelo SVM mediante la b√∫squeda de hiperpar√°metros.

-   Generar predicciones utilizando el conjunto de test 1.

-   Evaluar el modelo en el conjunto de test 2.

# **1. Carga de librer√≠as**

```{r}
# Lista de paquetes necesarios
necessary_packages <- c("dplyr", "caret", "e1071", "robustbase", "ggplot2", "data.table", "pROC","doParallel")

# Instalar paquetes que no est√°n instalados
new_packages <- necessary_packages[!(necessary_packages %in% installed.packages()[, "Package"])]
if (length(new_packages) > 0) {
  install.packages(new_packages)
}

# Cargar todos los paquetes
lapply(necessary_packages, library, character.only = TRUE)
```

```{r}
# Cargar las librer√≠as necesarias
library(caret)      # Para divisi√≥n estratificada y evaluaci√≥n de modelos
library(scales)     # Para Min-Max Scaling
library(e1071)      # Para entrenar SVM
library(randomForest)  # Para obtener la importancia de las variables
library(dplyr)      # Para manipulaci√≥n de datos
# Cargar la librer√≠a
library(visdat)
# Cargar la librer√≠a
library(tidyr)
# Cargar el paquete 'car'
library(car)
library(ggplot2)
library(stringr) #Cambiar variables


```

# 2. Cargar el dataset

```{r}
# Ruta del archivo CSV (modificar seg√∫n tu sistema)
ruta_dataset <- "C:/Users/ngonzalez/Documents/Inesdi/Datos proyecto 8/proyect8/data_vars_imputadas.csv"
data <- read.csv(ruta_dataset)


data <- read.csv(ruta_dataset)

# Resumen del dataset
cat("### Informaci√≥n General del Dataset")
dim(data) # Dimensiones del dataset
str(data) # Estructura del dataset

```

```{r}
summary(data) # Resumen estad√≠stico b√°sico
```

## 2.1 Selecci√≥n de las Variables de acuerdo a RF, VIF y Anova

```{r}
# Seleccionar solo las variables relevantes
data_filtrado <- data %>%
  select(accelX.g., accelZ.g., accelY.g.,  # Aceleraci√≥n
         Roll.rads., Pitch.rads., Yaw.rads., gyroY.rad.s.,  # Giroscopios
         Pressure.kilopascals., herzios,  # Contexto ambiental
         m33,  # Componentes de Movimiento
         ActivityType)  # Variable objetivo

# Guardar el dataset actualizado
write.csv(data_filtrado, "dataset_filtrado.csv", row.names = FALSE)

# Mostrar primeras filas del dataset filtrado
head(data_filtrado)
```

```{r}
str( data_filtrado)
```

```{r}
# Variables num√©ricas en el dataset
numeric_vars <- names(data_filtrado)[sapply(data_filtrado, is.numeric)]

# Graficar histogramas para cada variable num√©rica
par(mfrow = c(3, 3))  # Organizar en una matriz de 3x3
for (var in numeric_vars) {
  hist(data_filtrado[[var]], main = paste("Histograma de", var), col = "skyblue", border = "white")
}

```

# 3. Crear nuevas variables

Para mejorar la clasificaci√≥n en el modelo de SVM con kernel radial, se crearon nuevas variables como la **aceleraci√≥n absoluta**, que combina las tres componentes de aceleraci√≥n (X, Y, Z), y la **combinaci√≥n de Roll y Yaw**, que captura el comportamiento de rotaci√≥n del veh√≠culo. Adem√°s, se introdujo la **combinaci√≥n de aceleraci√≥n y √°ngulos** para capturar la relaci√≥n entre el movimiento y la orientaci√≥n del veh√≠culo, lo cual es crucial para diferenciar actividades como **Avi√≥n** y **Autob√∫s**, que presentan caracter√≠sticas de movimiento distintas. Estas nuevas variables permitieron una mejor discriminaci√≥n entre las clases, especialmente para las actividades m√°s dif√≠ciles de clasificar, como el **Avi√≥n**.

### 3.1. **Aceleraci√≥n absoluta**:

La aceleraci√≥n absoluta es una medida general de la aceleraci√≥n que combina las tres direcciones de la aceleraci√≥n (X, Y, Z) para representar la magnitud total del movimiento. Esta variable puede ser √∫til para identificar patrones de aceleraci√≥n general en el comportamiento de diferentes modos de transporte, como veh√≠culos en movimiento o aviones. **Impacto Esperado**: Esta variable puede ser crucial para distinguir entre los modos de transporte que implican movimientos m√°s suaves y aquellos que son m√°s din√°micos o abruptos.

```{r}
data_filtrado$accel_absolute <- sqrt(data_filtrado$accelX.g.^2 + 
                                            data_filtrado$accelY.g.^2 + 
                                            data_filtrado$accelZ.g.^2)

```

### 3.2. **Combinaci√≥n de Roll y Yaw**:

El comportamiento de rotaci√≥n en el espacio se puede capturar combinando los √°ngulos de roll y yaw. Estos √°ngulos representan la inclinaci√≥n del veh√≠culo (hacia los lados o hacia adelante/atr√°s) y la direcci√≥n de rotaci√≥n, lo cual puede ser esencial para el modelo, especialmente en modos de transporte como aviones o veh√≠culos en curvas. Esto puede incluir la diferencia entre ambos, la suma o incluso la ra√≠z cuadrada de su suma al cuadrado:

```{r}
data_filtrado$roll_yaw_combined <- sqrt(data_filtrado$Roll.rads.^2 + 
                                               data_filtrado$Yaw.rads.^2)

```

### 3.3 **Combinaci√≥n de Aceleraci√≥n y √Ångulos**

En algunos modos de transporte, como los autom√≥viles en carretera o autopista, la combinaci√≥n de aceleraci√≥n con orientaci√≥n puede ser muy informativa. Las actividades que muestran una aceleraci√≥n constante, como en una carretera, pueden diferenciarse de las que presentan variaciones significativas, como los aviones durante el despegue.

```{r}
data_filtrado$accel_angle_combined <- data_filtrado$accel_absolute * 
                                             sqrt(data_filtrado$Roll.rads.^2 + 
                                                  data_filtrado$Yaw.rads.^2 + 
                                                  data_filtrado$Pitch.rads.^2)

```

```{r}
str(data_filtrado)
```

# 3. Implementar `class.weights` para ajustar el desbalance de clases.

La combinaci√≥n de pesos manuales y los pesos inversos puede ser eficaz para balancear la influencia de las clases en el modelo. Los pesos manuales se basan en un conocimiento previo sobre la importancia relativa de cada clase, mientras que los pesos inversos ajustan la influencia seg√∫n la frecuencia de las clases en los datos.

**Implementaci√≥n de Promediado de Pesos**: Para calcular los pesos combinados, utilizamos una combinaci√≥n de los pesos manuales y los inversos. Estos pesos se promedian para generar una estrategia equilibrada.

```{r}
# Convertir la variable objetivo a factor (si no lo est√°)
data_filtrado$ActivityType <- as.factor(data_filtrado$ActivityType)

# 1 Convertir Herzios a num√©rico
data_filtrado <- data_filtrado %>%
  mutate(herzios = as.numeric(herzios))

# Verificar que Herzios ahora es num√©rico
str(data_filtrado$herzios)
summary(data_filtrado$herzios)
```

```{r}
# Identificar solo las columnas num√©ricas (excluyendo `ActivityType`)
num_cols <- sapply(data_filtrado, is.numeric)

# Aplicar Min-Max Scaling SOLO a las columnas num√©ricas
preproc <- preProcess(data_filtrado[, num_cols], method = c("range"))
data_scaled <- predict(preproc, data_filtrado[, num_cols])

# Volver a agregar la variable objetivo `ActivityType`
data_scaled$ActivityType <- data_filtrado$ActivityType

# Verificar la estructura del dataset escalado
str(data_scaled)
summary(data_scaled)
```

```{r}
# Verificar si hay NA despu√©s del escalado
print("üîé ¬øHay valores NA despu√©s del escalado?")
print(any(is.na(data_scaled)))  # Debe ser FALSE

# Verificar si las variables est√°n en el rango correcto [0,1]
summary(data_scaled)
```

```{r}

# Aplciar nuevos pesos
class_weights_pesado <- c("Andando" = 10, "Autobus" = 15, "Avion" = 60, 
                   "Bicicleta" = 5, "Coche_autopista" = 10, "Coche_urbano" = 1)

# **2. Normalizaci√≥n de pesos manuales (usando el m√°ximo en vez de la suma)**
class_weights_pesado <- class_weights_pesado / max(class_weights_pesado)
print("Pesos manuales normalizados:")
print(class_weights_pesado)

# **3. Calcular pesos inversamente proporcionales al tama√±o de cada clase**
class_counts <- table(data_scaled$ActivityType)
class_weights_auto <- 1 / class_counts  # Inversamente proporcional al n√∫mero de muestras

# **4. Normalizar los pesos autom√°ticos usando el m√°ximo para escala relativa**
class_weights_auto <- class_weights_auto / max(class_weights_auto)

# **5. Asegurar que ambos vectores tengan las mismas clases**
names(class_weights_auto) <- names(class_counts)

# **6. Combinar los pesos manuales y autom√°ticos con ponderaci√≥n**
# ‚úî 70% de pesos autom√°ticos y 30% de pesos manuales para evitar sesgos excesivos
clases_comunes <- intersect(names(class_weights_pesado), names(class_weights_auto))
class_weights_combined <- (0.8 * class_weights_auto[clases_comunes]) + (0.2 * class_weights_pesado[clases_comunes])

# **7. Mostrar los pesos combinados normalizados**
print("Pesos combinados normalizados:")
print(class_weights_combined)


```

```{r}
str(data_scaled)
```

```{r}
# Revisa si hay NA en m33
sum(is.na(data_scaled$m33))

# Revisa si hay valores extremos (m√°s all√° del rango esperado)
summary(data_scaled$m33)

```

```{r}
# Dividimos los datos en entrenamiento y prueba
set.seed(123)  # Para asegurar reproducibilidad
train_index <- createDataPartition(data_scaled$ActivityType, p = 0.8, list = FALSE)
train_data <- data_scaled[train_index, ]
test_data <- data_scaled[-train_index, ]
```

# 4. Entrenar Modelo Kermel Radial:

## 4.1 SVM con Kernel: Radial y pesos combinados

```{r}
# Convertir ActivityType en factor (asegurarse de que es categ√≥rica)
train_data$ActivityType <- as.factor(train_data$ActivityType)
test_data$ActivityType <- as.factor(test_data$ActivityType)

# Ahora entrenamos el modelo
start_time <- Sys.time()

svm_model_combined <- svm(ActivityType ~ ., data = train_data, 
                          kernel = "radial", cost = 1, gamma = 0.01, 
                          class.weights = class_weights_combined)

# Registrar el tiempo de finalizaci√≥n del entrenamiento
end_time <- Sys.time()

# Calcular el tiempo de entrenamiento
training_time <- end_time - start_time
cat("Tiempo de entrenamiento SVM:", training_time, "\n")

```

```{r}
pred_2 <- predict(svm_model_combined, test_data)

# Matriz de confusi√≥n
conf_matrix_2 <- confusionMatrix(pred_2, test_data$ActivityType)
print(conf_matrix_2)

# Extraer m√©tricas espec√≠ficas
precision <- conf_matrix_2$byClass[, "Pos Pred Value"]  # Precisi√≥n por clase
recall <- conf_matrix_2$byClass[, "Sensitivity"]        # Recall por clase
f1_score <- 2 * (precision * recall) / (precision + recall)  # F1-score

# üìå Mostrar resultados de precisi√≥n, recall y F1-score
metrics_results_2 <- data.frame(Class = levels(test_data$ActivityType),
                              Precision = precision,
                              Recall = recall,
                              F1_Score = f1_score)

print(metrics_results_2)
```

```{r}
# Generar predicciones en los datos de prueba
predictions <- predict(svm_model_combined, test_data)

```

```{r}
library(ggplot2)
library(ggfortify)

# Generar predicciones en los datos de prueba
pred <- predict(svm_model_combined, test_data)

# Asegurar que test_data solo tiene variables num√©ricas antes de PCA
test_data_numeric <- test_data %>%
  select(-ActivityType) %>%
  mutate_if(is.character, as.numeric)  # Convertir caracteres a num√©ricos si es necesario

# Aplicar PCA a los datos de prueba
pca_result <- prcomp(test_data_numeric, scale. = TRUE)

# Crear un dataframe con los resultados del PCA y las predicciones del modelo
pca_data <- data.frame(
  PC1 = pca_result$x[, 1], 
  PC2 = pca_result$x[, 2], 
  Predicci√≥n = pred,  # Agregamos la predicci√≥n del modelo
  Clase_Real = test_data$ActivityType  # Agregamos la clase real
)

# Graficar PCA con predicciones del modelo combinado
ggplot(pca_data, aes(x = PC1, y = PC2, color = Predicci√≥n, shape = Clase_Real)) +
  geom_point(alpha = 0.6, size = 2) +
  labs(title = "Separaci√≥n de Clases con PCA en SVM - Peso Combinado",
       x = "PC1",
       y = "PC2") +
  theme_minimal()

```

En este estudio, se introdujeron nuevas variables para mejorar la clasificaci√≥n de actividades, especialmente aquellas que previamente no se separaban adecuadamente. Se agregaron tres nuevas variables: **aceleraci√≥n absoluta**, que combina las tres componentes de aceleraci√≥n (X, Y y Z), **combinaci√≥n de los √°ngulos de Roll y Yaw** para capturar la rotaci√≥n, y **combinaci√≥n de aceleraci√≥n y √°ngulos** que mezcla la aceleraci√≥n total con los tres √°ngulos de rotaci√≥n (Roll, Yaw y Pitch). Estas variables permitieron al modelo captar mejor la din√°mica de las actividades, como la diferencia entre un avi√≥n despegando y un autob√∫s en movimiento.

Los resultados mostraron que el modelo entrenado con estas nuevas variables alcanz√≥ una **precisi√≥n global de 98.51%**, mejorando especialmente la clasificaci√≥n de clases como "Avi√≥n" y "Autob√∫s", que antes presentaban confusi√≥n. En la matriz de confusi√≥n, el modelo mostr√≥ una **excelente capacidad para clasificar todas las clases**, con un **Kappa de 0.9798**, indicando una excelente concordancia entre las predicciones y los valores reales. Las m√©tricas de precisi√≥n, recall y F1-score tambi√©n demostraron un buen rendimiento en todas las clases, destacando la mejora en clases minoritarias. En resumen, las nuevas variables ayudaron a mejorar la precisi√≥n del modelo sin afectar el rendimiento global, logrando una mejor separaci√≥n entre las clases de transporte.

### 4.3 Busqueda del mejor modelo

La **b√∫squeda de hiperpar√°metros** es un proceso esencial en el desarrollo de modelos de Machine Learning, cuyo objetivo es encontrar la combinaci√≥n m√°s adecuada de par√°metros que maximice el rendimiento del modelo. En el caso de un **Support Vector Machine (SVM)** con kernel radial, los par√°metros m√°s relevantes son:

-   **`C`**: Es el par√°metro de penalizaci√≥n que controla la compensaci√≥n entre margen y los errores de clasificaci√≥n. Un valor bajo permite m√°s errores en la clasificaci√≥n, mientras que un valor alto obliga al modelo a ajustarse m√°s estrictamente a los datos, lo que puede resultar en sobreajuste.

-   **`sigma` (conocido como `gamma`)**: Este par√°metro regula la forma del kernel radial, afectando c√≥mo se miden las distancias entre las muestras. Un valor peque√±o de `sigma` hace que el modelo sea m√°s suave y generalice mejor, mientras que un valor grande puede resultar en un modelo que se ajusta demasiado a los datos de entrenamiento, reduciendo su capacidad de generalizaci√≥n.

### **Pasos para la B√∫squeda de Hiperpar√°metros:**

1.  **Definici√≥n de la Malla de Hiperpar√°metros:** El primer paso en la b√∫squeda de los mejores par√°metros es definir una **malla de hiperpar√°metros**. Esta malla consiste en un conjunto de valores posibles para `C` y `sigma` que el modelo probar√° durante el proceso de entrenamiento. La malla se elige en funci√≥n de los valores que se consideran m√°s relevantes o que se sabe que pueden ofrecer buenos resultados seg√∫n el tipo de problema y los datos.

2.  **Estrategia de Validaci√≥n Cruzada:** Para evaluar la eficacia de cada combinaci√≥n de hiperpar√°metros, se utiliza **validaci√≥n cruzada**. Este m√©todo divide el conjunto de datos en varios subconjuntos o "pliegues". El modelo se entrena en algunos de estos subconjuntos y se eval√∫a en los otros. Esto se repite varias veces para asegurar que el modelo se eval√∫e de manera robusta y no se sobreajuste a un √∫nico conjunto de datos. La validaci√≥n cruzada ayuda a obtener una estimaci√≥n m√°s confiable del rendimiento del modelo.

    En este caso, se utiliz√≥ una **validaci√≥n cruzada de 10 pliegues**, lo que significa que el conjunto de datos se divide en 10 partes, y el modelo se entrena y eval√∫a 10 veces, asegurando que todas las muestras se utilicen tanto para entrenar como para evaluar el modelo.

3.  **Entrenamiento con B√∫squeda de Hiperpar√°metros:** Durante el proceso de entrenamiento, el modelo se ajusta repetidamente utilizando cada combinaci√≥n de valores de `C` y `sigma` definida en la malla de hiperpar√°metros. Cada combinaci√≥n se eval√∫a a trav√©s de la validaci√≥n cruzada, y el rendimiento del modelo se calcula para determinar cu√°l de las combinaciones proporciona el mejor resultado en t√©rminos de precisi√≥n, recall, o cualquier otra m√©trica relevante.

4.  **Paralelizaci√≥n del Proceso:** Dado que el proceso de b√∫squeda de hiperpar√°metros puede ser computacionalmente costoso, especialmente cuando se utiliza validaci√≥n cruzada con m√∫ltiples combinaciones de par√°metros, **paralelizaci√≥n** es una t√©cnica clave para acelerar el proceso. Mediante la paralelizaci√≥n, se distribuyen las cargas de trabajo entre m√∫ltiples n√∫cleos del procesador, lo que permite que las pruebas de diferentes combinaciones de hiperpar√°metros se realicen simult√°neamente, reduciendo significativamente el tiempo total de ejecuci√≥n.

5.  **Selecci√≥n de la Mejor Combinaci√≥n de Hiperpar√°metros:** Una vez que se completa la b√∫squeda, se selecciona el conjunto de hiperpar√°metros que ha mostrado el mejor rendimiento en t√©rminos de la m√©trica de evaluaci√≥n. El modelo final es entrenado utilizando esta combinaci√≥n √≥ptima de par√°metros y se utiliza para hacer predicciones sobre nuevos datos.

6.  **Liberaci√≥n de Recursos del Sistema:** Despu√©s de completar el proceso de entrenamiento y selecci√≥n del modelo, es importante liberar los recursos del sistema que se utilizaron para la paralelizaci√≥n. Esto implica cerrar el cl√∫ster de n√∫cleos y volver al modo secuencial para evitar sobrecargar el sistema.

```{r}
library(caret)
library(e1071)
library(doParallel)  # Para paralelizaci√≥n

# 1  Configurar los n√∫cleos para paralelizaci√≥n
num_cores <- detectCores() - 2  # Dejar 2 n√∫cleos libres para evitar bloqueos
cl <- makeCluster(num_cores)  # Crear cl√∫ster
registerDoParallel(cl)  # Activar paralelizaci√≥n

# 1 Definir la malla de hiperpar√°metros correctamente
tune_grid <- expand.grid(
  sigma = c(0.0001, 0.001, 0.01, 0.1, 1),  # Cambiar 'gamma' por 'sigma'
  C = c(0.01, 0.1, 1, 10)
)

# 2  Configurar validaci√≥n cruzada con paralelizaci√≥n
train_control <- trainControl(method = "cv", number = 10, allowParallel = TRUE)

# 3 Registrar el tiempo de inicio
start_time <- Sys.time()

# 4 Entrenar el modelo SVM con Grid Search paralelizado
svm_tune <- train(ActivityType ~ ., data = train_data, 
                   method = "svmRadial",
                   trControl = train_control,
                   tuneGrid = tune_grid,
                   class.weights = class_weights_combined)

# 5 Registrar el tiempo de fin
end_time <- Sys.time()

# Calcular el tiempo total de entrenamiento
training_time <- end_time - start_time
cat("Tiempo total de entrenamiento SVM con Grid Search:", training_time, "\n")

# 6 Apagar el cl√∫ster despu√©s del entrenamiento
stopCluster(cl)
registerDoSEQ()  # Volver al modo secuencial normal
```

```{r}
# 6 Imprimir los mejores hiperpar√°metros
print(svm_tune$bestTune)

# 7 Visualizar resultados de Grid Search
plot(svm_tune)

```

```{r}
library(viridis)

# 9 **Heatmap de Accuracy en funci√≥n de C y Sigma para SVM Radial**
# Ordenar resultados por accuracy
tune_results_radial <- svm_tune$results %>% 
  select(C, sigma, Accuracy) %>% 
  arrange(desc(Accuracy))

# Crear Heatmap con colores equilibrados y etiquetas adaptadas al fondo
ggplot(tune_results_radial, aes(x = factor(sigma), y = factor(C), fill = Accuracy)) +
  geom_tile() +
  scale_fill_viridis_c(option = "cividis", direction = -1, name = "Accuracy") +  
  geom_text(aes(label = round(Accuracy, 4), 
                color = ifelse(Accuracy > 0.7, "black", "white")), 
            size = 5, fontface = "bold") +  # Tama√±o m√°s grande para mayor visibilidad
  scale_color_manual(values = c("white", "black"), guide = "none") +  
  labs(title = "Accuracy en funci√≥n de C y Sigma (SVM Radial)",
       x = "Sigma",
       y = "C") +
  theme_minimal(base_size = 14) +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# Capturar el tiempo de inicio del entrenamiento
start_train_time <- Sys.time()

# Extraer los mejores hiperpar√°metros encontrados en Grid Search
best_C <- svm_tune$bestTune$C
best_gamma <- svm_tune$bestTune$sigma

# Entrenar el modelo final con los mejores hiperpar√°metros
svm_final <- svm(ActivityType ~ ., data = train_data, kernel = "radial",
                 cost = 10, gamma = 0.01, class.weights = class_weights_combined)

# Capturar el tiempo de finalizaci√≥n del entrenamiento
end_train_time <- Sys.time()
train_duration <- end_train_time - start_train_time

# Capturar el tiempo de inicio de la predicci√≥n
start_pred_time <- Sys.time()

# Hacer predicciones en el conjunto de prueba 
pred_final <- predict(svm_final, test_data)

# Capturar el tiempo de finalizaci√≥n de la predicci√≥n
end_pred_time <- Sys.time()
pred_duration <- end_pred_time - start_pred_time

# Imprimir los tiempos de ejecuci√≥n
print(paste("Tiempo de entrenamiento:", train_duration))
print(paste("Tiempo de predicci√≥n:", pred_duration))

```

```{r}
# Evaluar modelo con Matriz de Confusi√≥n
conf_matrix <- confusionMatrix(pred_final, test_data$ActivityType)

# Mostrar matriz de confusi√≥n
print(conf_matrix)

# Extraer m√©tricas espec√≠ficas
precision <- conf_matrix$byClass[, "Pos Pred Value"]  # Precisi√≥n por clase
recall <- conf_matrix$byClass[, "Sensitivity"]        # Recall por clase
f1_score <- 2 * (precision * recall) / (precision + recall)  # F1-score

# Mostrar resultados
print(data.frame(Class = levels(test_data$ActivityType),
                 Precision = precision,
                 Recall = recall,
                 F1_Score = f1_score))
```

```{r}
library(ggplot2)
library(ggfortify)

# Generar predicciones en los datos de prueba
pred <- predict(svm_final, test_data)

# Asegurar que test_data solo tiene variables num√©ricas antes de PCA
test_data_numeric <- test_data %>%
  select(-ActivityType) %>%
  mutate_if(is.character, as.numeric)  # Convertir caracteres a num√©ricos si es necesario

# Aplicar PCA a los datos de prueba
pca_result <- prcomp(test_data_numeric, scale. = TRUE)

# Crear un dataframe con los resultados del PCA y las predicciones del modelo
pca_data <- data.frame(
  PC1 = pca_result$x[, 1], 
  PC2 = pca_result$x[, 2], 
  Predicci√≥n = pred_final,  # Agregamos la predicci√≥n del modelo
  Clase_Real = test_data$ActivityType  # Agregamos la clase real
)

# Graficar PCA con clases reales
autoplot(pca_result, data = test_data, colour = "ActivityType") +
  labs(title = "Separaci√≥n de Clases con PCA en SVM - Clases Reales")

# Graficar PCA con predicciones del modelo combinado
ggplot(pca_data, aes(x = PC1, y = PC2, color = Predicci√≥n, shape = Clase_Real)) +
  geom_point(alpha = 0.6, size = 2) +
  labs(title = "Separaci√≥n de Clases con PCA en SVM - Peso Combinado - Mejor Parametro",
       x = "PC1",
       y = "PC2") +
  theme_minimal()

```

```{r}
library(caret)
library(e1071)

# Realizar predicciones en los datos de entrenamiento y prueba
y_train_pred <- predict(svm_final, newdata = train_data)
y_pred <- predict(svm_final, newdata = test_data)

# Evaluar el accuracy en el conjunto de entrenamiento
accuracy_train <- mean(y_train_pred == train_data$ActivityType)
cat("Accuracy en los datos de entrenamiento:", accuracy_train, "\n")

# Evaluar el accuracy en el conjunto de prueba
accuracy_test <- mean(y_pred == test_data$ActivityType)
cat("Accuracy en los datos de prueba:", accuracy_test, "\n")

# Comparar la diferencia en accuracy entre entrenamiento y prueba
if (accuracy_train > accuracy_test) {
  cat("El modelo podr√≠a estar sobreajustando (overfitting).\n")
}

# Realizar validaci√≥n cruzada en el conjunto de entrenamiento
cv_control <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation
cv_model <- train(ActivityType ~ ., data = train_data, method = "svmRadial", trControl = cv_control)
cv_scores <- cv_model$resample$Accuracy
cat("Accuracy promedio con validaci√≥n cruzada en entrenamiento:", mean(cv_scores), "\n")

# Mostrar la matriz de confusi√≥n
conf_matrix <- confusionMatrix(y_pred, test_data$ActivityType)
cat("\nMatriz de confusi√≥n:\n")
print(conf_matrix)

# Extraer m√©tricas espec√≠ficas de la matriz de confusi√≥n
precision <- conf_matrix$byClass[, "Pos Pred Value"]
recall <- conf_matrix$byClass[, "Sensitivity"]
f1 <- conf_matrix$byClass[, "F1"]

# Crear un dataframe con las m√©tricas
metrics_df <- data.frame(
    'Class' = rownames(conf_matrix$byClass),
    'Precision' = precision,
    'Recall' = recall,
    'F1_Score' = f1
)

# Mostrar las m√©tricas por clase
print("\nM√©tricas por clase:")
print(metrics_df)
```

```{r}
# Guardar el modelo entrenado
save(svm_final, file = "svm_model_combined.RData")
```

# 5. Resultados:

Con los resultados obtenidos, es claro que la inclusi√≥n de las nuevas variables, como la **aceleraci√≥n absoluta**, la **combinaci√≥n de roll y yaw**, y la **combinaci√≥n de aceleraci√≥n con los √°ngulos** contribuy√≥ de manera significativa a la mejora del modelo.

La **precisi√≥n global** del modelo alcanz√≥ un impresionante 99.8%, con un **Kappa** de 1, lo que indica una concordancia excelente entre las predicciones y las clases reales. Estos resultados son una clara mejora en comparaci√≥n con modelos previos. La matriz de confusi√≥n muestra que el modelo logr√≥ clasificar correctamente casi todas las instancias, incluyendo clases como **Avi√≥n**, que previamente hab√≠a presentado mayores dificultades.

Las m√©tricas de **precision**, **recall** y **F1-Score** para todas las clases fueron excelentes, alcanzando un valor de **1.000** para casi todas las clases, lo que demuestra que las nuevas variables han mejorado notablemente la capacidad del modelo para distinguir entre las diferentes actividades, incluso aquellas con menos representaciones en los datos.

Adem√°s, los **pesos combinados** optimizados contribuyeron a manejar el desbalance entre clases, especialmente para clases minoritarias como **Avi√≥n**, que ahora se clasifica con mayor precisi√≥n sin sacrificar el rendimiento en las clases mayoritarias como **Coche urbano**.

La optimizaci√≥n de los hiperpar√°metros tambi√©n jug√≥ un papel crucial, seleccionando valores de **C = 10** y **gamma = 0.01** que ofrecieron el mejor equilibrio entre ajuste y generalizaci√≥n, evitando el sobreajuste que ocurri√≥ con combinaciones m√°s extremas de estos par√°metros.

Los resultados obtenidos tambi√©n se reflejan en la **gr√°fica de PCA** que muestra claramente c√≥mo las nuevas variables mejoran la separaci√≥n de las clases en el espacio reducido de dos componentes principales (PC1 y PC2). La separaci√≥n entre las clases es mucho m√°s n√≠tida y definida, lo que sugiere que el modelo es ahora capaz de diferenciar mejor entre las diferentes actividades

En resumen, la combinaci√≥n de nuevas variables de aceleraci√≥n y orientaci√≥n, junto con un ajuste preciso de los pesos y par√°metros, result√≥ en un modelo SVM m√°s robusto y preciso, mejorando especialmente la clasificaci√≥n de clases minoritarias sin comprometer la precisi√≥n general.

## Tabla Resumen de SVM - Kernel Radial:

![](images/clipboard-558285899.png)
