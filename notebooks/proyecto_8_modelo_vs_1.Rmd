---
title: "Prediccion de Tipo de Transporte - Proyecto de Transporte"
output: html_notebook
---

### General: Objetivos del Proyecto y Definición de Variables

El objetivo principal de este proyecto es desarrollar un modelo basado en **Máquinas de Vectores de Soporte (SVM)** para predecir el **modo de transporte** utilizado por un individuo en función de los datos recopilados por sensores de dispositivos móviles. Se busca analizar cómo las diferentes señales captadas por el acelerómetro, giróscopo, barómetro, GPS y magnetómetro pueden ser utilizadas para inferir con precisión el medio de transporte en uso.

Para lograr esto, se cuenta con un conjunto de datos que incluye:

1.  **Registro Temporal**

    -   Cada observación está asociada a un instante de tiempo específico.

2.  **Datos de Movimiento y Orientación**

    -   **Acelerómetro**: Componentes X, Y, Z del vector aceleración.

    -   **Giróscopo**: Velocidad angular en los ejes X, Y, Z y su derivada.

    -   **Matriz de Rotación y Cuaterniones**: Representan la orientación tridimensional del dispositivo.

3.  **Datos de Ubicación y Contexto**

    -   **GPS**: Coordenadas de latitud y longitud, velocidad, altitud y rumbo.

    -   **Presión Atmosférica**: Valores obtenidos del barómetro, junto con la altitud relativa.

    -   **Campo Magnético Terrestre**: Medición en los ejes X, Y, Z.

4.  **Variables Categóricas**

    -   **Modo de Transporte**: La categoría que se busca predecir (caminar, bicicleta, automóvil, etc.).

    -   **Nivel de Confianza**: Un indicador de la precisión estimada para la clasificación del transporte en los datos originales.

### Objetivo Notebook:

# **1. Carga de librerías**

```{r}
# Lista de paquetes necesarios
necessary_packages <- c("dplyr", "caret", "e1071", "robustbase", "ggplot2", "data.table")

# Instalar paquetes que no están instalados
new_packages <- necessary_packages[!(necessary_packages %in% installed.packages()[, "Package"])]
if (length(new_packages) > 0) {
  install.packages(new_packages)
}

# Cargar todos los paquetes
lapply(necessary_packages, library, character.only = TRUE)
```

```{r}
# Cargar las librerías necesarias
library(caret)      # Para división estratificada y evaluación de modelos
library(scales)     # Para Min-Max Scaling
library(e1071)      # Para entrenar SVM
library(randomForest)  # Para obtener la importancia de las variables
library(dplyr)      # Para manipulación de datos
# Cargar la librería
library(visdat)
# Cargar la librería
library(tidyr)
# Cargar el paquete 'car'
library(car)
library(ggplot2)
library(stringr) #Cambiar variables
```

# 2. Cargar el dataset

```{r}
# Ruta del archivo CSV (modificar según tu sistema)
ruta_dataset <- "C:/Users/Lenovo/Documents/IT Academy/Datos proyecto 8/proyect8/input_data/dataframes_modificado.csv"
data <- read.csv(ruta_dataset)


data <- read.csv(ruta_dataset)

# Resumen del dataset
cat("### Información General del Dataset")
dim(data) # Dimensiones del dataset
str(data) # Estructura del dataset

```

```{r}
summary(data) # Resumen estadístico básico
```

## 2.1 Adecuacion del dataset

```{r}
# Eliminar la columna "ActivityConfidence"
data <- data[, !names(data) %in% "ActivityConfidence"]

# Crear la nueva columna "herzios" basada en "ActivityType"
data$herzios <- ifelse(data$ActivityType == "Avion", 10,
                    ifelse(data$ActivityType == "Coche autopista", 2,
                    ifelse(data$ActivityType == "Autobus", 50,
                    ifelse(data$ActivityType == "Bicleta", 50,
                    ifelse(data$ActivityType == "Andando", 100,
                    ifelse(data$ActivityType == "Coche Urbano 100", 100,
                    ifelse(data$ActivityType == "Coche Urbano 250", 250,
                    ifelse(data$ActivityType == "Coche carretera", 100, 0))))))))
```

```{r}
data
```

```{r}
data %>%
  count(ActivityType, sort = TRUE)

# Reemplazar las categorías 'Coche autopista' y 'Coche carretera' por 'Coche'
data <- data %>%
  mutate(ActivityType = str_replace(ActivityType, "Coche autopista|Coche carretera", "Coche_autopista"))

data <- data %>%
  mutate(ActivityType = str_replace(ActivityType, "Coche Urbano 250|Coche Urbano 100", "Coche_urbano"))

# Verificar los primeros valores de ActivityType después del reemplazo
head(data$ActivityType)
```

```{r}
str(data)
```

# 3. Análisis de Datos

## 3.1 Detección de Valores faltantes

Identificar valores faltantes es crucial porque pueden afectar el rendimiento del modelo predictivo. Este paso ayuda a decidir estrategias para imputar o manejar estos valores.

```{r}
cat("### Análisis de Valores Faltantes\n")
# Resumen de valores faltantes por columna
print(sapply(data, function(x) sum(is.na(x))))

# Visualización de valores faltantes mejorada
vis_miss(data) +
  ggtitle("Mapa de Valores Faltantes") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, size = 8), # Ajuste de las etiquetas del eje X
    axis.text.y = element_text(size = 10),                       # Ajuste de las etiquetas del eje Y
    plot.title = element_text(hjust = 0.5, size = 14)            # Centrar y ajustar tamaño del título
  )

```

El análisis muestra que no hay valores nulos en el dataset. Esto significa que todas las variables contienen información completa para las 816 observaciones registradas. Este resultado asegura que no será necesario realizar técnicas de imputación de datos.

## 3.2 Detección de Outliers Univariantes

Usaremos el rango intercuartílico (IQR) para identificar outliers y calcular el porcentaje de valores extremos en cada variable numérica.

```{r}
# Extraer solo las columnas numéricas
num_data <- data %>% select(where(is.numeric))

if (ncol(num_data) > 0) {
  cat("### Análisis de Outliers\n")
  
  # Cálculo de outliers por IQR
  outlier_detection <- num_data %>%
    summarise(across(everything(), ~ {
      q1 <- quantile(.x, 0.25, na.rm = TRUE)
      q3 <- quantile(.x, 0.75, na.rm = TRUE)
      iqr <- q3 - q1
      sum(.x < (q1 - 1.5 * iqr) | .x > (q3 + 1.5 * iqr), na.rm = TRUE) / length(.x) * 100
    }))
  
  # Transponer la tabla
  outlier_detection <- as.data.frame(t(outlier_detection))
  outlier_detection$Variable <- rownames(outlier_detection)
  rownames(outlier_detection) <- NULL
  
  # Reordenar las columnas
  outlier_detection <- outlier_detection %>%
    select(Variable, `Outliers (%)` = V1) %>%
    arrange(desc(`Outliers (%)`))  # Ordenar de mayor a menor
  
  # Mostrar la tabla
  print(outlier_detection)
}
```

**Visualización de Outliers**

Utilizaremos boxplots para visualizar los outliers en cada variable numérica.

```{r}
if (ncol(num_data) > 0) {
  # Transformar datos a formato largo
  num_data_long <- num_data %>%
    pivot_longer(cols = everything(), names_to = "Variable", values_to = "Valor")
  
  # Dividir las variables en grupos de 6
  variable_groups <- split(unique(num_data_long$Variable), ceiling(seq_along(unique(num_data_long$Variable)) / 6))

  for (group in variable_groups) {
    # Filtrar las variables del grupo actual
    group_data_long <- num_data_long %>% filter(Variable %in% group)
    
    # Crear los boxplots
    print(
      ggplot(group_data_long, aes(x = Variable, y = Valor)) +
        geom_boxplot(outlier.colour = "red", outlier.size = 1.5, fill = "lightblue") +
        theme_minimal() +
        labs(
          title = "Visualización de Outliers",
          x = "Variable",
          y = "Valores"
        ) +
        theme(
          plot.title = element_text(size = 8, hjust = 0.5),
          axis.text.x = element_text(angle = 0, hjust = 1)
        ) +
        facet_wrap(~ Variable, scales = "free", ncol = 3)  # Cambia "ncol" a 2 o 3 según el diseño que prefieras
    )
  }
} else {
  cat("No hay variables numéricas en el dataset.\n")
}
```

## **3.3 Analisisis de Colinealidad**

```{r}
library(dplyr)

# Verificar que el dataset existe
if (exists("data")) {
  # Filtrar las variables numéricas y eliminar la variable dependiente (ActivityType)
  num_data_filtered <- data %>%
    select(where(is.numeric)) %>%
    mutate(dummy_target = runif(nrow(.), 0, 1)) # Crear una variable dummy temporal

  # Validar si hay suficientes variables para calcular el modelo
  if (ncol(num_data_filtered) > 1) {
    # Crear un modelo de regresión con las variables predictoras
    vif_model <- lm(dummy_target ~ ., data = num_data_filtered)
    
    # Calcular los valores de VIF
    vif_values <- vif(vif_model)
    
    # Imprimir los valores de VIF
    print("### Factores de Inflación de Varianza (VIF)")
    print(vif_values)
    
    # Identificar variables con alta colinealidad (VIF > 10 como umbral común)
    high_vif <- vif_values[vif_values > 10]
    if (length(high_vif) > 0) {
      cat("\nVariables con alta colinealidad (VIF > 10):\n")
      print(high_vif)
    } else {
      cat("\nNo se encontraron variables con alta colinealidad (VIF <= 10).\n")
    }
  } else {
    cat("No hay suficientes variables numéricas para calcular el VIF.\n")
  }
} else {
  cat("El dataset 'data' no existe en el entorno.\n")
}
```

> En el análisis de los datos, hemos observado que algunas variables, como `qX`, `qY` y `gyroX.rad.s.`, están fuertemente correlacionadas entre sí y también con otras variables clave del modelo, como las mediciones magnéticas (`magX.µT.`, `magY.µT.`). Esta alta colinealidad genera un aumento en los **Factores de Inflación de Varianza (VIF)**, con varios valores superiores a 10. Esto indica que algunas de estas variables están aportando la misma información, lo que provoca redundancia en el modelo.
>
> La presencia de estas variables altamente correlacionadas puede afectar la estabilidad y precisión de las predicciones. En particular, las variables relacionadas con las matrices de rotación y el campo magnético tienden a influir de manera similar, lo que dificulta que el modelo identifique correctamente las variables más importantes.
>
> Para mejorar la precisión y estabilidad del modelo, sería recomendable eliminar estas variables colineales, como `qX`, `qY` y `gyroX.rad.s.`, así como las variables magnéticas. De esta forma, reducimos la redundancia, lo que permitirá que el modelo funcione de manera más eficiente y que los resultados sean más fáciles de interpretar.

## **3.4** Distribución de las Clases en `ActivityType`

```{r}
# Crear un gráfico de barras para la variable 'target_variable' con un solo color
ggplot(data, aes(x = ActivityType)) + 
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Distribución de las Clases en la Variable `ActivityType`", 
       x = "Clases", y = "Frecuencia") +
  theme_minimal()

```

> El gráfico muestra la distribución de las clases en la variable objetivo `ActivityType`. Es evidente que existe un desbalance significativo en los datos, donde la clase `Coche_urbano` domina ampliamente con la mayor cantidad de observaciones, seguida por `Andando` y `Bicicleta`. En contraste, las clases `Avión` y `Coche_autopista` tienen una representación mucho menor, lo que podría generar desafíos para el modelo al clasificar estas clases minoritarias.
>
> ### **Implicaciones del Desbalance**
>
> 1.  **Riesgo de Sesgo hacia la Clase Mayoritaria:**\
>     El modelo puede sesgarse hacia la clase mayoritaria (`Coche_urbano`) durante el entrenamiento, ya que la mayoría de los ejemplos pertenecen a esta clase. Esto podría conducir a una alta precisión global aparente, pero con un rendimiento deficiente en las clases minoritarias (`Avión`, `Coche_autopista`).
>
> 2.  **Impacto en Métricas como Sensibilidad y F1-score:**\
>     El desbalance puede afectar negativamente métricas como la sensibilidad y el F1-score para las clases menos representadas, lo que es crítico en aplicaciones donde la detección precisa de estas clases es importante.

# 4. Imputacion de Variables

## 4.1 Imputacion de Outliers

La imputación mediante **winsorización** es un enfoque útil para tratar los outliers extremos en los datos. En este caso, se ha aplicado winsorización a las variables con más del 10% de outliers, como `gyroZ.rad.s.`, `Roll.rads.`, `gyroX.rad.s.`, entre otras. Este proceso consiste en limitar los valores de las variables fuera de un rango específico, utilizando los percentiles 1 y 99. De esta manera, los valores extremos son reemplazados por los valores más cercanos en esos percentiles, lo que reduce el impacto de los outliers sin eliminar completamente los datos.

```{r}
# Función para aplicar winsorización
winsorize <- function(x) {
  q1 <- quantile(x, 0.01)  # Percentil 1
  q99 <- quantile(x, 0.99)  # Percentil 99
  pmax(pmin(x, q99), q1)  # Limitar valores fuera de estos percentiles
}

# Lista de columnas a winsorizar
columns_to_winsorize <- c("gyroZ.rad.s.", "Roll.rads.", "m13", "gyroX.rad.s.", "gyroY.rad.s.", 
                          "accelX.g.", "m32", "qX", "magZ.µT.", "qY", "accelUserX.g.", 
                          "accelUserZ.g.", "accelZ.g.", "magY.µT.", "m33", "accelUserY.g.")

# Aplicar winsorización solo a las columnas que existen en el dataset
columns_to_winsorize <- columns_to_winsorize[columns_to_winsorize %in% colnames(data)]

# Aplicar la función de winsorización a las columnas seleccionadas
data[columns_to_winsorize] <- lapply(data[columns_to_winsorize], winsorize)

# Verificar las primeras filas después de aplicar winsorización
head(data)

```

```{r}
if (ncol(num_data) > 0) {
  cat("### Análisis de Outliers\n")
  
  # Cálculo de outliers por IQR
  outlier_detection <- num_data %>%
    summarise(across(everything(), ~ {
      q1 <- quantile(.x, 0.25, na.rm = TRUE)
      q3 <- quantile(.x, 0.75, na.rm = TRUE)
      iqr <- q3 - q1
      sum(.x < (q1 - 1.5 * iqr) | .x > (q3 + 1.5 * iqr), na.rm = TRUE) / length(.x) * 100
    }))
  
  # Transponer la tabla
  outlier_detection <- as.data.frame(t(outlier_detection))
  outlier_detection$Variable <- rownames(outlier_detection)
  rownames(outlier_detection) <- NULL
  
  # Reordenar las columnas
  outlier_detection <- outlier_detection %>%
    select(Variable, `Outliers (%)` = V1) %>%
    arrange(desc(`Outliers (%)`))  # Ordenar de mayor a menor
  
  # Mostrar la tabla
  print(outlier_detection)
}
```

```{r}
if (ncol(num_data) > 0) {
  # Transformar datos a formato largo
  num_data_long <- num_data %>%
    pivot_longer(cols = everything(), names_to = "Variable", values_to = "Valor")
  
  # Dividir las variables en grupos de 6
  variable_groups <- split(unique(num_data_long$Variable), ceiling(seq_along(unique(num_data_long$Variable)) / 6))

  for (group in variable_groups) {
    # Filtrar las variables del grupo actual
    group_data_long <- num_data_long %>% filter(Variable %in% group)
    
    # Crear los boxplots
    print(
      ggplot(group_data_long, aes(x = Variable, y = Valor)) +
        geom_boxplot(outlier.colour = "red", outlier.size = 1.5, fill = "lightblue") +
        theme_minimal() +
        labs(
          title = "Visualización de Outliers",
          x = "Variable",
          y = "Valores"
        ) +
        theme(
          plot.title = element_text(size = 8, hjust = 0.5),
          axis.text.x = element_text(angle = 0, hjust = 1)
        ) +
        facet_wrap(~ Variable, scales = "free", ncol = 3)  # Cambia "ncol" a 2 o 3 según el diseño que prefieras
    )
  }
} else {
  cat("No hay variables numéricas en el dataset.\n")
}
```

## 4.2 Eliminacion de Vairables 

Las variables `qX`, `qY` y `qZ` serán eliminadas debido a su alta correlación con las **matrices de rotación**. Estas variables aportan información redundante al modelo y, para evitar problemas de multicolinealidad, se ha decidido priorizar las **matrices de rotación**, que ya encapsulan la información necesaria para describir la orientación del objeto en movimiento.

Por otro lado, las variables asociadas al **campo magnético** (`magX.µT.`, `magY.µT.`, `magZ.µT.`, `calMagX.µT.`, `calMagY.µT.`, `calMagZ.µT.`) también serán eliminadas, pero por un motivo distinto. Aunque estas variables no están directamente relacionadas con las matrices de rotación, el campo magnético tiene un **impacto significativo en la clasificación de los tipos de transporte**. Las señales magnéticas pueden ser similares entre distintos medios de transporte, como coches, trenes o aviones, lo que puede generar confusión en el modelo. Al eliminar estas variables, se evita que el modelo dependa de estas señales que pueden no ser determinantes para la tarea de clasificación.

```{r}
# Eliminar las columnas especificadas del dataset
columns_to_remove <- c("qX", "qY", "qZ", "qW", "magX.µT.", "magY.µT.", "magZ.µT.", 
                       "calMagX.µT.", "calMagY.µT.", "calMagZ.µT.")

# Eliminar las columnas del dataset
data <- data[, !(colnames(data) %in% columns_to_remove)]

# Verificar las primeras filas después de eliminar las columnas
head(data)
```

```{r}
# Guardar el dataset modificado en el directorio de trabajo actual
write.csv(data, "data_vars_eliminadas.csv", row.names = FALSE)

# Mostrar el directorio de trabajo actual
cat("El dataset ha sido guardado en el directorio de trabajo actual:", getwd())

```

# 5. Escalado de Datos

Para los **outliers**, aplicamos **RobustScaler**, y para las otras variables, utilizamos **Min-Max Scaling.**

```{r}
# Convertir las variables categóricas a factor
data$ActivityType <- factor(data$ActivityType)

# Identificar las variables con outliers
variables_with_outliers <- c("gyroZ.rad.s.", "Roll.rads.", "m13", "gyroX.rad.s.",                              "gyroY.rad.s.", "accelX.g.", "m32", "accelUserX.g.", 
                            "accelUserZ.g.", "accelZ.g.", "m33", "accelUserY.g.")

# Función para aplicar RobustScaler
robust_scaler <- function(x) {
  median_val <- median(x, na.rm = TRUE)
  mad_val <- mad(x, na.rm = TRUE)
  (x - median_val) / mad_val
}

# Aplicar RobustScaler a las variables con outliers
data[variables_with_outliers] <- lapply(data[variables_with_outliers], robust_scaler)

# Escalado Min-Max para las otras variables (sin outliers)
# Filtrar solo las columnas numéricas (eliminar las categóricas)
num_variables <- sapply(data, is.numeric)
variables_without_outliers <- names(data)[num_variables & !names(data) %in% variables_with_outliers]

# Aplicar Min-Max Scaling a las variables numéricas sin outliers
data[variables_without_outliers] <- lapply(data[variables_without_outliers], rescale)

# Verificar las primeras filas después de la transformación
head(data)
```

```{r}
summary(data)
```

```{r}
# Verificar el rango de las variables con Min-Max Scaling
sapply(data[variables_without_outliers], function(x) range(x, na.rm = TRUE))

# Verificar las estadísticas básicas de las variables con RobustScaler
sapply(data[variables_with_outliers], summary)

```

# 6. Dividir los datos en entrenamiento y test

```{r}
set.seed(123)

# Crear la partición (estratificación)
split <- createDataPartition(data$ActivityType, p = 0.8, list = FALSE)  # 80% entrenamiento, 20% test
train_set <- data[split, ]
test_set <- data[-split, ]
```

# 7. Modelo SVM

## 7.1 entrenar el modelo

```{r}
# Medir el tiempo de entrenamiento con probabilidad habilitada
train_time <- system.time({
  svm_model <- svm(ActivityType ~ ., data = train_set, probability = TRUE)  # Activar probabilidades
})

# Medir el tiempo de predicción
predict_time <- system.time({
  predictions <- predict(svm_model, test_set, probability = TRUE)  # Obtener predicciones con probabilidades
})

# Imprimir los tiempos
print(train_time)
print(predict_time)
```

## 7.2 Evaluar el rendimiento del modelo

```{r}
# Evaluar el rendimiento del modelo
confusionMatrix(predictions, test_set$ActivityType)

```

El análisis de la matriz de confusión muestra que el modelo alcanzó una precisión perfecta (Accuracy = 1) con valores de sensibilidad y especificidad de 1.0000 para todas las clases. Sin embargo, la prevalencia de las clases indica un **desbalance significativo** en los datos. Por ejemplo, la clase mayoritaria (`Coche_urbano`) representa el 48.23% de las instancias, mientras que las clases minoritarias, como `Avión` (3.19%) y `Bicicleta` (11.72%), tienen una representación considerablemente menor. Este desbalance puede no afectar el rendimiento actual debido a la alta diferenciación en las características, pero podría impactar la **generalización del modelo** en datos no vistos o en escenarios con distribuciones de clases más equilibradas.

Para abordar este problema y garantizar la robustez del modelo, se propone la implementación de dos estrategias:

1.  **SMOTE (Synthetic Minority Oversampling Technique):**\
    Esta técnica permite aumentar la representación de las clases minoritarias mediante la generación de ejemplos sintéticos que interpolan instancias existentes de estas clases. Esto mejora la sensibilidad y el rendimiento en la clasificación de las clases menos representadas, evitando los problemas de sobreajuste asociados con el oversampling tradicional.

2.  **Ajuste de Pesos en SVM:**\
    Ajustar los pesos de penalización en la SVM permite compensar el desbalance asignando un mayor peso a las clases minoritarias. De esta forma, los errores en estas clases son más penalizados durante el entrenamiento, equilibrando el impacto de la clase mayoritaria en el modelo.

Los resultados actuales muestran que el modelo puede clasificar perfectamente todas las clases bajo las condiciones de este dataset, pero la prevalencia desigual sugiere la necesidad de incorporar estas estrategias para garantizar una mayor robustez en escenarios más variados. Estudios previos han demostrado que la combinación de **SMOTE + Ajuste de Pesos** mejora significativamente métricas clave como precisión balanceada, sensibilidad y F1-score, asegurando un mejor rendimiento en la clasificación de medios de transporte con clases minoritarias relevantes.

```{r}
# Crear una malla de puntos en el espacio 2D
x_min <- min(train_set$accelX.g.)
x_max <- max(train_set$accelX.g.)
y_min <- min(train_set$accelY.g.)
y_max <- max(train_set$accelY.g.)

grid <- expand.grid(
  accelX.g. = seq(x_min, x_max, length.out = 100),
  accelY.g. = seq(y_min, y_max, length.out = 100)
)

# Obtener las variables predictoras usadas en el modelo (excluyendo ActivityType)
predictors <- setdiff(names(train_set), "ActivityType")

# Identificar variables numéricas y categóricas
num_vars <- names(train_set)[sapply(train_set, is.numeric)]
cat_vars <- setdiff(predictors, num_vars)

# Crear un dataframe con todas las columnas necesarias
grid_full <- as.data.frame(matrix(ncol = length(predictors), nrow = nrow(grid)))
names(grid_full) <- predictors

# Asignar valores de accelX.g. y accelY.g. desde la malla de puntos
grid_full$accelX.g. <- grid$accelX.g.
grid_full$accelY.g. <- grid$accelY.g.

# Para las variables numéricas, asignar el promedio de train_set
for (col in num_vars) {
  if (!(col %in% c("accelX.g.", "accelY.g."))) {
    grid_full[[col]] <- mean(train_set[[col]], na.rm = TRUE)
  }
}

# Para las variables categóricas, asignar la categoría más frecuente de train_set
for (col in cat_vars) {
  most_frequent <- names(which.max(table(train_set[[col]])))  # Obtener la categoría más frecuente
  grid_full[[col]] <- factor(rep(most_frequent, nrow(grid_full)), levels = levels(train_set[[col]]))
}

# Asegurar que las columnas de grid_full coincidan con las de train_set (menos ActivityType)
grid_full <- grid_full[, names(train_set)[names(train_set) != "ActivityType"]]

# Predecir con el modelo entrenado
grid_full$ActivityType <- predict(svm_model, newdata = grid_full)

# Graficar los datos de entrenamiento y la frontera de decisión
ggplot(train_set, aes(x = accelX.g., y = accelY.g., color = ActivityType)) +
  geom_point(alpha = 0.6) +
  geom_contour(data = grid_full, aes(z = as.numeric(ActivityType)), bins = 1) +
  labs(title = "SVM: Hiperplanos de Decisión en 2D (Solo Train)", x = "accelX.g.", y = "accelY.g.") +
  theme_minimal()



```

```{r}
# Asegúrate de que tu modelo esté entrenado con solo dos variables para graficarlo
# Por ejemplo, seleccionemos dos variables específicas para entrenamiento
train_set_2d <- train_set[, c("accelX.g.", "accelY.g.", "ActivityType")]

# Volver a entrenar el modelo usando solo las dos variables seleccionadas
svm_model_2d <- svm(ActivityType ~ accelX.g. + accelY.g., data = train_set_2d, kernel = "linear")

# Graficar el modelo y los datos
plot(svm_model_2d, train_set_2d, main = "SVM classification plot")

# Agregar una leyenda manualmente
legend("bottom", legend = levels(train_set_2d$ActivityType),
       col = 1:length(levels(train_set_2d$ActivityType)), pch = 1)

```

**Observaciones de los graficos:**

-   El modelo ha logrado identificar regiones claras para la mayoría de las clases (`Andando`, `Coche_urbano`, `Avión`). Esto sugiere que las características seleccionadas (`accelX.g.` y `accelY.g.`) son informativas para la clasificación.

-   Hay áreas donde las clases, como `Autobús` y `Bicicleta`, tienen una ligera superposición en el espacio, lo que podría dificultar la clasificación precisa. Esto podría deberse a la similitud en las características dinámicas de estas actividades.

-   Dado que algunas clases tienen una representación mucho menor en los datos, como `Avión` y `Coche_autopista`, es posible que el modelo sea más sensible a errores en estas clases, especialmente en regiones donde las fronteras son menos claras.

-   Este análisis conecta directamente con los resultados de la matriz de confusión y la distribución de clases, destacando la importancia de las características seleccionadas y la necesidad de estrategias adicionales para optimizar el modelo.\
    \

```{r}
# Instalar pROC si no lo tienes
install.packages("pROC")
library(pROC)

```

```{r}
# Obtener probabilidades predichas
predicted_probabilities <- attr(predictions, "probabilities")

# Inicializar gráfico vacío
plot(1, type = "n", xlim = c(0, 1), ylim = c(0, 1),
     xlab = "Tasa de Falsos Positivos (1 - Especificidad)",
     ylab = "Tasa de Verdaderos Positivos (Sensibilidad)",
     main = "Curvas ROC por Clase")
abline(a = 0, b = 1, col = "red", lty = 2)  # Línea de referencia

# Iterar sobre las clases
classes <- colnames(predicted_probabilities)
for (class in classes) {
  # Crear etiquetas binarias para la clase actual
  binary_labels <- ifelse(test_set$ActivityType == class, 1, 0)
  
  # Calcular la curva ROC para esta clase
  roc_curve <- roc(binary_labels, predicted_probabilities[, class])
  
  # Agregar la curva al gráfico
  plot(roc_curve, col = sample(colors(), 1), add = TRUE)
  
  # Mostrar el AUC en consola
  auc_value <- auc(roc_curve)
  cat("AUC para la clase", class, ":", auc_value, "\n")
}

# Agregar leyenda al gráfico
legend("bottomright", legend = classes, col = 1:length(classes), lty = 1)
```

-   **Correcto técnicamente:** El gráfico muestra curvas ROC perfectamente ajustadas con valores de sensibilidad y especificidad ideales para todas las clases, lo que concuerda con las métricas calculadas.

-   **Irrealista en la práctica:** La situación en la que todas las clases tienen una separación perfecta es extremadamente rara en problemas reales. Este comportamiento puede deberse a:

    -   **Sobreajuste:** El modelo está demasiado ajustado al dataset.

    -   **Datos ideales o sin ruido:** Si los datos tienen características muy bien separadas o hay poca variabilidad, el modelo puede mostrar este comportamiento.

    -   **Filtros en los datos:** Si hay una filtración de datos entre el conjunto de entrenamiento y test (por ejemplo, datos duplicados), esto puede dar resultados engañosamente perfectos.

    ### **Pasos a Seguir**

    1.  **Verificar Overfitting:**

        -   Aplicar validación cruzada para evaluar el rendimiento del modelo en diferentes subconjuntos de datos.

        -   Inspeccionar las métricas en entrenamiento y prueba para verificar si hay una discrepancia significativa.

    2.  **Balancear las Clases:**

        -   Implementar técnicas como **SMOTE** y/o ajustar los pesos de las clases en el modelo para abordar el desbalance.

    3.  **Revisar el Dataset:**

        -   Revisar la calidad y escalado de las variables.

        -   Evaluar el uso de transformaciones adicionales o reducción de dimensionalidad (e.g., PCA).

    4.  **Validación Adicional:**

        -   Auste del parámetro `C` en SVM.

        -   Evaluar las métricas como el **F1-Score** y precisión balanceada para todas las clases.

        -   Inspeccionar errores de clasificación en clases minoritarias.

# 8. Evaluación de la importancia de las variables utilizando RF

```{r}
# Entrenar el modelo Random Forest para obtener la importancia de las variables
rf_model <- randomForest(ActivityType ~ ., data = train_set)

# Ver la importancia de las variables
imp <- importance(rf_model)

# Ver las primeras filas de la importancia
imp
```

```{r}
str(imp)
```

```{r}
# Convertir el vector de importancias en un data frame
imp_df <- data.frame(Variable = rownames(imp), MeanDecreaseGini = imp[, 1])

# Ordenar el data frame por la importancia de mayor a menor
imp_sorted <- imp_df[order(imp_df$MeanDecreaseGini, decreasing = TRUE), ]

# Graficar la importancia de las variables
barplot(imp_sorted$MeanDecreaseGini, 
        main = "Importancia de las Variables", 
        las = 2,                       # Rotar nombres de las variables
        col = "skyblue",               # Color de las barras
        names.arg = imp_sorted$Variable,  # Nombres de las variables
        cex.names = 0.7,               # Ajustar tamaño de los nombres
        horiz = TRUE,                  # Barra horizontal
        cex.axis = 0.7,                # Ajustar tamaño de los números del eje
        xlab = "Importancia",          # Título para el eje X
        ylab = "Variables")            # Título para el eje Y


```

**Selección de Variables para la Clasificación de Medios de Transporte**

El análisis basado en el criterio de **Mean Decrease Gini** permitió identificar las variables más relevantes para el modelo de clasificación. Sin embargo, además de considerar la importancia relativa de cada variable, también se evaluó su relevancia específica en el contexto de la **predicción de medios de transporte**, reconociendo que ciertas características, aunque con menor importancia en el análisis, pueden ser fundamentales para capturar las dinámicas propias de cada tipo de transporte.

### **Variables Seleccionadas**

1.  **Dinámicas de Movimiento (Aceleración y Giroscopios):** Estas variables son esenciales para describir los patrones característicos de movimiento, como aceleración, frenado y giros, que diferencian medios de transporte como coches, bicicletas o aviones:

    -   `accelX.g.`, `accelY.g.`, `accelZ.g.`

    -   `Roll.rads.`, `Pitch.rads.`, `Yaw.rads.`

2.  **Contexto Ambiental:** Estas variables aportan información crítica sobre las condiciones del entorno, como la altitud y la presión, que son especialmente útiles para diferenciar medios terrestres y aéreos:

    -   `Pressure.kilopascals.` (presión atmosférica)

    -   `RelativeAltitude.meters.` (altitud relativa)

3.  **Variables Moderadamente Importantes:** Aunque variables como `m11`, `m12`, `m13`, `m21`, `m22`, y `m33` no están entre las de mayor importancia relativa, complementan la información de orientación y dinámica, contribuyendo al modelo en escenarios más complejos.

### **Variables Excluidas**

Se decidió excluir variables con baja relevancia relativa o redundancia:

-   `accelUserX.g.`, `accelUserY.g.`, `accelUserZ.g.`

-   `gyroX.rad.s.`, `gyroZ.rad.s.`

# 9. Pasos a seguir: 

1.  **Eliminación de Variables no Relevantes:**\
    Basado en el análisis de importancia relativa con el criterio de **Mean Decrease Gini**, se eliminarán las variables propuestas que aportan baja relevancia al modelo. Esto reducirá la redundancia y permitirá un enfoque más eficiente en las características clave para la clasificación de medios de transporte.

2.  **Aplicación de Técnicas para Abordar el Desbalance de Clases:**\
    Implementar técnicas como **SMOTE (Synthetic Minority Oversampling Technique)** para aumentar la representación de las clases minoritarias y **ajuste de pesos en el modelo** para penalizar los errores en estas clases. Esto garantizará que el modelo sea más equilibrado y robusto frente al desbalance de clases.

3.  **Entrenamiento del Modelo y Evaluación de Resultados:**\
    Entrenar nuevamente el modelo con las variables seleccionadas y las técnicas de balanceo aplicadas. Evaluar su desempeño utilizando métricas como sensibilidad, precisión balanceada y F1-score para asegurar mejoras en la clasificación de las clases minoritarias.

4.  **Exploración de Nuevos Métodos de Entrenamiento:**\
    Probar configuraciones avanzadas, incluyendo:

    -   **Funciones Radiales Gamma:** Para capturar patrones no lineales en los datos.

    -   **Funciones Sigmoidales:** Útiles para manejar relaciones complejas entre características.

5.  **Chequeo de la Curva ROC y Análisis de Overfitting:**\
    Analizar las curvas ROC para cada clase y revisar posibles indicadores de overfitting, especialmente dado el desempeño aparentemente perfecto en los resultados actuales. Esto ayudará a identificar si el modelo está generalizando correctamente.

6.  **Aplicación de Validación Cruzada:**\
    Implementar técnicas de validación cruzada para evaluar la estabilidad del modelo en diferentes subconjuntos de datos. Esto permitirá verificar la capacidad del modelo para generalizar y evitar problemas de sobreajuste.

# **Para el Paper**

> El problema del **desbalance de clases** en el aprendizaje supervisado es ampliamente reconocido en la literatura como un factor que afecta negativamente el rendimiento de los modelos de clasificación (He & Garcia, 2009). En particular, **las Máquinas de Soporte Vectorial (SVM)** tienden a sesgarse hacia la clase mayoritaria debido a su objetivo de minimizar el error global, lo que perjudica la clasificación de la clase minoritaria (Fernández et al., 2011).
>
> #### **Uso de SMOTE para Mejorar la Representación de la Clase Minoritaria**
>
> Para abordar este problema, se han propuesto diversas estrategias, entre las cuales el **Oversampling Sintético** a través de **SMOTE (Synthetic Minority Over-sampling Technique)** se ha consolidado como una de las técnicas más efectivas (Chawla et al., 2002). En lugar de replicar instancias existentes, como ocurre en el oversampling tradicional, **SMOTE genera nuevas instancias sintéticas interpolando puntos en el espacio de características entre ejemplos de la clase minoritaria**, lo que contribuye a mejorar la representatividad del modelo sin introducir redundancia en los datos (Fernández et al., 2018).
>
> SMOTE ha sido evaluado en múltiples estudios y se ha demostrado que mejora significativamente la sensibilidad (recall) en modelos de clasificación sin degradar el rendimiento de la clase mayoritaria (Fernández et al., 2013). Esto es particularmente útil en aplicaciones médicas y de detección de fraudes, donde la detección de la clase minoritaria es crucial (López et al., 2012).
>
> #### **Ajuste de Pesos en SVM para Compensar el Desbalance**
>
> Además del uso de SMOTE, se ha encontrado que **ajustar los pesos de penalización en la SVM** puede mejorar aún más el rendimiento en escenarios desbalanceados. Vapnik (1999) estableció que el **parámetro de costo (`C`)** en las SVM regula la importancia de minimizar los errores de clasificación. Al aplicar **pesos inversamente proporcionales a la frecuencia de cada clase**, se logra compensar el desbalance, asegurando que los errores en la clase minoritaria sean más penalizados durante el proceso de optimización (Akbani et al., 2004).
>
> En particular, el trabajo de He y Ma (2013) mostró que el uso combinado de **SMOTE + Ajuste de Pesos en SVM** ofrece una mejora sustancial en términos de **precisión balanceada, sensibilidad y F1-score**, superando métodos convencionales como el undersampling o el simple oversampling.

Referencias:

-   Akbani, R., Kwek, S., & Japkowicz, N. (2004). Applying Support Vector Machines to Imbalanced Datasets. *European Conference on Machine Learning*.

-   Chawla, N. V., Bowyer, K. W., Hall, L. O., & Kegelmeyer, W. P. (2002). SMOTE: Synthetic Minority Over-sampling Technique. *Journal of Artificial Intelligence Research, 16*, 321-357.

-   Fernández, A., García, S., & Herrera, F. (2011). Addressing the Classification with Imbalanced Data: Open Problems and New Challenges. *Lecture Notes in Artificial Intelligence, 6678*, 1–10.

-   Fernández, A., et al. (2013). Learning from Imbalanced Data: Open Challenges and Future Directions. *Progress in Artificial Intelligence, 1*(1), 1-12.

-   He, H., & Garcia, E. A. (2009). Learning from imbalanced data. *IEEE Transactions on Knowledge and Data Engineering, 21*(9), 1263-1284.

-   He, H., & Ma, Y. (2013). Imbalanced Learning: Foundations, Algorithms, and Applications. *Wiley-IEEE Press*.

-   López, V., Fernández, A., Galar, M., & Herrera, F. (2012). Analysis of preprocessing vs. cost-sensitive learning for imbalanced classification. *Expert Systems with Applications, 39*(7), 6585-6608.

-   Vapnik, V. N. (1999). The Nature of Statistical Learning Theory. *Springer-Verlag*.
