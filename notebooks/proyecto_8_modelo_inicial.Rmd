---
title: "Prediccion de Tipo de Transporte - Proyecto de Transporte"
output: html_notebook
---

### General: Objetivos del Proyecto y Definición de Variables

El objetivo principal de este proyecto es desarrollar un modelo basado en **Máquinas de Vectores de Soporte (SVM)** para predecir el **modo de transporte** utilizado por un individuo en función de los datos recopilados por sensores de dispositivos móviles. Se busca analizar cómo las diferentes señales captadas por el acelerómetro, giróscopo, barómetro, GPS y magnetómetro pueden ser utilizadas para inferir con precisión el medio de transporte en uso.

Para lograr esto, se cuenta con un conjunto de datos que incluye:

1.  **Registro Temporal**

    -   Cada observación está asociada a un instante de tiempo específico.

2.  **Datos de Movimiento y Orientación**

    -   **Acelerómetro**: Componentes X, Y, Z del vector aceleración.

    -   **Giróscopo**: Velocidad angular en los ejes X, Y, Z y su derivada.

    -   **Matriz de Rotación y Cuaterniones**: Representan la orientación tridimensional del dispositivo.

3.  **Datos de Ubicación y Contexto**

    -   **GPS**: Coordenadas de latitud y longitud, velocidad, altitud y rumbo.

    -   **Presión Atmosférica**: Valores obtenidos del barómetro, junto con la altitud relativa.

    -   **Campo Magnético Terrestre**: Medición en los ejes X, Y, Z.

4.  **Variables Categóricas**

    -   **Modo de Transporte**: La categoría que se busca predecir (caminar, bicicleta, automóvil, etc.).

    -   **Nivel de Confianza**: Un indicador de la precisión estimada para la clasificación del transporte en los datos originales.

### Objetivo Notebook:

El objetivo de este notebook es realizar una preselección de variables clave para la construcción de un modelo basado en Máquinas de Vectores de Soporte (SVM) que permita predecir el modo de transporte a partir de datos de sensores de dispositivos móviles.

# **1. Carga de librerías**

```{r}
# Lista de paquetes necesarios
necessary_packages <- c("dplyr", "caret", "e1071", "robustbase", "ggplot2", "data.table", "pROC","doParallel" )

# Instalar paquetes que no están instalados
new_packages <- necessary_packages[!(necessary_packages %in% installed.packages()[, "Package"])]
if (length(new_packages) > 0) {
  install.packages(new_packages)
}

# Cargar todos los paquetes
lapply(necessary_packages, library, character.only = TRUE)
```

```{r}
# Cargar las librerías necesarias
library(caret)      # Para división estratificada y evaluación de modelos
library(scales)     # Para Min-Max Scaling
library(e1071)      # Para entrenar SVM
library(randomForest)  # Para obtener la importancia de las variables
library(dplyr)      # Para manipulación de datos
# Cargar la librería
library(visdat)
# Cargar la librería
library(tidyr)
# Cargar el paquete 'car'
library(car)
library(ggplot2)
library(stringr) #Cambiar variables
```

# 2. Cargar el dataset

```{r}
# Ruta del archivo CSV (modificar según tu sistema)
ruta_dataset <- "C:/Users/Lenovo/Documents/IT Academy/Datos proyecto 8/proyect8/input_data/dataframes_modificado.csv"
data <- read.csv(ruta_dataset)


data <- read.csv(ruta_dataset)

# Resumen del dataset
cat("### Información General del Dataset")
dim(data) # Dimensiones del dataset
str(data) # Estructura del dataset

```

```{r}
summary(data) # Resumen estadístico básico
```

## 2.1 Adecuación del dataset

```{r}
# Usando la función table()
actividad_count <- table(data$ActivityType)
print(actividad_count)

```

```{r}
# Eliminar la columna "ActivityConfidence"
data <- data[, !names(data) %in% "ActivityConfidence"]

# Crear la nueva columna "herzios" basada en "ActivityType"
data$herzios <- ifelse(data$ActivityType == "Avion", 10,
                    ifelse(data$ActivityType == "Coche autopista", 2,
                    ifelse(data$ActivityType == "Autobus", 50,
                    ifelse(data$ActivityType == "Bicleta", 50,
                    ifelse(data$ActivityType == "Andando", 100,
                    ifelse(data$ActivityType == "Coche Urbano 100", 100,
                    ifelse(data$ActivityType == "Coche Urbano 250", 250,
                    ifelse(data$ActivityType == "Coche carretera", 100, 0))))))))
```

```{r}
data %>%
  count(ActivityType, sort = TRUE)

# Reemplazar las categorías 'Coche autopista' y 'Coche carretera' por 'Coche'
data <- data %>%
  mutate(ActivityType = str_replace(ActivityType, "Coche autopista|Coche carretera", "Coche_autopista"))

data <- data %>%
  mutate(ActivityType = str_replace(ActivityType, "Coche Urbano 250|Coche Urbano 100", "Coche_urbano"))

data <- data %>%
  mutate(ActivityType = str_replace(ActivityType, "Bicleta", "Bicicleta"))

# Verificar los primeros valores de ActivityType después del reemplazo
head(data$ActivityType)
```

```{r}
str(data)
```

# 3. Análisis de Datos

## 3.1 Detección de Valores faltantes

Identificar valores faltantes es crucial porque pueden afectar el rendimiento del modelo predictivo. Este paso ayuda a decidir estrategias para imputar o manejar estos valores.

```{r}
cat("### Análisis de Valores Faltantes\n")
# Resumen de valores faltantes por columna
print(sapply(data, function(x) sum(is.na(x))))

# Visualización de valores faltantes mejorada
vis_miss(data) +
  ggtitle("Mapa de Valores Faltantes") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, size = 8), # Ajuste de las etiquetas del eje X
    axis.text.y = element_text(size = 10),                       # Ajuste de las etiquetas del eje Y
    plot.title = element_text(hjust = 0.5, size = 14)            # Centrar y ajustar tamaño del título
  )

```

El análisis muestra que no hay valores nulos en el dataset. Esto significa que todas las variables contienen información completa para las 816 observaciones registradas. Este resultado asegura que no será necesario realizar técnicas de imputación de datos.

## 3.2 Detección de Outliers Univariantes

Usaremos el rango intercuartílico (IQR) para identificar outliers y calcular el porcentaje de valores extremos en cada variable numérica.

```{r}
# Extraer solo las columnas numéricas
num_data <- data %>% select(where(is.numeric))

if (ncol(num_data) > 0) {
  cat("### Análisis de Outliers\n")
  
  # Cálculo de outliers por IQR
  outlier_detection <- num_data %>%
    summarise(across(everything(), ~ {
      q1 <- quantile(.x, 0.25, na.rm = TRUE)
      q3 <- quantile(.x, 0.75, na.rm = TRUE)
      iqr <- q3 - q1
      sum(.x < (q1 - 1.5 * iqr) | .x > (q3 + 1.5 * iqr), na.rm = TRUE) / length(.x) * 100
    }))
  
  # Transponer la tabla
  outlier_detection <- as.data.frame(t(outlier_detection))
  outlier_detection$Variable <- rownames(outlier_detection)
  rownames(outlier_detection) <- NULL
  
  # Reordenar las columnas
  outlier_detection <- outlier_detection %>%
    select(Variable, `V1`) %>%  # Mantiene "V1" como nombre original
    arrange(desc(`V1`))  # Ordenar de mayor a menor

  # Mostrar la tabla
  print(outlier_detection)

} else {
  cat("No hay columnas numéricas en el dataset.\n")
}

```

**Visualización de Outliers**

Utilizaremos boxplots para visualizar los outliers en cada variable numérica.

```{r}
if (ncol(num_data) > 0) {
  # Transformar datos a formato largo
  num_data_long <- num_data %>%
    pivot_longer(cols = everything(), names_to = "Variable", values_to = "Valor")
  
  # Dividir las variables en grupos de 6
  variable_groups <- split(unique(num_data_long$Variable), ceiling(seq_along(unique(num_data_long$Variable)) / 6))

  for (group in variable_groups) {
    # Filtrar las variables del grupo actual
    group_data_long <- num_data_long %>% filter(Variable %in% group)
    
    # Crear los boxplots
    print(
      ggplot(group_data_long, aes(x = Variable, y = Valor)) +
        geom_boxplot(outlier.colour = "red", outlier.size = 1.5, fill = "lightblue") +
        theme_minimal() +
        labs(
          title = "Visualización de Outliers",
          x = "Variable",
          y = "Valores"
        ) +
        theme(
          plot.title = element_text(size = 8, hjust = 0.5),
          axis.text.x = element_text(angle = 0, hjust = 1)
        ) +
        facet_wrap(~ Variable, scales = "free", ncol = 3)  # Cambia "ncol" a 2 o 3 según el diseño que prefieras
    )
  }
} else {
  cat("No hay variables numéricas en el dataset.\n")
}
```

## **3.3** Analisisis de Influencias

## 3.3.1. **Correlacion en el conjunto de datos**

```{r}
library(knitr)      # Para formatear tablas
library(kableExtra) # Para mejorar la presentación


# Calcular la matriz de correlación
cor_matrix <- cor(num_data, use = "complete.obs")

# Redondear para mejor visualización
cor_matrix_rounded <- round(cor_matrix, 2)

# Imprimir la matriz de correlación en la consola
print(cor_matrix_rounded)

# Alternativamente, generar una tabla con kable si prefieres una salida más ordenada

kable(cor_matrix_rounded, caption = "Tabla de Correlaciones (Excluyendo Variables No Relevantes)")
```

```{r}
library(ggplot2)
library(reshape2)

# Convertir la matriz en formato largo
corr_melted <- melt(cor_matrix)

# Crear el heatmap
ggplot(corr_melted, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "steelblue", high = "darkred", mid = "white", midpoint = 0, name = "Correlación") +
  theme_minimal(base_size = 6) +  # Aumentar el tamaño del texto
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, size = 10),
    axis.text.y = element_text(size = 10),
    plot.title = element_text(hjust = 0.5, size = 14),
    legend.text = element_text(size = 10),
    legend.title = element_text(size = 12)
  ) +
  labs(
    title = "Mapa de Calor de Correlaciones",
    x = "Variables",
    y = "Variables"
  ) +
  coord_fixed()
```

## **3.3.2 Colinealidad**

```{r}
library(dplyr)

# Verificar que el dataset existe
if (exists("data")) {
  # Filtrar las variables numéricas y eliminar la variable dependiente (ActivityType)
  num_data_filtered <- data %>%
    select(where(is.numeric)) %>%
    mutate(dummy_target = runif(nrow(.), 0, 1)) # Crear una variable dummy temporal

  # Validar si hay suficientes variables para calcular el modelo
  if (ncol(num_data_filtered) > 1) {
    # Crear un modelo de regresión con las variables predictoras
    vif_model <- lm(dummy_target ~ ., data = num_data_filtered)
    
    # Calcular los valores de VIF
    vif_values <- vif(vif_model)
    
    # Imprimir los valores de VIF
    print("### Factores de Inflación de Varianza (VIF)")
    print(vif_values)
    
    # Identificar variables con alta colinealidad (VIF > 10 como umbral común)
    high_vif <- vif_values[vif_values > 10]
    if (length(high_vif) > 0) {
      cat("\nVariables con alta colinealidad (VIF > 10):\n")
      print(high_vif)
    } else {
      cat("\nNo se encontraron variables con alta colinealidad (VIF <= 10).\n")
    }
  } else {
    cat("No hay suficientes variables numéricas para calcular el VIF.\n")
  }
} else {
  cat("El dataset 'data' no existe en el entorno.\n")
}
```

> En el análisis de los datos, hemos observado que algunas variables, como `qX`, `qY` y `gyroX.rad.s.`, están fuertemente correlacionadas entre sí y también con otras variables clave del modelo, como las mediciones magnéticas (`magX.µT.`, `magY.µT.`). Esta alta colinealidad genera un aumento en los **Factores de Inflación de Varianza (VIF)**, con varios valores superiores a 10. Esto indica que algunas de estas variables están aportando la misma información, lo que provoca redundancia en el modelo.
>
> La presencia de estas variables altamente correlacionadas puede afectar la estabilidad y precisión de las predicciones. En particular, las variables relacionadas con las matrices de rotación y el campo magnético tienden a influir de manera similar, lo que dificulta que el modelo identifique correctamente las variables más importantes.
>
> Para mejorar la precisión y estabilidad del modelo, sería recomendable eliminar estas variables colineales, como `qX`, `qY` y `gyroX.rad.s.`, así como las variables magnéticas. De esta forma, reducimos la redundancia, lo que permitirá que el modelo funcione de manera más eficiente y que los resultados sean más fáciles de interpretar.

### 3.3.3. ANOVA

l análisis de **Factor de Inflación de Varianza (VIF)** reveló la presencia de **alta colinealidad** entre varias variables, lo que indica redundancia y posible inestabilidad en el modelo. Para abordar esto, se aplica **ANOVA** con el fin de:

✅ **Seleccionar solo las variables con diferencias significativas entre las clases de `ActivityType`**\
✅ **Eliminar variables con VIF alto que no aporten información relevante**\
✅ **Reducir la redundancia y mejorar la capacidad de generalización del modelo**

Se consideran significativas las variables con **p \< 0.05**, asegurando que solo aquellas que realmente influyen en la clasificación sean retenidas. Esto optimiza el modelo, evitando sobreajuste y mejorando la interpretación de los resultados.

```{r}
library(dplyr)
library(purrr)

num_vars <- names(data)[sapply(data, is.numeric)]
num_vars <- setdiff(num_vars, "ActivityType")


# Calcular ANOVA para todas las variables numéricas
anova_results <- map_dbl(num_vars, ~anova(lm(data[[.x]] ~ data$ActivityType))$`Pr(>F)`[1])

# Crear un dataframe con los resultados
anova_df <- data.frame(Variable = num_vars, P_Value = anova_results)

# Filtrar variables con p < 0.05 (significativas)
variables_significativas <- anova_df %>% filter(P_Value < 0.05) %>% arrange(P_Value)

# Mostrar las variables significativas
print(variables_significativas)

```

```{r}
library(ggplot2)

# Crear una nueva columna indicando si la variable es significativa
anova_df <- anova_df %>%
  mutate(Significativa = ifelse(P_Value < 0.05, "Significativa (p < 0.05)", "No significativa (p >= 0.05)"))

# Crear gráfico de barras
ggplot(anova_df, aes(x = reorder(Variable, -P_Value), y = -log10(P_Value), fill = Significativa)) +
  geom_bar(stat = "identity", position = "identity") +
  scale_fill_manual(values = c("Significativa (p < 0.05)" = "steelblue", "No significativa (p >= 0.05)" = "red")) +
  labs(title = "Resultados de ANOVA - Variables Significativas vs No Significativas",
       x = "Variables", y = "-log10(p-value)",
       fill = "Significancia") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  geom_hline(yintercept = -log10(0.05), linetype = "dashed", color = "gray")  # Línea de referencia en p = 0.05

```

Para definir las variables más relevantes en la predicción del tipo de transporte, se han utilizado los siguientes enfoques:

✅ **1. ANOVA (Análisis de Varianza):** Se identificaron las variables con **p-valores menores a 0.05**, lo que indica que presentan diferencias significativas entre las clases de `ActivityType`.\
✅ **2. VIF (Factor de Inflación de la Varianza):** Se analizaron las variables con **VIF \> 10** para identificar posibles redundancias.\
✅ **3. Validación con Importancia en Random Forest (RF):** Se propone validar las variables seleccionadas a través del criterio `MeanDecreaseGini`, que permite medir la contribución real de cada variable en la clasificación.

## **3.4** Distribución de las Clases en `ActivityType`

```{r}
# Crear un gráfico de barras para la variable 'target_variable' con un solo color
ggplot(data, aes(x = ActivityType)) + 
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Distribución de las Clases en la Variable `ActivityType`", 
       x = "Clases", y = "Frecuencia") +
  theme_minimal()

```

> El gráfico muestra la distribución de las clases en la variable objetivo `ActivityType`. Es evidente que existe un desbalance significativo en los datos, donde la clase `Coche_urbano` domina ampliamente con la mayor cantidad de observaciones, seguida por `Andando` y `Bicicleta`. En contraste, las clases `Avión` y `Coche_autopista` tienen una representación mucho menor, lo que podría generar desafíos para el modelo al clasificar estas clases minoritarias.
>
> ### **Implicaciones del Desbalance**
>
> 1.  **Riesgo de Sesgo hacia la Clase Mayoritaria:**\
>     El modelo puede sesgarse hacia la clase mayoritaria (`Coche_urbano`) durante el entrenamiento, ya que la mayoría de los ejemplos pertenecen a esta clase. Esto podría conducir a una alta precisión global aparente, pero con un rendimiento deficiente en las clases minoritarias (`Avión`, `Coche_autopista`).
>
> 2.  **Impacto en Métricas como Sensibilidad y F1-score:**\
>     El desbalance puede afectar negativamente métricas como la sensibilidad y el F1-score para las clases menos representadas, lo que es crítico en aplicaciones donde la detección precisa de estas clases es importante.

# 4. Imputacion de Variables

## 4.1 Eliminacion de Variables

Las variables `qX`, `qY` y `qZ` serán eliminadas debido a su alta correlación con las **matrices de rotación**. Estas variables aportan información redundante al modelo y, para evitar problemas de multicolinealidad, se ha decidido priorizar las **matrices de rotación**, que ya encapsulan la información necesaria para describir la orientación del objeto en movimiento.

Por otro lado, las variables asociadas al **campo magnético** (`magX.µT.`, `magY.µT.`, `magZ.µT.`, `calMagX.µT.`, `calMagY.µT.`, `calMagZ.µT.`) también serán eliminadas, pero por un motivo distinto. Aunque estas variables no están directamente relacionadas con las matrices de rotación, el campo magnético tiene un **impacto significativo en la clasificación de los tipos de transporte**. Las señales magnéticas pueden ser similares entre distintos medios de transporte, como coches, trenes o aviones, lo que puede generar confusión en el modelo. Al eliminar estas variables, se evita que el modelo dependa de estas señales que pueden no ser determinantes para la tarea de clasificación.

```{r}
# Eliminar las columnas especificadas del dataset
columns_to_remove <- c("qX", "qY", "qZ", "qW", "magX.µT.", "magY.µT.", "magZ.µT.", 
                       "calMagX.µT.", "calMagY.µT.", "calMagZ.µT.")

# Eliminar las columnas del dataset
data <- data[, !(colnames(data) %in% columns_to_remove)]

# Verificar las primeras filas después de eliminar las columnas
head(data)
```

## 4.2 Imputacion de Outliers

La imputación mediante **winsorización** es un enfoque útil para tratar los outliers extremos en los datos. En este caso, se ha aplicado winsorización a las variables con más del 10% de outliers, como `gyroZ.rad.s.`, `Roll.rads.`, `gyroX.rad.s.`, entre otras. Este proceso consiste en limitar los valores de las variables fuera de un rango específico, utilizando los percentiles 1 y 99. De esta manera, los valores extremos son reemplazados por los valores más cercanos en esos percentiles, lo que reduce el impacto de los outliers sin eliminar completamente los datos.

```{r}
# Función para calcular outliers por IQR por cada grupo de ActivityType
calculate_outliers_by_activity <- function(df, group_col = "ActivityType") {
  df %>%
    group_by(!!sym(group_col)) %>%
    summarise(across(where(is.numeric), ~ {
      q1 <- quantile(.x, 0.25, na.rm = TRUE)
      q3 <- quantile(.x, 0.75, na.rm = TRUE)
      iqr <- q3 - q1
      outliers <- sum(.x < (q1 - 1.5 * iqr) | .x > (q3 + 1.5 * iqr), na.rm = TRUE)
      return(outliers / length(.x) * 100)  # Retornar el porcentaje de outliers
    })) %>%
    pivot_longer(cols = where(is.numeric),
                 names_to = "Variable", values_to = "Outliers (%)") %>%
    pivot_wider(names_from = ActivityType, values_from = `Outliers (%)`) %>%
    arrange(Variable)  # Reordenar por las variables
}

# Calcular outliers por cada tipo de actividad
outliers_by_activity <- calculate_outliers_by_activity(data)

# Mostrar los resultados
print(outliers_by_activity)

```

```{r}
# Variables y actividades que tienen más del 10% de outliers
columns_to_impute <- c("gyroX.rad.s.", "gyroZ.rad.s.", "accelX.g.", "accelUserX.g.", "m21")
activities_to_impute <- c("Coche Urbano 100", "Coche autopista", "Avion", "Bicicleta")

# Función para imputar outliers usando la mediana dentro de cada actividad
replace_outliers_by_activity_specific <- function(df, group_col = "ActivityType", outlier_threshold = 10) {
  df_no_outliers <- df
  df_no_outliers <- df_no_outliers %>%
    group_by(!!sym(group_col)) %>%
    mutate(across(all_of(columns_to_impute), ~ {
      Q1 <- quantile(.x, 0.25, na.rm = TRUE)
      Q3 <- quantile(.x, 0.75, na.rm = TRUE)
      IQR <- Q3 - Q1
      lower_limit <- Q1 - 1.5 * IQR
      upper_limit <- Q3 + 1.5 * IQR
      outlier_pct <- sum(.x < lower_limit | .x > upper_limit, na.rm = TRUE) / length(.x) * 100
      
      # Solo reemplazar los outliers si superan el umbral (10%)
      if (outlier_pct > outlier_threshold) {
        .[. < lower_limit | . > upper_limit] <- median(.x, na.rm = TRUE)
      }
      return(.)
    })) %>%
    ungroup()
  
  return(df_no_outliers)
}

# Filtrar solo las actividades con outliers altos
data_filtered <- data %>%
  filter(ActivityType %in% activities_to_impute)

# Aplicar imputación de outliers en las actividades seleccionadas
data_no_outliers_activity_replaced_specific <- replace_outliers_by_activity_specific(data_filtered)

# Verificar los cambios después de reemplazar outliers
summary(data_no_outliers_activity_replaced_specific)
head(data_no_outliers_activity_replaced_specific)

```

```{r}
# 2. Asegurar que los datos originales y modificados se combinen correctamente sin duplicar
data_combined <- data %>%
  left_join(data_no_outliers_activity_replaced_specific %>%
              select(ActivityType, all_of(columns_to_impute)) %>%
              rename_with(~paste0(., "_imputed"), all_of(columns_to_impute)), 
            by = "ActivityType") %>%
  # Mantener las columnas originales si no fueron modificadas
  mutate(across(all_of(columns_to_impute), 
                ~ ifelse(is.na(get(paste0(cur_column(), "_imputed"))), .x, get(paste0(cur_column(), "_imputed"))), 
                .names = "{col}")) %>%
  # Eliminar las columnas imputadas que no necesitamos
  select(-ends_with("_imputed"))

# Verificar los cambios
summary(data_combined)
head(data_combined)
```

```{r}
# Verificar las columnas disponibles en el dataframe
str(data)

```

```{r}
# Guardar el dataset modificado en el directorio de trabajo actual
write.csv(data, "data_vars_imputadas.csv", row.names = FALSE)

# Mostrar el directorio de trabajo actual
cat("El dataset ha sido guardado en el directorio de trabajo actual:", getwd())

```

# 5. Escalado de Datos

Utilizamos **Min-Max Scaling, porque trabaja mejor con SVM**

```{r}
# Convertir las variables categóricas a factor
data$ActivityType <- factor(data$ActivityType)
```

```{r}
# Lista de columnas numéricas
num_columns <- sapply(data, is.numeric)

# Aplicar Min-Max Scaling a todas las columnas numéricas
data[num_columns] <- lapply(data[num_columns], function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
})

# Verificar el rango después del escalado
summary(data[num_columns])

```

```{r}
summary(data)
```

# 6. Dividir los datos en entrenamiento y test

```{r}
set.seed(123)

# Crear la partición (estratificación)
split <- createDataPartition(data$ActivityType, p = 0.80, list = FALSE)  # 80% entrenamiento, 20% test
train_set <- data[split, ]
test_set <- data[-split, ]
```

# 7. Modelo SVM

## 7.1 entrenar el modelo

```{r}
# Medir el tiempo de entrenamiento con probabilidad habilitada
train_time <- system.time({
  svm_model <- svm(ActivityType ~ ., data = train_set, probability = TRUE)  # Activar probabilidades
})

# Medir el tiempo de predicción
predict_time <- system.time({
  predictions <- predict(svm_model, test_set, probability = TRUE)  # Obtener predicciones con probabilidades
})

# Imprimir los tiempos
print(train_time)
print(predict_time)
```

## 7.2 Evaluar el rendimiento del modelo

```{r}
# Evaluar el rendimiento del modelo
confusionMatrix(predictions, test_set$ActivityType)

```

El análisis de la matriz de confusión muestra que el modelo alcanzó una precisión perfecta (Accuracy = 1) con valores de sensibilidad y especificidad de 1.0000 para todas las clases. Sin embargo, la prevalencia de las clases indica un **desbalance significativo** en los datos. Por ejemplo, la clase mayoritaria (`Coche_urbano`) representa el 48.23% de las instancias, mientras que las clases minoritarias, como `Avión` (3.19%) y `Bicicleta` (11.72%), tienen una representación considerablemente menor. Este desbalance puede no afectar el rendimiento actual debido a la alta diferenciación en las características, pero podría impactar la **generalización del modelo** en datos no vistos o en escenarios con distribuciones de clases más equilibradas.

Para abordar este problema y garantizar la robustez del modelo, se propone la implementación de dos estrategias:

1.  **SMOTE (Synthetic Minority Oversampling Technique):**\
    Esta técnica permite aumentar la representación de las clases minoritarias mediante la generación de ejemplos sintéticos que interpolan instancias existentes de estas clases. Esto mejora la sensibilidad y el rendimiento en la clasificación de las clases menos representadas, evitando los problemas de sobreajuste asociados con el oversampling tradicional.

2.  **Ajuste de Pesos en SVM:**\
    Ajustar los pesos de penalización en la SVM permite compensar el desbalance asignando un mayor peso a las clases minoritarias. De esta forma, los errores en estas clases son más penalizados durante el entrenamiento, equilibrando el impacto de la clase mayoritaria en el modelo.

Los resultados actuales muestran que el modelo puede clasificar perfectamente todas las clases bajo las condiciones de este dataset, pero la prevalencia desigual sugiere la necesidad de incorporar estas estrategias para garantizar una mayor robustez en escenarios más variados. Estudios previos han demostrado que la combinación de **SMOTE + Ajuste de Pesos** mejora significativamente métricas clave como precisión balanceada, sensibilidad y F1-score, asegurando un mejor rendimiento en la clasificación de medios de transporte con clases minoritarias relevantes.

```{r}
# Crear una malla de puntos en el espacio 2D
x_min <- min(train_set$accelX.g.)
x_max <- max(train_set$accelX.g.)
y_min <- min(train_set$accelY.g.)
y_max <- max(train_set$accelY.g.)

grid <- expand.grid(
  accelX.g. = seq(x_min, x_max, length.out = 100),
  accelY.g. = seq(y_min, y_max, length.out = 100)
)

# Obtener las variables predictoras usadas en el modelo (excluyendo ActivityType)
predictors <- setdiff(names(train_set), "ActivityType")

# Identificar variables numéricas y categóricas
num_vars <- names(train_set)[sapply(train_set, is.numeric)]
cat_vars <- setdiff(predictors, num_vars)

# Crear un dataframe con todas las columnas necesarias
grid_full <- as.data.frame(matrix(ncol = length(predictors), nrow = nrow(grid)))
names(grid_full) <- predictors

# Asignar valores de accelX.g. y accelY.g. desde la malla de puntos
grid_full$accelX.g. <- grid$accelX.g.
grid_full$accelY.g. <- grid$accelY.g.

# Para las variables numéricas, asignar el promedio de train_set
for (col in num_vars) {
  if (!(col %in% c("accelX.g.", "accelY.g."))) {
    grid_full[[col]] <- mean(train_set[[col]], na.rm = TRUE)
  }
}

# Para las variables categóricas, asignar la categoría más frecuente de train_set
for (col in cat_vars) {
  most_frequent <- names(which.max(table(train_set[[col]])))  # Obtener la categoría más frecuente
  grid_full[[col]] <- factor(rep(most_frequent, nrow(grid_full)), levels = levels(train_set[[col]]))
}

# Asegurar que las columnas de grid_full coincidan con las de train_set (menos ActivityType)
grid_full <- grid_full[, names(train_set)[names(train_set) != "ActivityType"]]

# Predecir con el modelo entrenado
grid_full$ActivityType <- predict(svm_model, newdata = grid_full)

# Graficar los datos de entrenamiento y la frontera de decisión
ggplot(train_set, aes(x = accelX.g., y = accelY.g., color = ActivityType)) +
  geom_point(alpha = 0.6) +
  geom_contour(data = grid_full, aes(z = as.numeric(ActivityType)), bins = 1) +
  labs(title = "SVM: Hiperplanos de Decisión en 2D (Solo Train)", x = "accelX.g.", y = "accelY.g.") +
  theme_minimal()



```

```{r}
# Asegúrate de que tu modelo esté entrenado con solo dos variables para graficarlo
# Por ejemplo, seleccionemos dos variables específicas para entrenamiento
train_set_2d <- train_set[, c("accelX.g.", "accelY.g.", "ActivityType")]

# Volver a entrenar el modelo usando solo las dos variables seleccionadas
svm_model_2d <- svm(ActivityType ~ accelX.g. + accelY.g., data = train_set_2d, kernel = "linear")

# Graficar el modelo y los datos
plot(svm_model_2d, train_set_2d, main = "SVM classification plot")

# Agregar una leyenda manualmente
legend("bottom", legend = levels(train_set_2d$ActivityType),
       col = 1:length(levels(train_set_2d$ActivityType)), pch = 1)

```

**Observaciones de los graficos:**

-   El modelo ha logrado identificar regiones claras para la mayoría de las clases (`Andando`, `Coche_urbano`, `Avión`). Esto sugiere que las características seleccionadas (`accelX.g.` y `accelY.g.`) son informativas para la clasificación.

-   Hay áreas donde las clases, como `Autobús` y `Bicicleta`, tienen una ligera superposición en el espacio, lo que podría dificultar la clasificación precisa. Esto podría deberse a la similitud en las características dinámicas de estas actividades.

-   Dado que algunas clases tienen una representación mucho menor en los datos, como `Avión` y `Coche_autopista`, es posible que el modelo sea más sensible a errores en estas clases, especialmente en regiones donde las fronteras son menos claras.

-   Este análisis conecta directamente con los resultados de la matriz de confusión y la distribución de clases, destacando la importancia de las características seleccionadas y la necesidad de estrategias adicionales para optimizar el modelo.\
    \

```{r}
# Instalar pROC si no lo tienes
library(pROC)

```

```{r}
# Obtener probabilidades predichas
predicted_probabilities <- attr(predictions, "probabilities")

# Inicializar gráfico vacío
plot(1, type = "n", xlim = c(0, 1), ylim = c(0, 1),
     xlab = "Tasa de Falsos Positivos (1 - Especificidad)",
     ylab = "Tasa de Verdaderos Positivos (Sensibilidad)",
     main = "Curvas ROC por Clase")
abline(a = 0, b = 1, col = "red", lty = 2)  # Línea de referencia

# Iterar sobre las clases
classes <- colnames(predicted_probabilities)
for (class in classes) {
  # Crear etiquetas binarias para la clase actual
  binary_labels <- ifelse(test_set$ActivityType == class, 1, 0)
  
  # Calcular la curva ROC para esta clase
  roc_curve <- roc(binary_labels, predicted_probabilities[, class])
  
  # Agregar la curva al gráfico
  plot(roc_curve, col = sample(colors(), 1), add = TRUE)
  
  # Mostrar el AUC en consola
  auc_value <- auc(roc_curve)
  cat("AUC para la clase", class, ":", auc_value, "\n")
}

# Agregar leyenda al gráfico
legend("bottomright", legend = classes, col = 1:length(classes), lty = 1)
```

-   **Correcto técnicamente:** El gráfico muestra curvas ROC perfectamente ajustadas con valores de sensibilidad y especificidad ideales para todas las clases, lo que concuerda con las métricas calculadas.

-   **Irrealista en la práctica:** La situación en la que todas las clases tienen una separación perfecta es extremadamente rara en problemas reales. Este comportamiento puede deberse a:

    -   **Sobreajuste:** El modelo está demasiado ajustado al dataset.

    -   **Datos ideales o sin ruido:** Si los datos tienen características muy bien separadas o hay poca variabilidad, el modelo puede mostrar este comportamiento.

    -   **Filtros en los datos:** Si hay una filtración de datos entre el conjunto de entrenamiento y test (por ejemplo, datos duplicados), esto puede dar resultados engañosamente perfectos.

    ### **Pasos a Seguir**

    1.  **Verificar Overfitting:**

        -   Aplicar validación cruzada para evaluar el rendimiento del modelo en diferentes subconjuntos de datos.

        -   Inspeccionar las métricas en entrenamiento y prueba para verificar si hay una discrepancia significativa.

    2.  **Balancear las Clases:**

        -   Implementar técnicas como **SMOTE** y/o ajustar los pesos de las clases en el modelo para abordar el desbalance.

    3.  **Revisar el Dataset:**

        -   Revisar la calidad, correlaci{ones con la variable target y escalado de las variables.

        -   Evaluar el uso de transformaciones adicionales o reducción de dimensionalidad (e.g., PCA).

    4.  **Validación Adicional:**

        -   Auste del parámetro `C` en SVM.

        -   Evaluar las métricas como el **F1-Score** y precisión balanceada para todas las clases.

        -   Inspeccionar errores de clasificación en clases minoritarias.

# 8. Evaluación de la importancia de las variables utilizando RF

```{r}
# Entrenar el modelo Random Forest para obtener la importancia de las variables
rf_model <- randomForest(ActivityType ~ ., data = train_set)

# Ver la importancia de las variables
imp <- importance(rf_model)

# Ver las primeras filas de la importancia
imp
```

```{r}
str(imp)
```

```{r}
# Convertir el vector de importancias en un data frame
imp_df <- data.frame(Variable = rownames(imp), MeanDecreaseGini = imp[, 1])

# Ordenar el data frame por la importancia de mayor a menor
imp_sorted <- imp_df[order(imp_df$MeanDecreaseGini, decreasing = TRUE), ]

# Graficar la importancia de las variables
barplot(imp_sorted$MeanDecreaseGini, 
        main = "Importancia de las Variables", 
        las = 2,                       # Rotar nombres de las variables
        col = "skyblue",               # Color de las barras
        names.arg = imp_sorted$Variable,  # Nombres de las variables
        cex.names = 0.7,               # Ajustar tamaño de los nombres
        horiz = TRUE,                  # Barra horizontal
        cex.axis = 0.7,                # Ajustar tamaño de los números del eje
        xlab = "Importancia",          # Título para el eje X
        ylab = "Variables")            # Título para el eje Y


```

## **📊 Variables Seleccionadas**

Para desarrollar un sistema de clasificación del tipo de transporte, es crucial seleccionar las variables más relevantes y evitar redundancias. En este análisis, utilizamos tres enfoques principales:

-   **Mapa de calor de correlaciones** para identificar relaciones fuertes entre variables.

-   **Factores de Inflación de Varianza (VIF)** para detectar multicolinealidad.

-   **Importancia de las variables (MeanDecreaseGini)** para evaluar su relevancia en la clasificación.

Se identificó **alta correlación** entre las variables de aceleración (`accelX.g`, `accelY.g`, `accelZ.g`), giroscopio (`gyroX.rad.s`, `gyroY.rad.s`, `gyroZ.rad.s`) y variables del grupo `m__` (`m11` a `m33`). Las variables de orientación (`Yaw.rads.`, `Pitch.rads.`, `Roll.rads.`) mostraron correlaciones moderadas con aceleraciones y giroscopios. Variables como `Pressure.kilopascals`, `RelativeAltitude.meters` y `herzios` mostraron **baja correlación con el resto**, indicando que aportan información única.

Con base en el análisis, se seleccionaron las siguientes variables para el modelo:

### **✅ Variables de contexto (presión y altitud)**

-   `Pressure.kilopascals` → Información sobre presión atmosférica, útil para diferenciar transportes en diferentes altitudes (ej. avión vs. coche).

### **✅ Variable de frecuencia de muestreo**

-   `herzios` → Puede indicar la tasa de muestreo del dispositivo, útil en la segmentación de datos.

### **✅ Variables de aceleración (movimiento en los ejes X, Y, Z)**

-   `accelX.g`

-   `accelY.g`

-   `accelZ.g`\
    Estas variables permiten identificar patrones de movimiento y diferencias en los tipos de transporte basadas en fuerzas de aceleración.

### **✅ Variables de giroscopio y orientación**

-   `gyroZ.rad.s` → Se seleccionó este eje como el más representativo del giroscopio.

-   `Pitch.rads.` → Inclinación hacia adelante o atrás, utili para transporte aéros.

-   `Roll.rads.` → Inclinación lateral, para identificar cambios de pendientes.

-   Yaw.rads. → Rotación en el eje Z, clave para identificar cambios de dirección.

### **✅ Variable representativa del grupo `m`**

-   `m33` → Seleccionada como la más relevante según la importancia de variables (MeanDecreaseGini).

## 📌 **Variables Excluidas**

Se decidió excluir variables con baja relevancia relativa o redundancia:

❌ **Variables del grupo `m`**: `m31`, `m21`, `m12`, `m11`, `m22`, `m32, m13, m23` (alta correlación entre sí, se mantiene solo `m33` por su mayor importancia).

❌ **Giroscopios con menor relevancia**: `gyroY.rad.s.`, `gyroZ.rad.s.` (se selecciona solo `gyroZ.rad.s.` por su mayor impacto en MeanDecreaseGini).

❌ **Aceleraciones redundantes**: `accelUserX.g`, `accelUserY.g`, `accelUserZ.g` (altamente correlacionadas con `accelX.g`, `accelY.g` y `accelZ.g`).

### **📊 Variables Seleccionadas y Justificación**

Las siguientes variables han sido retenidas porque:\
✔ **Tienen alta importancia en Random Forest (`MeanDecreaseGini`).**\
✔ **Son significativas en ANOVA (p \< 0.05).**\
✔ **No presentan colinealidad extrema según VIF.**

![](images/clipboard-3932775431.png)

# 9. Pasos a seguir:

1.  **Eliminación de Variables no Relevantes:**\
    Basado en **ANOVA, VIF y `MeanDecreaseGini` en RF**. Se mantienen solo variables clave en **movimiento, aceleración y contexto ambiental**.

2.  **Aplicación de Técnicas para Abordar el Desbalance de Clases:**\
    Implementar técnicas como **SMOTE (Synthetic Minority Oversampling Technique)** para aumentar la representación de las clases minoritarias y **Ajuste de pesos (`class.weights`)** en SVM para penalizar errores en clases menos representadas.

3.  **Entrenamiento del Modelo y Evaluación de Resultados:**\
    Entrenar nuevamente el modelo con las variables seleccionadas y las técnicas de balanceo aplicadas. Evaluar su desempeño utilizando métricas como sensibilidad, precisión balanceada y F1-score para asegurar mejoras en la clasificación de las clases minoritarias.

4.  **Exploración de Nuevos Métodos de Entrenamiento:**\
    Probar configuraciones avanzadas, incluyendo:

    -   **Funciones Radiales Gamma:** Para capturar patrones no lineales en los datos.

    -   **Funciones Sigmoidales:** Útiles para manejar relaciones complejas entre características.

5.  **Evaluación de curvas ROC, matriz de confusión y F1-score para medir mejoras.**\
    Analizar las curvas ROC para cada clase y revisar posibles indicadores de overfitting, especialmente dado el desempeño aparentemente perfecto en los resultados actuales. Esto ayudará a identificar si el modelo está generalizando correctamente.

6.  **Aplicación de Validación Cruzada:**\
    Implementar técnicas de validación cruzada para evaluar la estabilidad del modelo en diferentes subconjuntos de datos. Esto permitirá verificar la capacidad del modelo para generalizar y evitar problemas de sobreajuste.

# 
