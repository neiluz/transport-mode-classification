---
title: "Prediccion de Tipo de Transporte - Modelo SVM - Kernel Simoide - Proyecto de Transporte"
output: html_notebook
---

### General: Objetivos del Proyecto y Definici√≥n de Variables

El objetivo principal de este proyecto es desarrollar un modelo basado en **M√°quinas de Vectores de Soporte (SVM)** para predecir el **modo de transporte** utilizado por un individuo en funci√≥n de los datos recopilados por sensores de dispositivos m√≥viles. Se busca analizar c√≥mo las diferentes se√±ales captadas por el aceler√≥metro, gir√≥scopo, bar√≥metro, GPS y magnet√≥metro pueden ser utilizadas para inferir con precisi√≥n el medio de transporte en uso.

Para lograr esto, se cuenta con un conjunto de datos que incluye:

1.  **Registro Temporal**

    -   Cada observaci√≥n est√° asociada a un instante de tiempo espec√≠fico.

2.  **Datos de Movimiento y Orientaci√≥n**

    -   **Aceler√≥metro**: Componentes X, Y, Z del vector aceleraci√≥n.

    -   **Gir√≥scopo**: Velocidad angular en los ejes X, Y, Z y su derivada.

    -   **Matriz de Rotaci√≥n y Cuaterniones**: Representan la orientaci√≥n tridimensional del dispositivo.

3.  **Datos de Ubicaci√≥n y Contexto**

    -   **GPS**: Coordenadas de latitud y longitud, velocidad, altitud y rumbo.

    -   **Presi√≥n Atmosf√©rica**: Valores obtenidos del bar√≥metro, junto con la altitud relativa.

    -   **Campo Magn√©tico Terrestre**: Medici√≥n en los ejes X, Y, Z.

4.  **Variables Categ√≥ricas**

    -   **Modo de Transporte**: La categor√≠a que se busca predecir (caminar, bicicleta, autom√≥vil, etc.).

    -   **Nivel de Confianza**: Un indicador de la precisi√≥n estimada para la clasificaci√≥n del transporte en los datos originales.

### Objetivo Notebook:

-   Evaluar el rendimiento del modelo Support Vector Machine (SVM) con diferentes configuraciones del kernel Simoidal.

-   Optimizar el modelo SVM mediante la b√∫squeda de hiperpar√°metros.

-   Generar predicciones utilizando el conjunto de test 1.

# **1. Carga de librer√≠as**

```{r}
# Lista de paquetes necesarios
necessary_packages <- c("dplyr", "caret", "e1071", "robustbase", "ggplot2", "data.table", "pROC","doParallel")

# Instalar paquetes que no est√°n instalados
new_packages <- necessary_packages[!(necessary_packages %in% installed.packages()[, "Package"])]
if (length(new_packages) > 0) {
  install.packages(new_packages)
}

# Cargar todos los paquetes
lapply(necessary_packages, library, character.only = TRUE)
```

```{r}
# Cargar las librer√≠as necesarias
library(caret)      # Para divisi√≥n estratificada y evaluaci√≥n de modelos
library(scales)     # Para Min-Max Scaling
library(e1071)      # Para entrenar SVM
library(randomForest)  # Para obtener la importancia de las variables
library(dplyr)      # Para manipulaci√≥n de datos
# Cargar la librer√≠a
library(visdat)
# Cargar la librer√≠a
library(tidyr)
# Cargar el paquete 'car'
library(car)
library(ggplot2)
library(stringr) #Cambiar variables
```

# 2. Cargar el dataset

```{r}
# Ruta del archivo CSV (modificar seg√∫n tu sistema)
ruta_dataset <- "C:/Users/ngonzalez/Documents/Inesdi/Datos proyecto 8/proyect8/data_vars_imputadas.csv"
data <- read.csv(ruta_dataset)


data <- read.csv(ruta_dataset)

# Resumen del dataset
cat("### Informaci√≥n General del Dataset")
dim(data) # Dimensiones del dataset
str(data) # Estructura del dataset

```

```{r}
summary(data) # Resumen estad√≠stico b√°sico
```

## 2.1 Selecci√≥n de las Variables de acuerdo a RF, VIF y Anova

```{r}
# Seleccionar solo las variables relevantes
data_filtrado <- data %>%
  select(accelX.g., accelZ.g., accelY.g.,  # Aceleraci√≥n
         Roll.rads., Pitch.rads., Yaw.rads., gyroY.rad.s.,  # Giroscopios
         Pressure.kilopascals., herzios,  # Contexto ambiental
         m33,  # Componentes de Movimiento
         ActivityType)  # Variable objetivo

# Guardar el dataset actualizado
write.csv(data_filtrado, "dataset_filtrado.csv", row.names = FALSE)

# Mostrar primeras filas del dataset filtrado
head(data_filtrado)
```

```{r}
str ( data_filtrado)
```

# 3. Implementar `class.weights` combinado para ajustar el desbalance de clases.

La combinaci√≥n de pesos manuales y los pesos inversos puede ser eficaz para balancear la influencia de las clases en el modelo. Los pesos manuales se basan en un conocimiento previo sobre la importancia relativa de cada clase, mientras que los pesos inversos ajustan la influencia seg√∫n la frecuencia de las clases en los datos.

**Implementaci√≥n de Promediado de Pesos**: Para calcular los pesos combinados, utilizamos una combinaci√≥n de los pesos manuales y los inversos. Estos pesos se promedian para generar una estrategia equilibrada.

```{r}
# Convertir la variable objetivo a factor (si no lo est√°)
data_filtrado$ActivityType <- as.factor(data_filtrado$ActivityType)

# 1 Convertir Herzios a num√©rico
data_filtrado <- data_filtrado %>%
  mutate(herzios = as.numeric(herzios))

# Verificar que Herzios ahora es num√©rico
str(data_filtrado$herzios)
summary(data_filtrado$herzios)
```

```{r}
# Identificar solo las columnas num√©ricas (excluyendo `ActivityType`)
num_cols <- sapply(data_filtrado, is.numeric)

# Aplicar Min-Max Scaling SOLO a las columnas num√©ricas
preproc <- preProcess(data_filtrado[, num_cols], method = c("range"))
data_scaled <- predict(preproc, data_filtrado[, num_cols])

# Volver a agregar la variable objetivo `ActivityType`
data_scaled$ActivityType <- data_filtrado$ActivityType

# Verificar la estructura del dataset escalado
str(data_scaled)
summary(data_scaled)
```

```{r}
# Verificar si hay NA despu√©s del escalado
print("üîé ¬øHay valores NA despu√©s del escalado?")
print(any(is.na(data_scaled)))  # Debe ser FALSE

# Verificar si las variables est√°n en el rango correcto [0,1]
summary(data_scaled)
```

```{r}
# Aplciar nuevos pesos
class_weights_pesado <- c("Andando" = 10, "Autobus" = 15, "Avion" = 60, 
                   "Bicicleta" = 5, "Coche_autopista" = 10, "Coche_urbano" = 1)

# **2. Normalizaci√≥n de pesos manuales (usando el m√°ximo en vez de la suma)**
class_weights_pesado <- class_weights_pesado / max(class_weights_pesado)
print("Pesos manuales normalizados:")
print(class_weights_pesado)

# **3. Calcular pesos inversamente proporcionales al tama√±o de cada clase**
class_counts <- table(data_scaled$ActivityType)
class_weights_auto <- 1 / class_counts  # Inversamente proporcional al n√∫mero de muestras

# **4. Normalizar los pesos autom√°ticos usando el m√°ximo para escala relativa**
class_weights_auto <- class_weights_auto / max(class_weights_auto)

# **5. Asegurar que ambos vectores tengan las mismas clases**
names(class_weights_auto) <- names(class_counts)

# **6. Combinar los pesos manuales y autom√°ticos con ponderaci√≥n**
# ‚úî 70% de pesos autom√°ticos y 30% de pesos manuales para evitar sesgos excesivos
clases_comunes <- intersect(names(class_weights_pesado), names(class_weights_auto))
class_weights_combined <- (0.8 * class_weights_auto[clases_comunes]) + (0.2 * class_weights_pesado[clases_comunes])

# **7. Mostrar los pesos combinados normalizados**
print("Pesos combinados normalizados:")
print(class_weights_combined)


```

```{r}
set.seed(123)
trainIndex <- createDataPartition(data_scaled$ActivityType, p = 0.80, list = FALSE)
train_data <- data_scaled[trainIndex, ]
test_data <- data_scaled[-trainIndex, ]
```

```{r}
print(colnames(train_data))
print(colnames(test_data))

```

```{r}
print(table(train_data$ActivityType))
print(table(test_data$ActivityType))

```

# 4. Entrenar Modelo Kermel Simoide:

Dado que los resultados con el kernel radial han mostrado un buen rendimiento general, pero a√∫n presentan ciertos desaf√≠os con el desbalanceo de clases, se considera probar el **kernel sigmoide**. Este kernel puede ser √∫til en problemas donde los datos no sean perfectamente separables mediante una frontera estricta, ya que introduce una transformaci√≥n m√°s flexible similar a las redes neuronales.

Sin embargo, es importante se√±alar que el principal factor que afecta la clasificaci√≥n sigue siendo el **desbalanceo de clases**, lo que podr√≠a generar sesgo en el modelo sin importar el kernel utilizado. Por ello, adem√°s de probar el kernel sigmoide, es recomendable continuar ajustando los pesos de clase.

## 4.1 Kernel Simoide con clase combinada

```{r}
library(e1071)

# Definir hiperpar√°metros
best_C <- 1
best_gamma <- 0.1
best_coef0 <- 1

# Capturar tiempo de inicio del entrenamiento
start_train_time <- Sys.time()

# Entrenar el modelo SVM con kernel sigmoide
svm_model_sigmoid <- svm(ActivityType ~ ., 
                         data = train_data, 
                         kernel = "sigmoid",
                         cost = best_C,
                         gamma = best_gamma,
                         coef0 = best_coef0,
                         class.weights = class_weights_combined,
                         probability = TRUE)

# Capturar tiempo de finalizaci√≥n del entrenamiento
end_train_time <- Sys.time()
train_duration <- end_train_time - start_train_time

# Imprimir tiempo de entrenamiento
print(paste("Tiempo de entrenamiento:", train_duration))

```

```{r}
# Capturar tiempo de inicio de la predicci√≥n
start_pred_time <- Sys.time()

# Hacer predicciones con el modelo SVM Sigmoide
predictions <- predict(svm_model_sigmoid, test_data, probability = TRUE)

# Capturar tiempo de finalizaci√≥n de la predicci√≥n
end_pred_time <- Sys.time()

# Calcular la duraci√≥n de la predicci√≥n
pred_duration <- end_pred_time - start_pred_time

# Imprimir el tiempo de predicci√≥n
print(paste("Tiempo de predicci√≥n:", pred_duration))


```

```{r}
# Matriz de confusi√≥n
conf_matrix <- confusionMatrix(predictions, test_data$ActivityType)
print(conf_matrix)

# Extraer m√©tricas espec√≠ficas
precision <- conf_matrix$byClass[, "Pos Pred Value"]  # Precisi√≥n por clase
recall <- conf_matrix$byClass[, "Sensitivity"]        # Recall por clase
f1_score <- 2 * (precision * recall) / (precision + recall)  # F1-score

# üìå Mostrar resultados de precisi√≥n, recall y F1-score
metrics_results <- data.frame(Class = levels(test_data$ActivityType),
                              Precision = precision,
                              Recall = recall,
                              F1_Score = f1_score)

print(metrics_results)

```

```{r}
library(ggplot2)

# Generar predicciones en los datos de prueba
pred <- predict(svm_model_sigmoid, test_data)

# Asegurar que test_data solo tiene variables num√©ricas antes de PCA
test_data_numeric <- test_data %>%
  select(-ActivityType) %>%
  mutate_if(is.character, as.numeric)  # Convertir caracteres a num√©ricos si hay errores

# Aplicar PCA a los datos de prueba
pca_result <- prcomp(scale(test_data_numeric))

# Crear un dataframe con los resultados del PCA y las predicciones del modelo
pca_data <- data.frame(
  PC1 = pca_result$x[, 1], 
  PC2 = pca_result$x[, 2], 
  Predicci√≥n = pred,  # Agregamos la predicci√≥n del modelo
  Clase_Real = test_data$ActivityType  # Agregamos la clase real
)

# Graficar la separaci√≥n de clases usando PCA (seg√∫n la predicci√≥n del modelo)
ggplot(pca_data, aes(x = PC1, y = PC2, color = Predicci√≥n, shape = Clase_Real)) +
  geom_point(alpha = 0.6, size = 2) +  
  labs(title = "Separaci√≥n de Clases con PCA en SVM - Simoidal - Balance Combinado",
       x = "PC1",
       y = "PC2") +
  theme_minimal()

```

Los resultados obtenidos con el **SVM con kernel sigmoidal** muestran mejoras en algunas clases, pero a√∫n existen desaf√≠os en la clasificaci√≥n de ciertas categor√≠as. En t√©rminos generales, las clases **Bicicleta, Coche_autopista y Coche_urbano** fueron correctamente identificadas con valores de **F1-Score superiores a 0.94**, lo que indica que el modelo logr√≥ una buena precisi√≥n y recuperaci√≥n en estas categor√≠as. Sin embargo, persisten problemas en la clasificaci√≥n de la clase **Avi√≥n**, con un **F1-Score de 0.46**, debido a una baja sensibilidad (**Recall: 0.30**), lo que sugiere que el modelo sigue confundiendo esta categor√≠a con otras.

El an√°lisis de PCA muestra que el modelo logra una separaci√≥n visualmente aceptable entre las clases, aunque sigue existiendo cierto solapamiento entre categor√≠as como **Autob√∫s y Coche_urbano**. A pesar de que se aplicaron t√©cnicas de balanceo de clases, como la ponderaci√≥n ajustada, el desempe√±o en clases minoritarias sigue siendo un reto. Para mejorar estos resultados, se podr√≠a considerar una combinaci√≥n de t√©cnicas, como la optimizaci√≥n de hiperpar√°metros m√°s exhaustiva, el uso de t√©cnicas de remuestreo m√°s avanzadas (como Cluster-Based Resampling) y la exploraci√≥n de otros kernels m√°s adecuados para la estructura de los datos.

## 4.2 B√∫squeda del mejor par√°metro.

Durante el proceso de ajuste de hiperpar√°metros del modelo SVM con kernel sigmoidal, se enfrent√≥ un desaf√≠o t√©cnico al realizar la b√∫squeda de hiperpar√°metros en **R**. Aunque R es un lenguaje robusto para la ciencia de datos, en este caso, la b√∫squeda de par√°metros como **C** y **gamma** a trav√©s de validaci√≥n cruzada result√≥ ser muy costosa en t√©rminos de recursos. A medida que aumentaba el n√∫mero de combinaciones de par√°metros y el tama√±o del conjunto de datos, el proceso se volvi√≥ extremadamente lento, llegando a esperar hasta **3 horas** por resultados sin obtener √©xito. En muchos casos, el sistema colapsaba debido a la gran demanda de memoria y procesamiento, lo que hac√≠a que la operaci√≥n fuera insostenible.

Este inconveniente fue causado por la falta de optimizaci√≥n de R en cuanto a la paralelizaci√≥n de tareas y la gesti√≥n de memoria al realizar b√∫squedas exhaustivas de hiperpar√°metros. R no logr√≥ manejar de manera eficiente la carga computacional derivada de la validaci√≥n cruzada con m√∫ltiples combinaciones de par√°metros, lo que result√≥ en un tiempo de espera largo y un sistema inestable. Esto demostr√≥ que R no era la mejor opci√≥n en este caso espec√≠fico, dado que la operaci√≥n estaba limitando el progreso del an√°lisis.

Por lo tanto, se decidi√≥ cambiar a **Python**, conocido por su eficiencia y capacidad de manejar grandes vol√∫menes de datos y operaciones paralelizadas. Python, con bibliotecas como **scikit-learn** y **joblib**, permite la distribuci√≥n de tareas entre m√∫ltiples n√∫cleos de procesamiento, lo que optimiza significativamente el tiempo de c√°lculo. Gracias a estas capacidades de optimizaci√≥n, la b√∫squeda de hiperpar√°metros se complet√≥ con √©xito y en tiempos mucho m√°s cortos, permitiendo obtener los mejores par√°metros para el modelo de manera estable y sin colapsos en el sistema. Esto hizo que Python fuera la opci√≥n ideal para realizar la tarea de manera eficiente y escalable.

Una vez obtenidos los mejores hiperpar√°metros en Python, se utilizaron en **R** para verificar los resultados y garantizar que los par√°metros seleccionados tambi√©n fueran efectivos al replicar el an√°lisis en dicho entorno.

```{r}
library(e1071)

# Definir hiperpar√°metros
best_C <- 10
best_gamma <- 0.1


# Capturar tiempo de inicio del entrenamiento
start_train_time <- Sys.time()

# Entrenar el modelo SVM con kernel sigmoide
svm_model_sigmoid_10 <- svm(ActivityType ~ ., 
                         data = train_data, 
                         kernel = "sigmoid",
                         cost = best_C,
                         gamma = best_gamma,
                         class.weights = class_weights_combined,
                         probability = TRUE)

# Capturar tiempo de finalizaci√≥n del entrenamiento
end_train_time <- Sys.time()
train_duration <- end_train_time - start_train_time

# Imprimir tiempo de entrenamiento
print(paste("Tiempo de entrenamiento:", train_duration))

```

```{r}
# Capturar tiempo de inicio de la predicci√≥n
start_pred_time <- Sys.time()

# Hacer predicciones con el modelo SVM Sigmoide
predictions_10 <- predict(svm_model_sigmoid_10, test_data, probability = TRUE)

# Capturar tiempo de finalizaci√≥n de la predicci√≥n
end_pred_time <- Sys.time()

# Calcular la duraci√≥n de la predicci√≥n
pred_duration <- end_pred_time - start_pred_time

# Imprimir el tiempo de predicci√≥n
print(paste("Tiempo de predicci√≥n:", pred_duration))

```

```{r}
# Matriz de confusi√≥n
conf_matrix_10 <- confusionMatrix(predictions_10, test_data$ActivityType)
print(conf_matrix)

# Extraer m√©tricas espec√≠ficas
precision <- conf_matrix_10$byClass[, "Pos Pred Value"]  # Precisi√≥n por clase
recall <- conf_matrix_10$byClass[, "Sensitivity"]        # Recall por clase
f1_score <- 2 * (precision * recall) / (precision + recall)  # F1-score

# üìå Mostrar resultados de precisi√≥n, recall y F1-score
metrics_results <- data.frame(Class = levels(test_data$ActivityType),
                              Precision = precision,
                              Recall = recall,
                              F1_Score = f1_score)

print(metrics_results)

```

```{r}
library(ggplot2)

# Generar predicciones en los datos de prueba
pred <- predict(svm_model_sigmoid_10, test_data)

# Asegurar que test_data solo tiene variables num√©ricas antes de PCA
test_data_numeric <- test_data %>%
  select(-ActivityType) %>%
  mutate_if(is.character, as.numeric)  # Convertir caracteres a num√©ricos si hay errores

# Aplicar PCA a los datos de prueba
pca_result <- prcomp(scale(test_data_numeric))

# Crear un dataframe con los resultados del PCA y las predicciones del modelo
pca_data <- data.frame(
  PC1 = pca_result$x[, 1], 
  PC2 = pca_result$x[, 2], 
  Predicci√≥n = pred,  # Agregamos la predicci√≥n del modelo
  Clase_Real = test_data$ActivityType  # Agregamos la clase real
)

# Graficar la separaci√≥n de clases usando PCA (seg√∫n la predicci√≥n del modelo)
ggplot(pca_data, aes(x = PC1, y = PC2, color = Predicci√≥n, shape = Clase_Real)) +
  geom_point(alpha = 0.6, size = 2) +  
  labs(title = "Separaci√≥n de Clases con PCA en SVM - Simoidal - Balance Combinado",
       x = "PC1",
       y = "PC2") +
  theme_minimal()

```

En el proceso de desarrollo del modelo para la clasificaci√≥n del tipo de transporte, se utilizaron dos lenguajes de programaci√≥n, **Python** y **R**, con el fin de implementar el modelo de **M√°quinas de Vectores de Soporte (SVM)** con un **kernel sigmoidal**. Sin embargo, los resultados obtenidos en ambos lenguajes presentaron diferencias significativas, especialmente en cuanto al **accuracy** y las **m√©tricas de rendimiento**.

#### **Diferencias en el Rendimiento entre R y Python**

1.  **Uso de Librer√≠as y Ajustes de Modelo:**

    -   **Python**: Se utiliz√≥ **`scikit-learn`** para entrenar el modelo SVM, donde se aplic√≥ una **b√∫squeda de hiperpar√°metros** con **`GridSearchCV`** y validaci√≥n cruzada. Esta biblioteca est√° altamente optimizada para trabajar con modelos de machine learning y es muy eficiente en cuanto a manejo de memoria y paralelizaci√≥n, lo que permite ajustar de manera efectiva los hiperpar√°metros y obtener un modelo robusto. En este entorno, se logr√≥ un rendimiento perfecto (accuracy de 1.0) tanto en el conjunto de entrenamiento como en el de prueba.

    -   **R**: En R, se utiliz√≥ **`e1071`** para implementar el modelo SVM. Aunque se aplicaron t√©cnicas de **pesos de clase** y **SMOTE** para balancear las clases, los resultados fueron diferentes. El modelo en **R** mostr√≥ un **accuracy del 89.95%** en los datos de prueba, lo que refleja una diferencia significativa respecto a los resultados obtenidos en **Python**. Aunque R tiene paquetes potentes para clasificaci√≥n, como **`e1071`** y **`caret`**, la optimizaci√≥n de los par√°metros y la capacidad de paralelizaci√≥n no est√°n tan desarrolladas como en Python, lo que pudo haber afectado los resultados.

2.  **Manejo del Desbalanceo de Clases:**

    -   En **Python**, el balanceo de clases se manej√≥ de forma autom√°tica mediante el par√°metro `class_weight='balanced'` en el modelo SVM, lo que permiti√≥ que el modelo prestara m√°s atenci√≥n a las clases minoritarias, optimizando el rendimiento para esas clases. Esta caracter√≠stica est√° integrada en **`scikit-learn`** y facilita el manejo de datasets desbalanceados sin necesidad de ajustes manuales.

    -   En **R**, aunque se utiliz√≥ **peso inverso** y se ajustaron **pesos manuales** para balancear las clases, el proceso no fue tan autom√°tico como en Python. En **R**, el ajuste manual de los **pesos de clase** requiere intervenci√≥n expl√≠cita, y los resultados mostraron que el modelo podr√≠a no haber aprovechado completamente estas t√©cnicas, lo que result√≥ en un rendimiento inferior en los datos de prueba.

El modelo de **SVM con kernel sigmoidal** mostr√≥ diferencias de rendimiento entre **R** y **Python** debido a varios factores. En **Python**, la **b√∫squeda de hiperpar√°metros** con **`GridSearchCV`** y el **balanceo autom√°tico de clases** mediante `class_weight='balanced'` optimizaron el rendimiento, lo que result√≥ en un **accuracy del 100%** tanto en los datos de entrenamiento como en los de prueba. Adem√°s, la capacidad de **paralelizaci√≥n** y optimizaci√≥n de **scikit-learn** permiti√≥ un ajuste eficiente.

En **R**, aunque se aplicaron pesos inversos y **pesos manuales** para balancear las clases, el proceso no fue tan autom√°tico ni optimizado como en Python. La falta de una b√∫squeda de hiperpar√°metros tan exhaustiva y las limitaciones en la gesti√≥n de recursos computacionales tambi√©n contribuyeron a que el modelo tuviera un **accuracy inferior** en los datos de prueba (89.95%).

En resumen, **Python** ofreci√≥ una ventaja significativa en t√©rminos de optimizaci√≥n, manejo de recursos y herramientas avanzadas, lo que permiti√≥ obtener mejores resultados en este caso.

![](images/clipboard-3349399504.png)
